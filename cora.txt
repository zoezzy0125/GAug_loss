seed 7
Big Epoch 0/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8491, ap 0.8465
EPNet pretrain, Epoch [  2/160]: loss 0.6906, auc 0.8175, ap 0.8093
EPNet pretrain, Epoch [  3/160]: loss 0.6838, auc 0.7908, ap 0.7881
EPNet pretrain, Epoch [  4/160]: loss 0.6794, auc 0.7770, ap 0.7790
EPNet pretrain, Epoch [  5/160]: loss 0.6780, auc 0.7728, ap 0.7806
EPNet pretrain, Epoch [  6/160]: loss 0.6736, auc 0.7684, ap 0.7834
EPNet pretrain, Epoch [  7/160]: loss 0.6714, auc 0.7631, ap 0.7858
EPNet pretrain, Epoch [  8/160]: loss 0.6675, auc 0.7579, ap 0.7854
EPNet pretrain, Epoch [  9/160]: loss 0.6616, auc 0.7526, ap 0.7823
EPNet pretrain, Epoch [ 10/160]: loss 0.6556, auc 0.7495, ap 0.7801
EPNet pretrain, Epoch [ 11/160]: loss 0.6499, auc 0.7534, ap 0.7825
EPNet pretrain, Epoch [ 12/160]: loss 0.6424, auc 0.7690, ap 0.7933
EPNet pretrain, Epoch [ 13/160]: loss 0.6343, auc 0.7901, ap 0.8100
EPNet pretrain, Epoch [ 14/160]: loss 0.6269, auc 0.8089, ap 0.8264
EPNet pretrain, Epoch [ 15/160]: loss 0.6195, auc 0.8211, ap 0.8371
EPNet pretrain, Epoch [ 16/160]: loss 0.6128, auc 0.8294, ap 0.8435
EPNet pretrain, Epoch [ 17/160]: loss 0.6070, auc 0.8361, ap 0.8479
EPNet pretrain, Epoch [ 18/160]: loss 0.6018, auc 0.8429, ap 0.8511
EPNet pretrain, Epoch [ 19/160]: loss 0.5972, auc 0.8499, ap 0.8546
EPNet pretrain, Epoch [ 20/160]: loss 0.5932, auc 0.8566, ap 0.8585
EPNet pretrain, Epoch [ 21/160]: loss 0.5896, auc 0.8620, ap 0.8632
EPNet pretrain, Epoch [ 22/160]: loss 0.5865, auc 0.8663, ap 0.8673
EPNet pretrain, Epoch [ 23/160]: loss 0.5837, auc 0.8696, ap 0.8712
EPNet pretrain, Epoch [ 24/160]: loss 0.5809, auc 0.8730, ap 0.8751
EPNet pretrain, Epoch [ 25/160]: loss 0.5780, auc 0.8763, ap 0.8793
EPNet pretrain, Epoch [ 26/160]: loss 0.5752, auc 0.8796, ap 0.8832
EPNet pretrain, Epoch [ 27/160]: loss 0.5726, auc 0.8834, ap 0.8866
EPNet pretrain, Epoch [ 28/160]: loss 0.5704, auc 0.8860, ap 0.8890
EPNet pretrain, Epoch [ 29/160]: loss 0.5682, auc 0.8890, ap 0.8913
EPNet pretrain, Epoch [ 30/160]: loss 0.5654, auc 0.8918, ap 0.8937
EPNet pretrain, Epoch [ 31/160]: loss 0.5622, auc 0.8947, ap 0.8961
EPNet pretrain, Epoch [ 32/160]: loss 0.5591, auc 0.8980, ap 0.8991
EPNet pretrain, Epoch [ 33/160]: loss 0.5567, auc 0.8993, ap 0.9004
EPNet pretrain, Epoch [ 34/160]: loss 0.5548, auc 0.9005, ap 0.9013
EPNet pretrain, Epoch [ 35/160]: loss 0.5527, auc 0.9018, ap 0.9027
EPNet pretrain, Epoch [ 36/160]: loss 0.5503, auc 0.9031, ap 0.9041
EPNet pretrain, Epoch [ 37/160]: loss 0.5482, auc 0.9032, ap 0.9051
EPNet pretrain, Epoch [ 38/160]: loss 0.5462, auc 0.9057, ap 0.9075
EPNet pretrain, Epoch [ 39/160]: loss 0.5442, auc 0.9088, ap 0.9106
EPNet pretrain, Epoch [ 40/160]: loss 0.5421, auc 0.9115, ap 0.9134
EPNet pretrain, Epoch [ 41/160]: loss 0.5402, auc 0.9139, ap 0.9159
EPNet pretrain, Epoch [ 42/160]: loss 0.5384, auc 0.9150, ap 0.9176
EPNet pretrain, Epoch [ 43/160]: loss 0.5366, auc 0.9147, ap 0.9182
EPNet pretrain, Epoch [ 44/160]: loss 0.5348, auc 0.9154, ap 0.9195
EPNet pretrain, Epoch [ 45/160]: loss 0.5331, auc 0.9144, ap 0.9200
EPNet pretrain, Epoch [ 46/160]: loss 0.5317, auc 0.9164, ap 0.9224
EPNet pretrain, Epoch [ 47/160]: loss 0.5304, auc 0.9173, ap 0.9238
EPNet pretrain, Epoch [ 48/160]: loss 0.5291, auc 0.9172, ap 0.9242
EPNet pretrain, Epoch [ 49/160]: loss 0.5279, auc 0.9176, ap 0.9248
EPNet pretrain, Epoch [ 50/160]: loss 0.5267, auc 0.9193, ap 0.9261
EPNet pretrain, Epoch [ 51/160]: loss 0.5255, auc 0.9212, ap 0.9276
EPNet pretrain, Epoch [ 52/160]: loss 0.5244, auc 0.9229, ap 0.9290
EPNet pretrain, Epoch [ 53/160]: loss 0.5233, auc 0.9242, ap 0.9300
EPNet pretrain, Epoch [ 54/160]: loss 0.5221, auc 0.9251, ap 0.9308
EPNet pretrain, Epoch [ 55/160]: loss 0.5208, auc 0.9258, ap 0.9315
EPNet pretrain, Epoch [ 56/160]: loss 0.5195, auc 0.9264, ap 0.9322
EPNet pretrain, Epoch [ 57/160]: loss 0.5183, auc 0.9260, ap 0.9320
EPNet pretrain, Epoch [ 58/160]: loss 0.5170, auc 0.9260, ap 0.9324
EPNet pretrain, Epoch [ 59/160]: loss 0.5156, auc 0.9275, ap 0.9336
EPNet pretrain, Epoch [ 60/160]: loss 0.5143, auc 0.9294, ap 0.9352
EPNet pretrain, Epoch [ 61/160]: loss 0.5130, auc 0.9294, ap 0.9353
EPNet pretrain, Epoch [ 62/160]: loss 0.5117, auc 0.9307, ap 0.9363
EPNet pretrain, Epoch [ 63/160]: loss 0.5104, auc 0.9309, ap 0.9365
EPNet pretrain, Epoch [ 64/160]: loss 0.5092, auc 0.9315, ap 0.9373
EPNet pretrain, Epoch [ 65/160]: loss 0.5079, auc 0.9348, ap 0.9398
EPNet pretrain, Epoch [ 66/160]: loss 0.5067, auc 0.9360, ap 0.9408
EPNet pretrain, Epoch [ 67/160]: loss 0.5055, auc 0.9372, ap 0.9420
EPNet pretrain, Epoch [ 68/160]: loss 0.5044, auc 0.9395, ap 0.9439
EPNet pretrain, Epoch [ 69/160]: loss 0.5032, auc 0.9401, ap 0.9445
EPNet pretrain, Epoch [ 70/160]: loss 0.5021, auc 0.9419, ap 0.9460
EPNet pretrain, Epoch [ 71/160]: loss 0.5009, auc 0.9429, ap 0.9468
EPNet pretrain, Epoch [ 72/160]: loss 0.4999, auc 0.9441, ap 0.9477
EPNet pretrain, Epoch [ 73/160]: loss 0.4988, auc 0.9455, ap 0.9487
EPNet pretrain, Epoch [ 74/160]: loss 0.4978, auc 0.9473, ap 0.9501
EPNet pretrain, Epoch [ 75/160]: loss 0.4968, auc 0.9480, ap 0.9506
EPNet pretrain, Epoch [ 76/160]: loss 0.4958, auc 0.9487, ap 0.9511
EPNet pretrain, Epoch [ 77/160]: loss 0.4948, auc 0.9500, ap 0.9521
EPNet pretrain, Epoch [ 78/160]: loss 0.4937, auc 0.9502, ap 0.9522
EPNet pretrain, Epoch [ 79/160]: loss 0.4927, auc 0.9509, ap 0.9528
EPNet pretrain, Epoch [ 80/160]: loss 0.4917, auc 0.9525, ap 0.9544
EPNet pretrain, Epoch [ 81/160]: loss 0.4907, auc 0.9531, ap 0.9551
EPNet pretrain, Epoch [ 82/160]: loss 0.4897, auc 0.9543, ap 0.9560
EPNet pretrain, Epoch [ 83/160]: loss 0.4888, auc 0.9550, ap 0.9565
EPNet pretrain, Epoch [ 84/160]: loss 0.4879, auc 0.9543, ap 0.9561
EPNet pretrain, Epoch [ 85/160]: loss 0.4871, auc 0.9549, ap 0.9567
EPNet pretrain, Epoch [ 86/160]: loss 0.4864, auc 0.9547, ap 0.9566
EPNet pretrain, Epoch [ 87/160]: loss 0.4857, auc 0.9552, ap 0.9570
EPNet pretrain, Epoch [ 88/160]: loss 0.4850, auc 0.9562, ap 0.9578
EPNet pretrain, Epoch [ 89/160]: loss 0.4843, auc 0.9573, ap 0.9587
EPNet pretrain, Epoch [ 90/160]: loss 0.4836, auc 0.9584, ap 0.9597
EPNet pretrain, Epoch [ 91/160]: loss 0.4829, auc 0.9588, ap 0.9602
EPNet pretrain, Epoch [ 92/160]: loss 0.4822, auc 0.9594, ap 0.9608
EPNet pretrain, Epoch [ 93/160]: loss 0.4814, auc 0.9598, ap 0.9612
EPNet pretrain, Epoch [ 94/160]: loss 0.4807, auc 0.9601, ap 0.9616
EPNet pretrain, Epoch [ 95/160]: loss 0.4800, auc 0.9605, ap 0.9620
EPNet pretrain, Epoch [ 96/160]: loss 0.4793, auc 0.9618, ap 0.9632
EPNet pretrain, Epoch [ 97/160]: loss 0.4786, auc 0.9624, ap 0.9637
EPNet pretrain, Epoch [ 98/160]: loss 0.4779, auc 0.9629, ap 0.9642
EPNet pretrain, Epoch [ 99/160]: loss 0.4772, auc 0.9634, ap 0.9647
EPNet pretrain, Epoch [100/160]: loss 0.4765, auc 0.9645, ap 0.9655
EPNet pretrain, Epoch [101/160]: loss 0.4759, auc 0.9648, ap 0.9658
EPNet pretrain, Epoch [102/160]: loss 0.4753, auc 0.9652, ap 0.9662
EPNet pretrain, Epoch [103/160]: loss 0.4747, auc 0.9668, ap 0.9674
EPNet pretrain, Epoch [104/160]: loss 0.4741, auc 0.9672, ap 0.9676
EPNet pretrain, Epoch [105/160]: loss 0.4735, auc 0.9669, ap 0.9672
EPNet pretrain, Epoch [106/160]: loss 0.4729, auc 0.9673, ap 0.9674
EPNet pretrain, Epoch [107/160]: loss 0.4723, auc 0.9676, ap 0.9675
EPNet pretrain, Epoch [108/160]: loss 0.4717, auc 0.9685, ap 0.9680
EPNet pretrain, Epoch [109/160]: loss 0.4711, auc 0.9675, ap 0.9671
EPNet pretrain, Epoch [110/160]: loss 0.4705, auc 0.9677, ap 0.9671
EPNet pretrain, Epoch [111/160]: loss 0.4699, auc 0.9679, ap 0.9671
EPNet pretrain, Epoch [112/160]: loss 0.4693, auc 0.9688, ap 0.9677
EPNet pretrain, Epoch [113/160]: loss 0.4688, auc 0.9691, ap 0.9677
EPNet pretrain, Epoch [114/160]: loss 0.4682, auc 0.9693, ap 0.9678
EPNet pretrain, Epoch [115/160]: loss 0.4677, auc 0.9702, ap 0.9684
EPNet pretrain, Epoch [116/160]: loss 0.4671, auc 0.9703, ap 0.9686
EPNet pretrain, Epoch [117/160]: loss 0.4666, auc 0.9705, ap 0.9688
EPNet pretrain, Epoch [118/160]: loss 0.4661, auc 0.9707, ap 0.9689
EPNet pretrain, Epoch [119/160]: loss 0.4655, auc 0.9709, ap 0.9691
EPNet pretrain, Epoch [120/160]: loss 0.4650, auc 0.9712, ap 0.9693
EPNet pretrain, Epoch [121/160]: loss 0.4645, auc 0.9720, ap 0.9699
EPNet pretrain, Epoch [122/160]: loss 0.4640, auc 0.9722, ap 0.9700
EPNet pretrain, Epoch [123/160]: loss 0.4635, auc 0.9724, ap 0.9701
EPNet pretrain, Epoch [124/160]: loss 0.4629, auc 0.9725, ap 0.9702
EPNet pretrain, Epoch [125/160]: loss 0.4624, auc 0.9727, ap 0.9703
EPNet pretrain, Epoch [126/160]: loss 0.4619, auc 0.9729, ap 0.9704
EPNet pretrain, Epoch [127/160]: loss 0.4614, auc 0.9730, ap 0.9705
EPNet pretrain, Epoch [128/160]: loss 0.4609, auc 0.9725, ap 0.9701
EPNet pretrain, Epoch [129/160]: loss 0.4605, auc 0.9726, ap 0.9703
EPNet pretrain, Epoch [130/160]: loss 0.4600, auc 0.9740, ap 0.9714
EPNet pretrain, Epoch [131/160]: loss 0.4595, auc 0.9749, ap 0.9721
EPNet pretrain, Epoch [132/160]: loss 0.4590, auc 0.9750, ap 0.9723
EPNet pretrain, Epoch [133/160]: loss 0.4585, auc 0.9752, ap 0.9724
EPNet pretrain, Epoch [134/160]: loss 0.4580, auc 0.9752, ap 0.9725
EPNet pretrain, Epoch [135/160]: loss 0.4575, auc 0.9754, ap 0.9727
EPNet pretrain, Epoch [136/160]: loss 0.4570, auc 0.9756, ap 0.9729
EPNet pretrain, Epoch [137/160]: loss 0.4565, auc 0.9757, ap 0.9730
EPNet pretrain, Epoch [138/160]: loss 0.4560, auc 0.9759, ap 0.9731
EPNet pretrain, Epoch [139/160]: loss 0.4555, auc 0.9761, ap 0.9734
EPNet pretrain, Epoch [140/160]: loss 0.4550, auc 0.9762, ap 0.9734
EPNet pretrain, Epoch [141/160]: loss 0.4545, auc 0.9763, ap 0.9736
EPNet pretrain, Epoch [142/160]: loss 0.4540, auc 0.9763, ap 0.9736
EPNet pretrain, Epoch [143/160]: loss 0.4535, auc 0.9765, ap 0.9737
EPNet pretrain, Epoch [144/160]: loss 0.4529, auc 0.9771, ap 0.9742
EPNet pretrain, Epoch [145/160]: loss 0.4524, auc 0.9772, ap 0.9744
EPNet pretrain, Epoch [146/160]: loss 0.4520, auc 0.9765, ap 0.9737
EPNet pretrain, Epoch [147/160]: loss 0.4515, auc 0.9766, ap 0.9738
EPNet pretrain, Epoch [148/160]: loss 0.4510, auc 0.9766, ap 0.9738
EPNet pretrain, Epoch [149/160]: loss 0.4506, auc 0.9774, ap 0.9745
EPNet pretrain, Epoch [150/160]: loss 0.4501, auc 0.9775, ap 0.9748
EPNet pretrain, Epoch [151/160]: loss 0.4497, auc 0.9776, ap 0.9750
EPNet pretrain, Epoch [152/160]: loss 0.4493, auc 0.9777, ap 0.9752
EPNet pretrain, Epoch [153/160]: loss 0.4489, auc 0.9778, ap 0.9753
EPNet pretrain, Epoch [154/160]: loss 0.4486, auc 0.9778, ap 0.9754
EPNet pretrain, Epoch [155/160]: loss 0.4482, auc 0.9779, ap 0.9754
EPNet pretrain, Epoch [156/160]: loss 0.4479, auc 0.9779, ap 0.9754
EPNet pretrain, Epoch [157/160]: loss 0.4475, auc 0.9780, ap 0.9755
EPNet pretrain, Epoch [158/160]: loss 0.4472, auc 0.9787, ap 0.9761
EPNet pretrain, Epoch [159/160]: loss 0.4469, auc 0.9789, ap 0.9762
EPNet pretrain, Epoch [160/160]: loss 0.4466, auc 0.9790, ap 0.9764
NCNet pretrain, Epoch [ 1/30]: loss 1.9463, val acc 0.1280, test acc 0.1550
NCNet pretrain, Epoch [ 2/30]: loss 1.9297, val acc 0.1720, test acc 0.1890
NCNet pretrain, Epoch [ 3/30]: loss 1.9082, val acc 0.3340, test acc 0.3600
NCNet pretrain, Epoch [ 4/30]: loss 1.8843, val acc 0.4580, test acc 0.4830
NCNet pretrain, Epoch [ 5/30]: loss 1.8546, val acc 0.5180, test acc 0.5560
NCNet pretrain, Epoch [ 6/30]: loss 1.8208, val acc 0.5800, test acc 0.6180
NCNet pretrain, Epoch [ 7/30]: loss 1.7873, val acc 0.6180, test acc 0.6570
NCNet pretrain, Epoch [ 8/30]: loss 1.7543, val acc 0.6440, test acc 0.6940
NCNet pretrain, Epoch [ 9/30]: loss 1.7123, val acc 0.6780, test acc 0.7160
NCNet pretrain, Epoch [10/30]: loss 1.6665, val acc 0.6940, test acc 0.7390
NCNet pretrain, Epoch [11/30]: loss 1.6188, val acc 0.7100, test acc 0.7510
NCNet pretrain, Epoch [12/30]: loss 1.5758, val acc 0.7160, test acc 0.7550
NCNet pretrain, Epoch [13/30]: loss 1.5225, val acc 0.7200, test acc 0.7680
NCNet pretrain, Epoch [14/30]: loss 1.4691, val acc 0.7340, test acc 0.7720
NCNet pretrain, Epoch [15/30]: loss 1.4177, val acc 0.7500, test acc 0.7840
NCNet pretrain, Epoch [16/30]: loss 1.3654, val acc 0.7640, test acc 0.7870
NCNet pretrain, Epoch [17/30]: loss 1.2935, val acc 0.7700, test acc 0.7930
NCNet pretrain, Epoch [18/30]: loss 1.2473, val acc 0.7740, test acc 0.7970
NCNet pretrain, Epoch [19/30]: loss 1.1887, val acc 0.7720
NCNet pretrain, Epoch [20/30]: loss 1.1222, val acc 0.7720
NCNet pretrain, Epoch [21/30]: loss 1.0523, val acc 0.7760, test acc 0.8010
NCNet pretrain, Epoch [22/30]: loss 1.0226, val acc 0.7760
NCNet pretrain, Epoch [23/30]: loss 0.9903, val acc 0.7780, test acc 0.8010
NCNet pretrain, Epoch [24/30]: loss 0.9165, val acc 0.7800, test acc 0.8010
NCNet pretrain, Epoch [25/30]: loss 0.8781, val acc 0.7880, test acc 0.8040
NCNet pretrain, Epoch [26/30]: loss 0.8194, val acc 0.7920, test acc 0.8130
NCNet pretrain, Epoch [27/30]: loss 0.8013, val acc 0.8000, test acc 0.8210
NCNet pretrain, Epoch [28/30]: loss 0.7472, val acc 0.8040, test acc 0.8200
NCNet pretrain, Epoch [29/30]: loss 0.6931, val acc 0.8020
NCNet pretrain, Epoch [30/30]: loss 0.6660, val acc 0.7980
difference tensor(0.3813, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4463, nc loss 1.4301, ep auc: 0.9784, ep ap 0.9760, val acc 0.7460, test acc 0.7820
difference tensor(0.5435, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4589, nc loss 1.3326, ep auc: 0.9737, ep ap 0.9699, val acc 0.7760, test acc 0.8000
difference tensor(0.4042, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.4883, nc loss 1.2724, ep auc: 0.9652, ep ap 0.9601, val acc 0.7820, test acc 0.8190
difference tensor(0.4512, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5209, nc loss 1.1294, ep auc: 0.9469, ep ap 0.9409, val acc 0.8000, test acc 0.8380
difference tensor(0.5940, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5494, nc loss 1.1047, ep auc: 0.9050, ep ap 0.9005, val acc 0.8200, test acc 0.8420
difference tensor(1.9003, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.5731, nc loss 1.0393, ep auc: 0.8656, ep ap 0.8613, val acc 0.8220, test acc 0.8420
difference tensor(0.9774, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.5906, nc loss 1.0135, ep auc: 0.8305, ep ap 0.8267, val acc 0.8100, test acc 0.8420
difference tensor(1.3602, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.6000, nc loss 1.0025, ep auc: 0.7991, ep ap 0.7977, val acc 0.7980, test acc 0.8420
difference tensor(1.1069, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6072, nc loss 0.9543, ep auc: 0.7704, ep ap 0.7703, val acc 0.8000, test acc 0.8420
difference tensor(1.2994, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6112, nc loss 0.9295, ep auc: 0.7441, ep ap 0.7461, val acc 0.8060, test acc 0.8420
difference tensor(2.3759, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6124, nc loss 0.8939, ep auc: 0.7355, ep ap 0.7378, val acc 0.8140, test acc 0.8420
difference tensor(1.1678, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6130, nc loss 0.8399, ep auc: 0.7258, ep ap 0.7281, val acc 0.8100, test acc 0.8420
difference tensor(1.3643, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6137, nc loss 0.8253, ep auc: 0.7181, ep ap 0.7209, val acc 0.8140, test acc 0.8420
difference tensor(1.4447, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6138, nc loss 0.7743, ep auc: 0.7158, ep ap 0.7179, val acc 0.8080, test acc 0.8420
difference tensor(1.6634, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6143, nc loss 0.7747, ep auc: 0.7072, ep ap 0.7097, val acc 0.8040, test acc 0.8420
difference tensor(1.2575, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6146, nc loss 0.7798, ep auc: 0.7035, ep ap 0.7062, val acc 0.8100, test acc 0.8420
difference tensor(1.2106, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6144, nc loss 0.7542, ep auc: 0.7032, ep ap 0.7054, val acc 0.8120, test acc 0.8420
difference tensor(3.1718, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6143, nc loss 0.7461, ep auc: 0.7041, ep ap 0.7045, val acc 0.8140, test acc 0.8420
difference tensor(1.6416, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6147, nc loss 0.7295, ep auc: 0.7036, ep ap 0.7031, val acc 0.8160, test acc 0.8420
difference tensor(1.5669, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6151, nc loss 0.6928, ep auc: 0.7016, ep ap 0.7004, val acc 0.8100, test acc 0.8420
difference tensor(1.4649, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6157, nc loss 0.7048, ep auc: 0.6992, ep ap 0.6978, val acc 0.8120, test acc 0.8420
difference tensor(0.8961, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6163, nc loss 0.6821, ep auc: 0.6964, ep ap 0.6954, val acc 0.8060, test acc 0.8420
difference tensor(0.8970, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6172, nc loss 0.6804, ep auc: 0.6933, ep ap 0.6922, val acc 0.8040, test acc 0.8420
difference tensor(2.5137, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6182, nc loss 0.6861, ep auc: 0.6915, ep ap 0.6899, val acc 0.8100, test acc 0.8420
difference tensor(0.9868, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6191, nc loss 0.6699, ep auc: 0.6907, ep ap 0.6888, val acc 0.8100, test acc 0.8420
difference tensor(1.1873, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6197, nc loss 0.6800, ep auc: 0.6894, ep ap 0.6879, val acc 0.8060, test acc 0.8420
difference tensor(1.6140, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6202, nc loss 0.6654, ep auc: 0.6872, ep ap 0.6861, val acc 0.8060, test acc 0.8420
difference tensor(0.8649, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6204, nc loss 0.6439, ep auc: 0.6853, ep ap 0.6851, val acc 0.8060, test acc 0.8420
difference tensor(1.4842, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6207, nc loss 0.6585, ep auc: 0.6846, ep ap 0.6845, val acc 0.8040, test acc 0.8420
difference tensor(1.5980, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6212, nc loss 0.6450, ep auc: 0.6827, ep ap 0.6833, val acc 0.8000, test acc 0.8420
difference tensor(5.3535, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6218, nc loss 0.6689, ep auc: 0.6832, ep ap 0.6846, val acc 0.7960, test acc 0.8420
difference tensor(3.0907, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6225, nc loss 0.6528, ep auc: 0.6842, ep ap 0.6857, val acc 0.8000, test acc 0.8420
difference tensor(1.3271, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6233, nc loss 0.6495, ep auc: 0.6860, ep ap 0.6868, val acc 0.8040, test acc 0.8420
difference tensor(1.2784, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6239, nc loss 0.6313, ep auc: 0.6875, ep ap 0.6880, val acc 0.8040, test acc 0.8420
difference tensor(3.8038, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6245, nc loss 0.6288, ep auc: 0.6882, ep ap 0.6885, val acc 0.7960, test acc 0.8420
difference tensor(1.2014, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6252, nc loss 0.6424, ep auc: 0.6899, ep ap 0.6905, val acc 0.7940, test acc 0.8420
difference tensor(2.3998, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6259, nc loss 0.6354, ep auc: 0.6899, ep ap 0.6905, val acc 0.7920, test acc 0.8420
difference tensor(1.1726, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6264, nc loss 0.6419, ep auc: 0.6938, ep ap 0.6942, val acc 0.7920, test acc 0.8420
difference tensor(3.0326, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6268, nc loss 0.6378, ep auc: 0.6945, ep ap 0.6949, val acc 0.7900, test acc 0.8420
difference tensor(1.0337, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6273, nc loss 0.6385, ep auc: 0.6974, ep ap 0.6974, val acc 0.7940, test acc 0.8420
difference tensor(1.5321, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6280, nc loss 0.6387, ep auc: 0.6974, ep ap 0.6972, val acc 0.7980, test acc 0.8420
difference tensor(1.3179, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6285, nc loss 0.6516, ep auc: 0.6969, ep ap 0.6972, val acc 0.7900, test acc 0.8420
difference tensor(1.6172, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6289, nc loss 0.6625, ep auc: 0.6961, ep ap 0.6963, val acc 0.7900, test acc 0.8420
difference tensor(2.2507, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6293, nc loss 0.6467, ep auc: 0.6931, ep ap 0.6937, val acc 0.7920, test acc 0.8420
difference tensor(1.5424, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6295, nc loss 0.6424, ep auc: 0.6909, ep ap 0.6919, val acc 0.7880, test acc 0.8420
difference tensor(1.4302, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6300, nc loss 0.6694, ep auc: 0.6866, ep ap 0.6881, val acc 0.7860, test acc 0.8420
difference tensor(1.5285, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 47/200]: ep loss 0.6306, nc loss 0.6320, ep auc: 0.6887, ep ap 0.6900, val acc 0.7920, test acc 0.8420
difference tensor(1.2265, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 48/200]: ep loss 0.6315, nc loss 0.6240, ep auc: 0.6887, ep ap 0.6899, val acc 0.7920, test acc 0.8420
difference tensor(1.0009, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 49/200]: ep loss 0.6322, nc loss 0.6416, ep auc: 0.6887, ep ap 0.6898, val acc 0.7960, test acc 0.8420
difference tensor(2.7810, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 50/200]: ep loss 0.6330, nc loss 0.6353, ep auc: 0.6887, ep ap 0.6896, val acc 0.7920, test acc 0.8420
difference tensor(2.2564, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 51/200]: ep loss 0.6333, nc loss 0.6249, ep auc: 0.6894, ep ap 0.6902, val acc 0.7880, test acc 0.8420
difference tensor(1.0524, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 52/200]: ep loss 0.6335, nc loss 0.6229, ep auc: 0.6887, ep ap 0.6896, val acc 0.7840, test acc 0.8420
difference tensor(2.0785, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 53/200]: ep loss 0.6338, nc loss 0.6495, ep auc: 0.6887, ep ap 0.6894, val acc 0.7840, test acc 0.8420
difference tensor(1.7648, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 54/200]: ep loss 0.6340, nc loss 0.6350, ep auc: 0.6883, ep ap 0.6894, val acc 0.7880, test acc 0.8420
difference tensor(1.2915, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 55/200]: ep loss 0.6341, nc loss 0.6405, ep auc: 0.6876, ep ap 0.6888, val acc 0.7820, test acc 0.8420
difference tensor(2.1491, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 56/200]: ep loss 0.6343, nc loss 0.6186, ep auc: 0.6883, ep ap 0.6894, val acc 0.7840, test acc 0.8420
difference tensor(1.3431, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 57/200]: ep loss 0.6344, nc loss 0.6337, ep auc: 0.6890, ep ap 0.6900, val acc 0.7920, test acc 0.8420
difference tensor(1.1950, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 58/200]: ep loss 0.6342, nc loss 0.6206, ep auc: 0.6891, ep ap 0.6901, val acc 0.7900, test acc 0.8420
difference tensor(1.0478, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 59/200]: ep loss 0.6342, nc loss 0.6381, ep auc: 0.6898, ep ap 0.6908, val acc 0.7940, test acc 0.8420
difference tensor(0.9824, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 60/200]: ep loss 0.6343, nc loss 0.6191, ep auc: 0.6910, ep ap 0.6916, val acc 0.7960, test acc 0.8420
difference tensor(1.3490, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 61/200]: ep loss 0.6343, nc loss 0.6263, ep auc: 0.6911, ep ap 0.6917, val acc 0.8000, test acc 0.8420
difference tensor(1.8145, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 62/200]: ep loss 0.6343, nc loss 0.6499, ep auc: 0.6933, ep ap 0.6938, val acc 0.7940, test acc 0.8420
difference tensor(1.8118, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 63/200]: ep loss 0.6342, nc loss 0.6224, ep auc: 0.6929, ep ap 0.6940, val acc 0.7920, test acc 0.8420
difference tensor(1.4353, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 64/200]: ep loss 0.6341, nc loss 0.6198, ep auc: 0.6916, ep ap 0.6930, val acc 0.7880, test acc 0.8420
difference tensor(1.0780, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 65/200]: ep loss 0.6338, nc loss 0.6076, ep auc: 0.6912, ep ap 0.6932, val acc 0.7840, test acc 0.8420
difference tensor(1.3284, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 66/200]: ep loss 0.6335, nc loss 0.6047, ep auc: 0.6900, ep ap 0.6928, val acc 0.7860, test acc 0.8420
difference tensor(1.5747, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 67/200]: ep loss 0.6331, nc loss 0.6229, ep auc: 0.6902, ep ap 0.6924, val acc 0.7840, test acc 0.8420
difference tensor(1.5104, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 68/200]: ep loss 0.6329, nc loss 0.6094, ep auc: 0.6907, ep ap 0.6924, val acc 0.7860, test acc 0.8420
difference tensor(1.8244, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 69/200]: ep loss 0.6328, nc loss 0.6075, ep auc: 0.6906, ep ap 0.6925, val acc 0.7840, test acc 0.8420
difference tensor(1.1832, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 70/200]: ep loss 0.6326, nc loss 0.5924, ep auc: 0.6942, ep ap 0.6955, val acc 0.7840, test acc 0.8420
difference tensor(1.4883, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 71/200]: ep loss 0.6324, nc loss 0.6192, ep auc: 0.6930, ep ap 0.6949, val acc 0.7920, test acc 0.8420
difference tensor(1.5449, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 72/200]: ep loss 0.6325, nc loss 0.6002, ep auc: 0.6942, ep ap 0.6956, val acc 0.7840, test acc 0.8420
difference tensor(2.4549, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 73/200]: ep loss 0.6325, nc loss 0.6165, ep auc: 0.6943, ep ap 0.6957, val acc 0.7800, test acc 0.8420
difference tensor(1.3151, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 74/200]: ep loss 0.6330, nc loss 0.6217, ep auc: 0.6950, ep ap 0.6963, val acc 0.7820, test acc 0.8420
difference tensor(1.1573, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 75/200]: ep loss 0.6333, nc loss 0.6185, ep auc: 0.6953, ep ap 0.6970, val acc 0.7880, test acc 0.8420
difference tensor(1.7163, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 76/200]: ep loss 0.6333, nc loss 0.6194, ep auc: 0.6960, ep ap 0.6974, val acc 0.7860, test acc 0.8420
difference tensor(1.0798, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 77/200]: ep loss 0.6333, nc loss 0.6139, ep auc: 0.6960, ep ap 0.6973, val acc 0.7780, test acc 0.8420
difference tensor(1.6959, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 78/200]: ep loss 0.6330, nc loss 0.6029, ep auc: 0.6967, ep ap 0.6978, val acc 0.7760, test acc 0.8420
difference tensor(2.0459, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 79/200]: ep loss 0.6328, nc loss 0.5996, ep auc: 0.6974, ep ap 0.6984, val acc 0.7800, test acc 0.8420
difference tensor(1.6074, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 80/200]: ep loss 0.6326, nc loss 0.6035, ep auc: 0.6967, ep ap 0.6979, val acc 0.7820, test acc 0.8420
difference tensor(1.1955, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 81/200]: ep loss 0.6324, nc loss 0.6035, ep auc: 0.6967, ep ap 0.6979, val acc 0.7840, test acc 0.8420
difference tensor(1.2438, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 82/200]: ep loss 0.6321, nc loss 0.6090, ep auc: 0.6968, ep ap 0.6980, val acc 0.7880, test acc 0.8420
difference tensor(1.1286, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 83/200]: ep loss 0.6318, nc loss 0.6152, ep auc: 0.6961, ep ap 0.6974, val acc 0.7860, test acc 0.8420
difference tensor(1.2449, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 84/200]: ep loss 0.6314, nc loss 0.6016, ep auc: 0.6964, ep ap 0.6981, val acc 0.7900, test acc 0.8420
difference tensor(1.2991, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 85/200]: ep loss 0.6309, nc loss 0.5973, ep auc: 0.6958, ep ap 0.6976, val acc 0.7860, test acc 0.8420
difference tensor(1.5462, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 86/200]: ep loss 0.6304, nc loss 0.6048, ep auc: 0.6958, ep ap 0.6978, val acc 0.7880, test acc 0.8420
difference tensor(1.1171, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 87/200]: ep loss 0.6297, nc loss 0.6039, ep auc: 0.6958, ep ap 0.6978, val acc 0.7840, test acc 0.8420
difference tensor(1.0498, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 88/200]: ep loss 0.6292, nc loss 0.5868, ep auc: 0.6970, ep ap 0.6986, val acc 0.7800, test acc 0.8420
difference tensor(0.9261, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 89/200]: ep loss 0.6288, nc loss 0.5998, ep auc: 0.6976, ep ap 0.6981, val acc 0.7860, test acc 0.8420
difference tensor(1.6970, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 90/200]: ep loss 0.6285, nc loss 0.5905, ep auc: 0.6974, ep ap 0.6976, val acc 0.7860, test acc 0.8420
difference tensor(1.0888, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 91/200]: ep loss 0.6283, nc loss 0.5934, ep auc: 0.6971, ep ap 0.6971, val acc 0.7820, test acc 0.8420
difference tensor(3.0997, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 92/200]: ep loss 0.6281, nc loss 0.6076, ep auc: 0.6960, ep ap 0.6965, val acc 0.7820, test acc 0.8420
difference tensor(1.1107, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 93/200]: ep loss 0.6280, nc loss 0.5920, ep auc: 0.6948, ep ap 0.6959, val acc 0.7840, test acc 0.8420
difference tensor(1.7460, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 94/200]: ep loss 0.6280, nc loss 0.6053, ep auc: 0.6955, ep ap 0.6966, val acc 0.7800, test acc 0.8420
difference tensor(1.9613, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 95/200]: ep loss 0.6280, nc loss 0.5889, ep auc: 0.6955, ep ap 0.6967, val acc 0.7780, test acc 0.8420
difference tensor(1.4920, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 96/200]: ep loss 0.6280, nc loss 0.6018, ep auc: 0.6944, ep ap 0.6962, val acc 0.7760, test acc 0.8420
difference tensor(2.4187, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 97/200]: ep loss 0.6279, nc loss 0.5976, ep auc: 0.6937, ep ap 0.6955, val acc 0.7840, test acc 0.8420
difference tensor(1.0611, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 98/200]: ep loss 0.6279, nc loss 0.6090, ep auc: 0.6937, ep ap 0.6956, val acc 0.7880, test acc 0.8420
difference tensor(1.0070, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 99/200]: ep loss 0.6277, nc loss 0.5996, ep auc: 0.6959, ep ap 0.6974, val acc 0.7860, test acc 0.8420
difference tensor(2.8110, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [100/200]: ep loss 0.6275, nc loss 0.5925, ep auc: 0.6976, ep ap 0.6980, val acc 0.7820, test acc 0.8420
difference tensor(1.5211, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [101/200]: ep loss 0.6274, nc loss 0.5999, ep auc: 0.7008, ep ap 0.7009, val acc 0.7760, test acc 0.8420
difference tensor(1.3911, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [102/200]: ep loss 0.6273, nc loss 0.5833, ep auc: 0.7011, ep ap 0.7016, val acc 0.7720, test acc 0.8420
difference tensor(1.8550, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [103/200]: ep loss 0.6273, nc loss 0.5969, ep auc: 0.7040, ep ap 0.7041, val acc 0.7740, test acc 0.8420
difference tensor(1.2284, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [104/200]: ep loss 0.6273, nc loss 0.5880, ep auc: 0.7048, ep ap 0.7050, val acc 0.7760, test acc 0.8420
difference tensor(1.7724, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [105/200]: ep loss 0.6273, nc loss 0.5999, ep auc: 0.7052, ep ap 0.7051, val acc 0.7780, test acc 0.8420
Early stop!
Final test acc with early stop: 0.8420, without early stop: 0.7960
Micro F1: 0.842000, std: 0.000000, Max is 0.842000, min is 0.842000
Big Epoch 0/30 dataset is cora fid_frac is 0.1
Big Epoch 1/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8442, ap 0.8509
EPNet pretrain, Epoch [  2/160]: loss 0.6903, auc 0.8141, ap 0.8113
EPNet pretrain, Epoch [  3/160]: loss 0.6829, auc 0.7953, ap 0.7959
EPNet pretrain, Epoch [  4/160]: loss 0.6817, auc 0.7873, ap 0.7911
EPNet pretrain, Epoch [  5/160]: loss 0.6774, auc 0.7879, ap 0.7971
EPNet pretrain, Epoch [  6/160]: loss 0.6748, auc 0.7824, ap 0.8003
EPNet pretrain, Epoch [  7/160]: loss 0.6731, auc 0.7714, ap 0.7988
EPNet pretrain, Epoch [  8/160]: loss 0.6695, auc 0.7608, ap 0.7949
EPNet pretrain, Epoch [  9/160]: loss 0.6647, auc 0.7523, ap 0.7900
EPNet pretrain, Epoch [ 10/160]: loss 0.6605, auc 0.7469, ap 0.7863
EPNet pretrain, Epoch [ 11/160]: loss 0.6559, auc 0.7477, ap 0.7855
EPNet pretrain, Epoch [ 12/160]: loss 0.6496, auc 0.7591, ap 0.7898
EPNet pretrain, Epoch [ 13/160]: loss 0.6439, auc 0.7811, ap 0.8018
EPNet pretrain, Epoch [ 14/160]: loss 0.6383, auc 0.8031, ap 0.8160
EPNet pretrain, Epoch [ 15/160]: loss 0.6315, auc 0.8195, ap 0.8288
EPNet pretrain, Epoch [ 16/160]: loss 0.6243, auc 0.8316, ap 0.8400
EPNet pretrain, Epoch [ 17/160]: loss 0.6173, auc 0.8429, ap 0.8514
EPNet pretrain, Epoch [ 18/160]: loss 0.6106, auc 0.8539, ap 0.8612
EPNet pretrain, Epoch [ 19/160]: loss 0.6048, auc 0.8624, ap 0.8661
EPNet pretrain, Epoch [ 20/160]: loss 0.6002, auc 0.8692, ap 0.8670
EPNet pretrain, Epoch [ 21/160]: loss 0.5955, auc 0.8762, ap 0.8696
EPNet pretrain, Epoch [ 22/160]: loss 0.5914, auc 0.8813, ap 0.8734
EPNet pretrain, Epoch [ 23/160]: loss 0.5881, auc 0.8851, ap 0.8771
EPNet pretrain, Epoch [ 24/160]: loss 0.5849, auc 0.8881, ap 0.8806
EPNet pretrain, Epoch [ 25/160]: loss 0.5816, auc 0.8920, ap 0.8847
EPNet pretrain, Epoch [ 26/160]: loss 0.5785, auc 0.8959, ap 0.8885
EPNet pretrain, Epoch [ 27/160]: loss 0.5752, auc 0.8996, ap 0.8922
EPNet pretrain, Epoch [ 28/160]: loss 0.5715, auc 0.9033, ap 0.8964
EPNet pretrain, Epoch [ 29/160]: loss 0.5680, auc 0.9067, ap 0.8997
EPNet pretrain, Epoch [ 30/160]: loss 0.5648, auc 0.9088, ap 0.9021
EPNet pretrain, Epoch [ 31/160]: loss 0.5616, auc 0.9112, ap 0.9051
EPNet pretrain, Epoch [ 32/160]: loss 0.5581, auc 0.9130, ap 0.9087
EPNet pretrain, Epoch [ 33/160]: loss 0.5549, auc 0.9155, ap 0.9125
EPNet pretrain, Epoch [ 34/160]: loss 0.5520, auc 0.9179, ap 0.9158
EPNet pretrain, Epoch [ 35/160]: loss 0.5491, auc 0.9202, ap 0.9186
EPNet pretrain, Epoch [ 36/160]: loss 0.5460, auc 0.9229, ap 0.9209
EPNet pretrain, Epoch [ 37/160]: loss 0.5429, auc 0.9260, ap 0.9232
EPNet pretrain, Epoch [ 38/160]: loss 0.5402, auc 0.9283, ap 0.9249
EPNet pretrain, Epoch [ 39/160]: loss 0.5378, auc 0.9299, ap 0.9263
EPNet pretrain, Epoch [ 40/160]: loss 0.5354, auc 0.9320, ap 0.9281
EPNet pretrain, Epoch [ 41/160]: loss 0.5333, auc 0.9335, ap 0.9294
EPNet pretrain, Epoch [ 42/160]: loss 0.5313, auc 0.9346, ap 0.9304
EPNet pretrain, Epoch [ 43/160]: loss 0.5293, auc 0.9351, ap 0.9309
EPNet pretrain, Epoch [ 44/160]: loss 0.5275, auc 0.9360, ap 0.9318
EPNet pretrain, Epoch [ 45/160]: loss 0.5258, auc 0.9372, ap 0.9328
EPNet pretrain, Epoch [ 46/160]: loss 0.5243, auc 0.9383, ap 0.9342
EPNet pretrain, Epoch [ 47/160]: loss 0.5228, auc 0.9382, ap 0.9347
EPNet pretrain, Epoch [ 48/160]: loss 0.5214, auc 0.9402, ap 0.9369
EPNet pretrain, Epoch [ 49/160]: loss 0.5201, auc 0.9418, ap 0.9387
EPNet pretrain, Epoch [ 50/160]: loss 0.5189, auc 0.9443, ap 0.9409
EPNet pretrain, Epoch [ 51/160]: loss 0.5178, auc 0.9458, ap 0.9421
EPNet pretrain, Epoch [ 52/160]: loss 0.5168, auc 0.9468, ap 0.9428
EPNet pretrain, Epoch [ 53/160]: loss 0.5158, auc 0.9476, ap 0.9435
EPNet pretrain, Epoch [ 54/160]: loss 0.5146, auc 0.9480, ap 0.9440
EPNet pretrain, Epoch [ 55/160]: loss 0.5133, auc 0.9475, ap 0.9436
EPNet pretrain, Epoch [ 56/160]: loss 0.5122, auc 0.9474, ap 0.9435
EPNet pretrain, Epoch [ 57/160]: loss 0.5110, auc 0.9476, ap 0.9435
EPNet pretrain, Epoch [ 58/160]: loss 0.5099, auc 0.9484, ap 0.9437
EPNet pretrain, Epoch [ 59/160]: loss 0.5088, auc 0.9495, ap 0.9445
EPNet pretrain, Epoch [ 60/160]: loss 0.5077, auc 0.9507, ap 0.9454
EPNet pretrain, Epoch [ 61/160]: loss 0.5065, auc 0.9516, ap 0.9462
EPNet pretrain, Epoch [ 62/160]: loss 0.5055, auc 0.9526, ap 0.9472
EPNet pretrain, Epoch [ 63/160]: loss 0.5046, auc 0.9542, ap 0.9484
EPNet pretrain, Epoch [ 64/160]: loss 0.5037, auc 0.9535, ap 0.9480
EPNet pretrain, Epoch [ 65/160]: loss 0.5028, auc 0.9542, ap 0.9483
EPNet pretrain, Epoch [ 66/160]: loss 0.5019, auc 0.9547, ap 0.9485
EPNet pretrain, Epoch [ 67/160]: loss 0.5010, auc 0.9543, ap 0.9480
EPNet pretrain, Epoch [ 68/160]: loss 0.5002, auc 0.9541, ap 0.9477
EPNet pretrain, Epoch [ 69/160]: loss 0.4993, auc 0.9538, ap 0.9474
EPNet pretrain, Epoch [ 70/160]: loss 0.4984, auc 0.9541, ap 0.9477
EPNet pretrain, Epoch [ 71/160]: loss 0.4976, auc 0.9541, ap 0.9478
EPNet pretrain, Epoch [ 72/160]: loss 0.4967, auc 0.9550, ap 0.9485
EPNet pretrain, Epoch [ 73/160]: loss 0.4959, auc 0.9554, ap 0.9487
EPNet pretrain, Epoch [ 74/160]: loss 0.4950, auc 0.9558, ap 0.9490
EPNet pretrain, Epoch [ 75/160]: loss 0.4942, auc 0.9560, ap 0.9492
EPNet pretrain, Epoch [ 76/160]: loss 0.4934, auc 0.9563, ap 0.9493
EPNet pretrain, Epoch [ 77/160]: loss 0.4927, auc 0.9567, ap 0.9497
EPNet pretrain, Epoch [ 78/160]: loss 0.4919, auc 0.9568, ap 0.9498
EPNet pretrain, Epoch [ 79/160]: loss 0.4912, auc 0.9571, ap 0.9499
EPNet pretrain, Epoch [ 80/160]: loss 0.4905, auc 0.9575, ap 0.9505
EPNet pretrain, Epoch [ 81/160]: loss 0.4899, auc 0.9583, ap 0.9512
EPNet pretrain, Epoch [ 82/160]: loss 0.4892, auc 0.9586, ap 0.9516
EPNet pretrain, Epoch [ 83/160]: loss 0.4885, auc 0.9589, ap 0.9521
EPNet pretrain, Epoch [ 84/160]: loss 0.4879, auc 0.9592, ap 0.9526
EPNet pretrain, Epoch [ 85/160]: loss 0.4872, auc 0.9594, ap 0.9529
EPNet pretrain, Epoch [ 86/160]: loss 0.4865, auc 0.9597, ap 0.9534
EPNet pretrain, Epoch [ 87/160]: loss 0.4859, auc 0.9611, ap 0.9547
EPNet pretrain, Epoch [ 88/160]: loss 0.4852, auc 0.9614, ap 0.9552
EPNet pretrain, Epoch [ 89/160]: loss 0.4845, auc 0.9616, ap 0.9556
EPNet pretrain, Epoch [ 90/160]: loss 0.4838, auc 0.9606, ap 0.9549
EPNet pretrain, Epoch [ 91/160]: loss 0.4831, auc 0.9620, ap 0.9560
EPNet pretrain, Epoch [ 92/160]: loss 0.4824, auc 0.9623, ap 0.9562
EPNet pretrain, Epoch [ 93/160]: loss 0.4816, auc 0.9620, ap 0.9560
EPNet pretrain, Epoch [ 94/160]: loss 0.4809, auc 0.9622, ap 0.9562
EPNet pretrain, Epoch [ 95/160]: loss 0.4802, auc 0.9625, ap 0.9564
EPNet pretrain, Epoch [ 96/160]: loss 0.4794, auc 0.9628, ap 0.9567
EPNet pretrain, Epoch [ 97/160]: loss 0.4787, auc 0.9631, ap 0.9569
EPNet pretrain, Epoch [ 98/160]: loss 0.4780, auc 0.9639, ap 0.9576
EPNet pretrain, Epoch [ 99/160]: loss 0.4773, auc 0.9641, ap 0.9577
EPNet pretrain, Epoch [100/160]: loss 0.4766, auc 0.9642, ap 0.9578
EPNet pretrain, Epoch [101/160]: loss 0.4760, auc 0.9644, ap 0.9579
EPNet pretrain, Epoch [102/160]: loss 0.4754, auc 0.9646, ap 0.9579
EPNet pretrain, Epoch [103/160]: loss 0.4749, auc 0.9648, ap 0.9580
EPNet pretrain, Epoch [104/160]: loss 0.4743, auc 0.9649, ap 0.9579
EPNet pretrain, Epoch [105/160]: loss 0.4738, auc 0.9649, ap 0.9578
EPNet pretrain, Epoch [106/160]: loss 0.4733, auc 0.9650, ap 0.9578
EPNet pretrain, Epoch [107/160]: loss 0.4728, auc 0.9646, ap 0.9573
EPNet pretrain, Epoch [108/160]: loss 0.4724, auc 0.9647, ap 0.9574
EPNet pretrain, Epoch [109/160]: loss 0.4719, auc 0.9649, ap 0.9576
EPNet pretrain, Epoch [110/160]: loss 0.4714, auc 0.9644, ap 0.9572
EPNet pretrain, Epoch [111/160]: loss 0.4710, auc 0.9645, ap 0.9572
EPNet pretrain, Epoch [112/160]: loss 0.4705, auc 0.9646, ap 0.9573
EPNet pretrain, Epoch [113/160]: loss 0.4701, auc 0.9659, ap 0.9585
EPNet pretrain, Epoch [114/160]: loss 0.4697, auc 0.9661, ap 0.9587
EPNet pretrain, Epoch [115/160]: loss 0.4693, auc 0.9663, ap 0.9591
EPNet pretrain, Epoch [116/160]: loss 0.4688, auc 0.9665, ap 0.9593
EPNet pretrain, Epoch [117/160]: loss 0.4684, auc 0.9662, ap 0.9591
EPNet pretrain, Epoch [118/160]: loss 0.4680, auc 0.9664, ap 0.9593
EPNet pretrain, Epoch [119/160]: loss 0.4676, auc 0.9671, ap 0.9599
EPNet pretrain, Epoch [120/160]: loss 0.4672, auc 0.9667, ap 0.9598
EPNet pretrain, Epoch [121/160]: loss 0.4668, auc 0.9669, ap 0.9600
EPNet pretrain, Epoch [122/160]: loss 0.4664, auc 0.9670, ap 0.9602
EPNet pretrain, Epoch [123/160]: loss 0.4661, auc 0.9672, ap 0.9604
EPNet pretrain, Epoch [124/160]: loss 0.4657, auc 0.9673, ap 0.9604
EPNet pretrain, Epoch [125/160]: loss 0.4653, auc 0.9675, ap 0.9607
EPNet pretrain, Epoch [126/160]: loss 0.4650, auc 0.9676, ap 0.9610
EPNet pretrain, Epoch [127/160]: loss 0.4646, auc 0.9678, ap 0.9611
EPNet pretrain, Epoch [128/160]: loss 0.4643, auc 0.9679, ap 0.9611
EPNet pretrain, Epoch [129/160]: loss 0.4639, auc 0.9679, ap 0.9612
EPNet pretrain, Epoch [130/160]: loss 0.4636, auc 0.9686, ap 0.9618
EPNet pretrain, Epoch [131/160]: loss 0.4632, auc 0.9694, ap 0.9624
EPNet pretrain, Epoch [132/160]: loss 0.4628, auc 0.9696, ap 0.9627
EPNet pretrain, Epoch [133/160]: loss 0.4625, auc 0.9703, ap 0.9633
EPNet pretrain, Epoch [134/160]: loss 0.4621, auc 0.9699, ap 0.9631
EPNet pretrain, Epoch [135/160]: loss 0.4618, auc 0.9700, ap 0.9633
EPNet pretrain, Epoch [136/160]: loss 0.4614, auc 0.9703, ap 0.9635
EPNet pretrain, Epoch [137/160]: loss 0.4611, auc 0.9704, ap 0.9637
EPNet pretrain, Epoch [138/160]: loss 0.4607, auc 0.9700, ap 0.9634
EPNet pretrain, Epoch [139/160]: loss 0.4603, auc 0.9707, ap 0.9640
EPNet pretrain, Epoch [140/160]: loss 0.4600, auc 0.9703, ap 0.9638
EPNet pretrain, Epoch [141/160]: loss 0.4596, auc 0.9705, ap 0.9639
EPNet pretrain, Epoch [142/160]: loss 0.4593, auc 0.9706, ap 0.9641
EPNet pretrain, Epoch [143/160]: loss 0.4589, auc 0.9708, ap 0.9644
EPNet pretrain, Epoch [144/160]: loss 0.4586, auc 0.9710, ap 0.9646
EPNet pretrain, Epoch [145/160]: loss 0.4582, auc 0.9711, ap 0.9647
EPNet pretrain, Epoch [146/160]: loss 0.4579, auc 0.9713, ap 0.9649
EPNet pretrain, Epoch [147/160]: loss 0.4576, auc 0.9715, ap 0.9651
EPNet pretrain, Epoch [148/160]: loss 0.4572, auc 0.9716, ap 0.9652
EPNet pretrain, Epoch [149/160]: loss 0.4569, auc 0.9723, ap 0.9659
EPNet pretrain, Epoch [150/160]: loss 0.4565, auc 0.9725, ap 0.9660
EPNet pretrain, Epoch [151/160]: loss 0.4562, auc 0.9726, ap 0.9661
EPNet pretrain, Epoch [152/160]: loss 0.4558, auc 0.9727, ap 0.9663
EPNet pretrain, Epoch [153/160]: loss 0.4554, auc 0.9728, ap 0.9663
EPNet pretrain, Epoch [154/160]: loss 0.4550, auc 0.9729, ap 0.9665
EPNet pretrain, Epoch [155/160]: loss 0.4546, auc 0.9730, ap 0.9666
EPNet pretrain, Epoch [156/160]: loss 0.4542, auc 0.9730, ap 0.9666
EPNet pretrain, Epoch [157/160]: loss 0.4538, auc 0.9731, ap 0.9667
EPNet pretrain, Epoch [158/160]: loss 0.4534, auc 0.9732, ap 0.9668
EPNet pretrain, Epoch [159/160]: loss 0.4531, auc 0.9732, ap 0.9668
EPNet pretrain, Epoch [160/160]: loss 0.4527, auc 0.9732, ap 0.9667
NCNet pretrain, Epoch [ 1/30]: loss 1.9455, val acc 0.3860, test acc 0.4120
NCNet pretrain, Epoch [ 2/30]: loss 1.9264, val acc 0.3620
NCNet pretrain, Epoch [ 3/30]: loss 1.9058, val acc 0.4180, test acc 0.4280
NCNet pretrain, Epoch [ 4/30]: loss 1.8780, val acc 0.4800, test acc 0.4940
NCNet pretrain, Epoch [ 5/30]: loss 1.8481, val acc 0.5100, test acc 0.5550
NCNet pretrain, Epoch [ 6/30]: loss 1.8174, val acc 0.5560, test acc 0.5930
NCNet pretrain, Epoch [ 7/30]: loss 1.7780, val acc 0.6060, test acc 0.6470
NCNet pretrain, Epoch [ 8/30]: loss 1.7420, val acc 0.6320, test acc 0.6680
NCNet pretrain, Epoch [ 9/30]: loss 1.6968, val acc 0.6560, test acc 0.6770
NCNet pretrain, Epoch [10/30]: loss 1.6541, val acc 0.6680, test acc 0.6800
NCNet pretrain, Epoch [11/30]: loss 1.6019, val acc 0.6840, test acc 0.6920
NCNet pretrain, Epoch [12/30]: loss 1.5597, val acc 0.6940, test acc 0.7070
NCNet pretrain, Epoch [13/30]: loss 1.4987, val acc 0.7060, test acc 0.7280
NCNet pretrain, Epoch [14/30]: loss 1.4432, val acc 0.7300, test acc 0.7500
NCNet pretrain, Epoch [15/30]: loss 1.3878, val acc 0.7420, test acc 0.7660
NCNet pretrain, Epoch [16/30]: loss 1.3263, val acc 0.7560, test acc 0.7790
NCNet pretrain, Epoch [17/30]: loss 1.2722, val acc 0.7700, test acc 0.7930
NCNet pretrain, Epoch [18/30]: loss 1.2252, val acc 0.7720, test acc 0.7940
NCNet pretrain, Epoch [19/30]: loss 1.1563, val acc 0.7820, test acc 0.8000
NCNet pretrain, Epoch [20/30]: loss 1.1036, val acc 0.7860, test acc 0.8010
NCNet pretrain, Epoch [21/30]: loss 1.0316, val acc 0.7860
NCNet pretrain, Epoch [22/30]: loss 0.9804, val acc 0.7920, test acc 0.8060
NCNet pretrain, Epoch [23/30]: loss 0.9532, val acc 0.7940, test acc 0.8070
NCNet pretrain, Epoch [24/30]: loss 0.9011, val acc 0.7980, test acc 0.8080
NCNet pretrain, Epoch [25/30]: loss 0.8418, val acc 0.7960
NCNet pretrain, Epoch [26/30]: loss 0.8000, val acc 0.7960
NCNet pretrain, Epoch [27/30]: loss 0.7355, val acc 0.8020, test acc 0.8130
NCNet pretrain, Epoch [28/30]: loss 0.6983, val acc 0.8080, test acc 0.8150
NCNet pretrain, Epoch [29/30]: loss 0.6598, val acc 0.8080
NCNet pretrain, Epoch [30/30]: loss 0.6178, val acc 0.8020
difference tensor(0.3553, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4523, nc loss 1.4362, ep auc: 0.9732, ep ap 0.9667, val acc 0.7480, test acc 0.7720
difference tensor(0.4974, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4650, nc loss 1.3151, ep auc: 0.9683, ep ap 0.9618, val acc 0.7360, test acc 0.7720
difference tensor(0.4785, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.4935, nc loss 1.2269, ep auc: 0.9548, ep ap 0.9466, val acc 0.7660, test acc 0.7880
difference tensor(0.8732, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5294, nc loss 1.1129, ep auc: 0.9352, ep ap 0.9252, val acc 0.7900, test acc 0.8130
difference tensor(0.6986, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5675, nc loss 1.1092, ep auc: 0.9174, ep ap 0.9050, val acc 0.8060, test acc 0.8230
difference tensor(1.0425, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.5973, nc loss 1.0581, ep auc: 0.8855, ep ap 0.8729, val acc 0.8080, test acc 0.8260
difference tensor(1.3945, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.6187, nc loss 1.0349, ep auc: 0.8449, ep ap 0.8341, val acc 0.8140, test acc 0.8260
difference tensor(1.3070, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.6305, nc loss 0.9751, ep auc: 0.8140, ep ap 0.8045, val acc 0.8180, test acc 0.8290
difference tensor(1.6973, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6370, nc loss 0.9267, ep auc: 0.7892, ep ap 0.7810, val acc 0.8220, test acc 0.8290
difference tensor(1.6291, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6417, nc loss 0.9208, ep auc: 0.7694, ep ap 0.7622, val acc 0.8160, test acc 0.8290
difference tensor(1.3296, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6437, nc loss 0.8874, ep auc: 0.7579, ep ap 0.7511, val acc 0.8120, test acc 0.8290
difference tensor(1.5256, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6434, nc loss 0.8366, ep auc: 0.7558, ep ap 0.7494, val acc 0.8040, test acc 0.8290
difference tensor(1.8863, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6422, nc loss 0.8251, ep auc: 0.7466, ep ap 0.7402, val acc 0.7980, test acc 0.8290
difference tensor(1.3179, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6415, nc loss 0.8371, ep auc: 0.7352, ep ap 0.7310, val acc 0.7900, test acc 0.8290
difference tensor(2.9493, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6409, nc loss 0.8094, ep auc: 0.7301, ep ap 0.7266, val acc 0.7860, test acc 0.8290
difference tensor(2.6384, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6410, nc loss 0.7615, ep auc: 0.7181, ep ap 0.7157, val acc 0.7860, test acc 0.8290
difference tensor(1.1893, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6416, nc loss 0.7344, ep auc: 0.7123, ep ap 0.7100, val acc 0.7840, test acc 0.8290
difference tensor(1.3222, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6440, nc loss 0.7261, ep auc: 0.7046, ep ap 0.7037, val acc 0.7920, test acc 0.8290
difference tensor(1.6713, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6465, nc loss 0.7096, ep auc: 0.7016, ep ap 0.7011, val acc 0.7900, test acc 0.8290
difference tensor(1.7256, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6497, nc loss 0.7158, ep auc: 0.6942, ep ap 0.6946, val acc 0.7900, test acc 0.8290
difference tensor(5.5357, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6514, nc loss 0.7140, ep auc: 0.6909, ep ap 0.6915, val acc 0.7920, test acc 0.8290
difference tensor(2.3395, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6524, nc loss 0.7314, ep auc: 0.6801, ep ap 0.6824, val acc 0.7980, test acc 0.8290
difference tensor(1.9581, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6534, nc loss 0.7135, ep auc: 0.6794, ep ap 0.6818, val acc 0.8000, test acc 0.8290
difference tensor(2.7846, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6550, nc loss 0.7045, ep auc: 0.6731, ep ap 0.6761, val acc 0.8000, test acc 0.8290
difference tensor(1.9147, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6564, nc loss 0.7031, ep auc: 0.6718, ep ap 0.6741, val acc 0.7960, test acc 0.8290
difference tensor(3.2540, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6574, nc loss 0.6907, ep auc: 0.6715, ep ap 0.6732, val acc 0.7920, test acc 0.8290
difference tensor(2.7438, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6585, nc loss 0.6868, ep auc: 0.6706, ep ap 0.6723, val acc 0.7840, test acc 0.8290
difference tensor(3.6966, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6601, nc loss 0.6901, ep auc: 0.6669, ep ap 0.6690, val acc 0.7800, test acc 0.8290
difference tensor(1.9696, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6612, nc loss 0.7041, ep auc: 0.6661, ep ap 0.6683, val acc 0.7780, test acc 0.8290
difference tensor(3.4124, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6611, nc loss 0.6915, ep auc: 0.6654, ep ap 0.6677, val acc 0.7760, test acc 0.8290
difference tensor(5.1667, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6608, nc loss 0.6875, ep auc: 0.6639, ep ap 0.6664, val acc 0.7700, test acc 0.8290
difference tensor(2.2245, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6589, nc loss 0.6796, ep auc: 0.6608, ep ap 0.6634, val acc 0.7700, test acc 0.8290
difference tensor(6.0655, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6570, nc loss 0.6662, ep auc: 0.6590, ep ap 0.6613, val acc 0.7760, test acc 0.8290
difference tensor(2.3102, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6553, nc loss 0.6537, ep auc: 0.6578, ep ap 0.6595, val acc 0.7800, test acc 0.8290
difference tensor(3.7564, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6538, nc loss 0.6794, ep auc: 0.6555, ep ap 0.6574, val acc 0.7840, test acc 0.8290
difference tensor(1.7081, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6530, nc loss 0.6571, ep auc: 0.6557, ep ap 0.6578, val acc 0.7860, test acc 0.8290
difference tensor(1.3292, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6525, nc loss 0.6549, ep auc: 0.6549, ep ap 0.6568, val acc 0.7800, test acc 0.8290
difference tensor(1.8747, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6524, nc loss 0.6686, ep auc: 0.6542, ep ap 0.6561, val acc 0.7760, test acc 0.8290
difference tensor(1.9766, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6528, nc loss 0.6588, ep auc: 0.6534, ep ap 0.6554, val acc 0.7720, test acc 0.8290
difference tensor(1.5170, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6531, nc loss 0.6673, ep auc: 0.6546, ep ap 0.6560, val acc 0.7680, test acc 0.8290
difference tensor(1.7245, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6538, nc loss 0.6686, ep auc: 0.6561, ep ap 0.6572, val acc 0.7680, test acc 0.8290
difference tensor(1.5715, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6547, nc loss 0.6626, ep auc: 0.6573, ep ap 0.6579, val acc 0.7700, test acc 0.8290
difference tensor(1.8762, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6557, nc loss 0.6666, ep auc: 0.6591, ep ap 0.6599, val acc 0.7680, test acc 0.8290
difference tensor(1.7093, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6567, nc loss 0.6752, ep auc: 0.6594, ep ap 0.6608, val acc 0.7720, test acc 0.8290
difference tensor(1.7913, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6579, nc loss 0.6506, ep auc: 0.6586, ep ap 0.6602, val acc 0.7700, test acc 0.8290
difference tensor(2.4264, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6588, nc loss 0.6478, ep auc: 0.6579, ep ap 0.6598, val acc 0.7740, test acc 0.8290
difference tensor(1.9913, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 47/200]: ep loss 0.6600, nc loss 0.6632, ep auc: 0.6564, ep ap 0.6584, val acc 0.7720, test acc 0.8290
difference tensor(3.0617, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 48/200]: ep loss 0.6612, nc loss 0.6670, ep auc: 0.6564, ep ap 0.6584, val acc 0.7740, test acc 0.8290
difference tensor(1.9258, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 49/200]: ep loss 0.6614, nc loss 0.6567, ep auc: 0.6565, ep ap 0.6586, val acc 0.7740, test acc 0.8290
difference tensor(4.0769, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 50/200]: ep loss 0.6614, nc loss 0.6626, ep auc: 0.6575, ep ap 0.6585, val acc 0.7760, test acc 0.8290
difference tensor(1.8364, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 51/200]: ep loss 0.6605, nc loss 0.6602, ep auc: 0.6568, ep ap 0.6579, val acc 0.7740, test acc 0.8290
difference tensor(2.2456, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 52/200]: ep loss 0.6593, nc loss 0.6566, ep auc: 0.6568, ep ap 0.6579, val acc 0.7740, test acc 0.8290
difference tensor(1.9481, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 53/200]: ep loss 0.6576, nc loss 0.6567, ep auc: 0.6583, ep ap 0.6593, val acc 0.7600, test acc 0.8290
difference tensor(1.8929, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 54/200]: ep loss 0.6564, nc loss 0.6521, ep auc: 0.6583, ep ap 0.6595, val acc 0.7600, test acc 0.8290
difference tensor(1.3409, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 55/200]: ep loss 0.6548, nc loss 0.6585, ep auc: 0.6560, ep ap 0.6572, val acc 0.7620, test acc 0.8290
difference tensor(3.1186, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 56/200]: ep loss 0.6534, nc loss 0.6356, ep auc: 0.6557, ep ap 0.6564, val acc 0.7660, test acc 0.8290
difference tensor(1.7741, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 57/200]: ep loss 0.6518, nc loss 0.6439, ep auc: 0.6550, ep ap 0.6558, val acc 0.7700, test acc 0.8290
difference tensor(1.1956, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 58/200]: ep loss 0.6499, nc loss 0.6501, ep auc: 0.6536, ep ap 0.6546, val acc 0.7780, test acc 0.8290
difference tensor(1.8767, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 59/200]: ep loss 0.6481, nc loss 0.6396, ep auc: 0.6561, ep ap 0.6559, val acc 0.7740, test acc 0.8290
difference tensor(3.6086, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 60/200]: ep loss 0.6463, nc loss 0.6354, ep auc: 0.6568, ep ap 0.6565, val acc 0.7700, test acc 0.8290
difference tensor(1.3800, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 61/200]: ep loss 0.6453, nc loss 0.6280, ep auc: 0.6552, ep ap 0.6545, val acc 0.7620, test acc 0.8290
difference tensor(2.2475, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 62/200]: ep loss 0.6450, nc loss 0.6263, ep auc: 0.6520, ep ap 0.6510, val acc 0.7700, test acc 0.8290
difference tensor(2.2928, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 63/200]: ep loss 0.6452, nc loss 0.6175, ep auc: 0.6498, ep ap 0.6489, val acc 0.7700, test acc 0.8290
difference tensor(1.4400, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 64/200]: ep loss 0.6457, nc loss 0.6296, ep auc: 0.6505, ep ap 0.6493, val acc 0.7660, test acc 0.8290
difference tensor(1.3581, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 65/200]: ep loss 0.6466, nc loss 0.6275, ep auc: 0.6522, ep ap 0.6513, val acc 0.7660, test acc 0.8290
difference tensor(1.3599, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 66/200]: ep loss 0.6477, nc loss 0.6305, ep auc: 0.6536, ep ap 0.6526, val acc 0.7540, test acc 0.8290
difference tensor(1.0564, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 67/200]: ep loss 0.6489, nc loss 0.6262, ep auc: 0.6520, ep ap 0.6524, val acc 0.7520, test acc 0.8290
difference tensor(1.9916, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 68/200]: ep loss 0.6504, nc loss 0.6225, ep auc: 0.6512, ep ap 0.6518, val acc 0.7540, test acc 0.8290
difference tensor(1.8327, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 69/200]: ep loss 0.6521, nc loss 0.6535, ep auc: 0.6514, ep ap 0.6524, val acc 0.7660, test acc 0.8290
difference tensor(1.3446, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 70/200]: ep loss 0.6536, nc loss 0.6244, ep auc: 0.6531, ep ap 0.6543, val acc 0.7700, test acc 0.8290
difference tensor(1.4483, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 71/200]: ep loss 0.6551, nc loss 0.6314, ep auc: 0.6543, ep ap 0.6551, val acc 0.7680, test acc 0.8290
difference tensor(1.5419, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 72/200]: ep loss 0.6560, nc loss 0.6296, ep auc: 0.6539, ep ap 0.6552, val acc 0.7580, test acc 0.8290
difference tensor(1.7846, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 73/200]: ep loss 0.6567, nc loss 0.6321, ep auc: 0.6546, ep ap 0.6560, val acc 0.7520, test acc 0.8290
difference tensor(2.8656, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 74/200]: ep loss 0.6573, nc loss 0.6362, ep auc: 0.6536, ep ap 0.6560, val acc 0.7620, test acc 0.8290
difference tensor(2.3096, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 75/200]: ep loss 0.6576, nc loss 0.6206, ep auc: 0.6543, ep ap 0.6566, val acc 0.7640, test acc 0.8290
difference tensor(4.7743, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 76/200]: ep loss 0.6576, nc loss 0.6264, ep auc: 0.6558, ep ap 0.6578, val acc 0.7620, test acc 0.8290
difference tensor(1.5286, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 77/200]: ep loss 0.6574, nc loss 0.6300, ep auc: 0.6558, ep ap 0.6579, val acc 0.7660, test acc 0.8290
difference tensor(1.6790, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 78/200]: ep loss 0.6570, nc loss 0.6298, ep auc: 0.6558, ep ap 0.6581, val acc 0.7640, test acc 0.8290
difference tensor(1.8792, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 79/200]: ep loss 0.6564, nc loss 0.6313, ep auc: 0.6559, ep ap 0.6582, val acc 0.7620, test acc 0.8290
difference tensor(2.3933, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 80/200]: ep loss 0.6557, nc loss 0.6348, ep auc: 0.6574, ep ap 0.6595, val acc 0.7720, test acc 0.8290
difference tensor(1.3614, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 81/200]: ep loss 0.6546, nc loss 0.6255, ep auc: 0.6579, ep ap 0.6596, val acc 0.7740, test acc 0.8290
difference tensor(1.6240, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 82/200]: ep loss 0.6535, nc loss 0.6264, ep auc: 0.6594, ep ap 0.6609, val acc 0.7740, test acc 0.8290
difference tensor(1.2329, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 83/200]: ep loss 0.6524, nc loss 0.6185, ep auc: 0.6596, ep ap 0.6614, val acc 0.7740, test acc 0.8290
difference tensor(1.8947, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 84/200]: ep loss 0.6513, nc loss 0.6128, ep auc: 0.6609, ep ap 0.6620, val acc 0.7720, test acc 0.8290
difference tensor(1.3841, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 85/200]: ep loss 0.6505, nc loss 0.6023, ep auc: 0.6606, ep ap 0.6613, val acc 0.7760, test acc 0.8290
difference tensor(1.7534, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 86/200]: ep loss 0.6502, nc loss 0.6076, ep auc: 0.6584, ep ap 0.6594, val acc 0.7680, test acc 0.8290
difference tensor(1.4504, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 87/200]: ep loss 0.6502, nc loss 0.6205, ep auc: 0.6570, ep ap 0.6581, val acc 0.7720, test acc 0.8290
difference tensor(1.6485, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 88/200]: ep loss 0.6505, nc loss 0.6155, ep auc: 0.6570, ep ap 0.6580, val acc 0.7680, test acc 0.8290
difference tensor(1.4034, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 89/200]: ep loss 0.6510, nc loss 0.6229, ep auc: 0.6567, ep ap 0.6574, val acc 0.7660, test acc 0.8290
difference tensor(1.6058, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 90/200]: ep loss 0.6512, nc loss 0.6215, ep auc: 0.6567, ep ap 0.6574, val acc 0.7600, test acc 0.8290
difference tensor(1.3989, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 91/200]: ep loss 0.6513, nc loss 0.6135, ep auc: 0.6552, ep ap 0.6562, val acc 0.7580, test acc 0.8290
difference tensor(2.1898, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 92/200]: ep loss 0.6514, nc loss 0.6266, ep auc: 0.6560, ep ap 0.6569, val acc 0.7560, test acc 0.8290
difference tensor(1.2803, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 93/200]: ep loss 0.6514, nc loss 0.6221, ep auc: 0.6567, ep ap 0.6576, val acc 0.7700, test acc 0.8290
difference tensor(2.7735, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 94/200]: ep loss 0.6517, nc loss 0.6174, ep auc: 0.6570, ep ap 0.6584, val acc 0.7720, test acc 0.8290
difference tensor(1.5947, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 95/200]: ep loss 0.6522, nc loss 0.6268, ep auc: 0.6577, ep ap 0.6591, val acc 0.7660, test acc 0.8290
difference tensor(1.4537, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 96/200]: ep loss 0.6527, nc loss 0.6166, ep auc: 0.6577, ep ap 0.6591, val acc 0.7740, test acc 0.8290
difference tensor(1.8682, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 97/200]: ep loss 0.6536, nc loss 0.6255, ep auc: 0.6577, ep ap 0.6592, val acc 0.7620, test acc 0.8290
difference tensor(1.9509, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 98/200]: ep loss 0.6531, nc loss 0.6249, ep auc: 0.6577, ep ap 0.6589, val acc 0.7640, test acc 0.8290
difference tensor(1.4562, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 99/200]: ep loss 0.6532, nc loss 0.6230, ep auc: 0.6572, ep ap 0.6574, val acc 0.7640, test acc 0.8290
difference tensor(4.1388, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [100/200]: ep loss 0.6522, nc loss 0.6243, ep auc: 0.6572, ep ap 0.6574, val acc 0.7560, test acc 0.8290
difference tensor(2.3822, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [101/200]: ep loss 0.6516, nc loss 0.6132, ep auc: 0.6569, ep ap 0.6566, val acc 0.7620, test acc 0.8290
difference tensor(1.5402, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [102/200]: ep loss 0.6507, nc loss 0.6067, ep auc: 0.6562, ep ap 0.6561, val acc 0.7520, test acc 0.8290
difference tensor(1.2188, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [103/200]: ep loss 0.6502, nc loss 0.6094, ep auc: 0.6550, ep ap 0.6555, val acc 0.7560, test acc 0.8290
difference tensor(4.8960, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [104/200]: ep loss 0.6497, nc loss 0.6175, ep auc: 0.6550, ep ap 0.6555, val acc 0.7520, test acc 0.8290
difference tensor(1.7184, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [105/200]: ep loss 0.6493, nc loss 0.6106, ep auc: 0.6549, ep ap 0.6555, val acc 0.7580, test acc 0.8290
difference tensor(1.4600, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [106/200]: ep loss 0.6492, nc loss 0.6028, ep auc: 0.6549, ep ap 0.6554, val acc 0.7680, test acc 0.8290
difference tensor(1.4330, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [107/200]: ep loss 0.6494, nc loss 0.5994, ep auc: 0.6549, ep ap 0.6554, val acc 0.7720, test acc 0.8290
difference tensor(1.1656, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [108/200]: ep loss 0.6496, nc loss 0.6041, ep auc: 0.6549, ep ap 0.6554, val acc 0.7640, test acc 0.8290
Early stop!
Final test acc with early stop: 0.8290, without early stop: 0.7840
Micro F1: 0.835500, std: 0.006500, Max is 0.842000, min is 0.829000
Big Epoch 1/30 dataset is cora fid_frac is 0.1
Big Epoch 2/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8456, ap 0.8262
EPNet pretrain, Epoch [  2/160]: loss 0.6914, auc 0.8206, ap 0.8034
EPNet pretrain, Epoch [  3/160]: loss 0.6858, auc 0.7952, ap 0.7795
EPNet pretrain, Epoch [  4/160]: loss 0.6786, auc 0.7839, ap 0.7703
EPNet pretrain, Epoch [  5/160]: loss 0.6877, auc 0.7812, ap 0.7722
EPNet pretrain, Epoch [  6/160]: loss 0.6753, auc 0.7911, ap 0.7834
EPNet pretrain, Epoch [  7/160]: loss 0.6739, auc 0.8075, ap 0.8022
EPNet pretrain, Epoch [  8/160]: loss 0.6745, auc 0.8233, ap 0.8215
EPNet pretrain, Epoch [  9/160]: loss 0.6731, auc 0.8312, ap 0.8321
EPNet pretrain, Epoch [ 10/160]: loss 0.6693, auc 0.8301, ap 0.8333
EPNet pretrain, Epoch [ 11/160]: loss 0.6631, auc 0.8234, ap 0.8284
EPNet pretrain, Epoch [ 12/160]: loss 0.6557, auc 0.8134, ap 0.8203
EPNet pretrain, Epoch [ 13/160]: loss 0.6496, auc 0.8051, ap 0.8138
EPNet pretrain, Epoch [ 14/160]: loss 0.6460, auc 0.8052, ap 0.8139
EPNet pretrain, Epoch [ 15/160]: loss 0.6399, auc 0.8191, ap 0.8253
EPNet pretrain, Epoch [ 16/160]: loss 0.6304, auc 0.8423, ap 0.8449
EPNet pretrain, Epoch [ 17/160]: loss 0.6213, auc 0.8640, ap 0.8645
EPNet pretrain, Epoch [ 18/160]: loss 0.6137, auc 0.8781, ap 0.8768
EPNet pretrain, Epoch [ 19/160]: loss 0.6071, auc 0.8838, ap 0.8800
EPNet pretrain, Epoch [ 20/160]: loss 0.6011, auc 0.8856, ap 0.8790
EPNet pretrain, Epoch [ 21/160]: loss 0.5959, auc 0.8861, ap 0.8774
EPNet pretrain, Epoch [ 22/160]: loss 0.5916, auc 0.8865, ap 0.8770
EPNet pretrain, Epoch [ 23/160]: loss 0.5881, auc 0.8875, ap 0.8778
EPNet pretrain, Epoch [ 24/160]: loss 0.5851, auc 0.8889, ap 0.8789
EPNet pretrain, Epoch [ 25/160]: loss 0.5823, auc 0.8909, ap 0.8800
EPNet pretrain, Epoch [ 26/160]: loss 0.5791, auc 0.8942, ap 0.8826
EPNet pretrain, Epoch [ 27/160]: loss 0.5752, auc 0.8985, ap 0.8867
EPNet pretrain, Epoch [ 28/160]: loss 0.5711, auc 0.9038, ap 0.8928
EPNet pretrain, Epoch [ 29/160]: loss 0.5672, auc 0.9082, ap 0.8978
EPNet pretrain, Epoch [ 30/160]: loss 0.5640, auc 0.9119, ap 0.9015
EPNet pretrain, Epoch [ 31/160]: loss 0.5613, auc 0.9148, ap 0.9045
EPNet pretrain, Epoch [ 32/160]: loss 0.5585, auc 0.9171, ap 0.9065
EPNet pretrain, Epoch [ 33/160]: loss 0.5552, auc 0.9188, ap 0.9076
EPNet pretrain, Epoch [ 34/160]: loss 0.5516, auc 0.9210, ap 0.9089
EPNet pretrain, Epoch [ 35/160]: loss 0.5482, auc 0.9228, ap 0.9098
EPNet pretrain, Epoch [ 36/160]: loss 0.5454, auc 0.9243, ap 0.9104
EPNet pretrain, Epoch [ 37/160]: loss 0.5431, auc 0.9251, ap 0.9106
EPNet pretrain, Epoch [ 38/160]: loss 0.5411, auc 0.9265, ap 0.9116
EPNet pretrain, Epoch [ 39/160]: loss 0.5391, auc 0.9283, ap 0.9134
EPNet pretrain, Epoch [ 40/160]: loss 0.5370, auc 0.9305, ap 0.9157
EPNet pretrain, Epoch [ 41/160]: loss 0.5348, auc 0.9319, ap 0.9175
EPNet pretrain, Epoch [ 42/160]: loss 0.5329, auc 0.9327, ap 0.9187
EPNet pretrain, Epoch [ 43/160]: loss 0.5312, auc 0.9334, ap 0.9200
EPNet pretrain, Epoch [ 44/160]: loss 0.5295, auc 0.9338, ap 0.9207
EPNet pretrain, Epoch [ 45/160]: loss 0.5279, auc 0.9343, ap 0.9212
EPNet pretrain, Epoch [ 46/160]: loss 0.5262, auc 0.9342, ap 0.9209
EPNet pretrain, Epoch [ 47/160]: loss 0.5245, auc 0.9350, ap 0.9214
EPNet pretrain, Epoch [ 48/160]: loss 0.5230, auc 0.9363, ap 0.9223
EPNet pretrain, Epoch [ 49/160]: loss 0.5216, auc 0.9370, ap 0.9227
EPNet pretrain, Epoch [ 50/160]: loss 0.5203, auc 0.9372, ap 0.9228
EPNet pretrain, Epoch [ 51/160]: loss 0.5191, auc 0.9382, ap 0.9234
EPNet pretrain, Epoch [ 52/160]: loss 0.5179, auc 0.9386, ap 0.9239
EPNet pretrain, Epoch [ 53/160]: loss 0.5167, auc 0.9389, ap 0.9242
EPNet pretrain, Epoch [ 54/160]: loss 0.5157, auc 0.9415, ap 0.9263
EPNet pretrain, Epoch [ 55/160]: loss 0.5148, auc 0.9429, ap 0.9275
EPNet pretrain, Epoch [ 56/160]: loss 0.5140, auc 0.9432, ap 0.9280
EPNet pretrain, Epoch [ 57/160]: loss 0.5132, auc 0.9442, ap 0.9288
EPNet pretrain, Epoch [ 58/160]: loss 0.5125, auc 0.9448, ap 0.9294
EPNet pretrain, Epoch [ 59/160]: loss 0.5118, auc 0.9451, ap 0.9296
EPNet pretrain, Epoch [ 60/160]: loss 0.5111, auc 0.9456, ap 0.9301
EPNet pretrain, Epoch [ 61/160]: loss 0.5104, auc 0.9461, ap 0.9304
EPNet pretrain, Epoch [ 62/160]: loss 0.5097, auc 0.9465, ap 0.9306
EPNet pretrain, Epoch [ 63/160]: loss 0.5089, auc 0.9468, ap 0.9308
EPNet pretrain, Epoch [ 64/160]: loss 0.5082, auc 0.9471, ap 0.9312
EPNet pretrain, Epoch [ 65/160]: loss 0.5075, auc 0.9475, ap 0.9317
EPNet pretrain, Epoch [ 66/160]: loss 0.5068, auc 0.9479, ap 0.9321
EPNet pretrain, Epoch [ 67/160]: loss 0.5061, auc 0.9483, ap 0.9328
EPNet pretrain, Epoch [ 68/160]: loss 0.5053, auc 0.9488, ap 0.9336
EPNet pretrain, Epoch [ 69/160]: loss 0.5046, auc 0.9493, ap 0.9342
EPNet pretrain, Epoch [ 70/160]: loss 0.5039, auc 0.9498, ap 0.9347
EPNet pretrain, Epoch [ 71/160]: loss 0.5031, auc 0.9505, ap 0.9355
EPNet pretrain, Epoch [ 72/160]: loss 0.5023, auc 0.9526, ap 0.9372
EPNet pretrain, Epoch [ 73/160]: loss 0.5016, auc 0.9532, ap 0.9379
EPNet pretrain, Epoch [ 74/160]: loss 0.5009, auc 0.9534, ap 0.9381
EPNet pretrain, Epoch [ 75/160]: loss 0.5003, auc 0.9537, ap 0.9385
EPNet pretrain, Epoch [ 76/160]: loss 0.4996, auc 0.9540, ap 0.9388
EPNet pretrain, Epoch [ 77/160]: loss 0.4989, auc 0.9541, ap 0.9390
EPNet pretrain, Epoch [ 78/160]: loss 0.4983, auc 0.9534, ap 0.9387
EPNet pretrain, Epoch [ 79/160]: loss 0.4977, auc 0.9537, ap 0.9389
EPNet pretrain, Epoch [ 80/160]: loss 0.4971, auc 0.9536, ap 0.9390
EPNet pretrain, Epoch [ 81/160]: loss 0.4965, auc 0.9535, ap 0.9391
EPNet pretrain, Epoch [ 82/160]: loss 0.4958, auc 0.9539, ap 0.9397
EPNet pretrain, Epoch [ 83/160]: loss 0.4951, auc 0.9542, ap 0.9402
EPNet pretrain, Epoch [ 84/160]: loss 0.4944, auc 0.9552, ap 0.9412
EPNet pretrain, Epoch [ 85/160]: loss 0.4937, auc 0.9556, ap 0.9417
EPNet pretrain, Epoch [ 86/160]: loss 0.4930, auc 0.9560, ap 0.9421
EPNet pretrain, Epoch [ 87/160]: loss 0.4923, auc 0.9563, ap 0.9425
EPNet pretrain, Epoch [ 88/160]: loss 0.4915, auc 0.9567, ap 0.9430
EPNet pretrain, Epoch [ 89/160]: loss 0.4908, auc 0.9566, ap 0.9430
EPNet pretrain, Epoch [ 90/160]: loss 0.4900, auc 0.9571, ap 0.9435
EPNet pretrain, Epoch [ 91/160]: loss 0.4892, auc 0.9577, ap 0.9442
EPNet pretrain, Epoch [ 92/160]: loss 0.4883, auc 0.9580, ap 0.9445
EPNet pretrain, Epoch [ 93/160]: loss 0.4875, auc 0.9585, ap 0.9449
EPNet pretrain, Epoch [ 94/160]: loss 0.4867, auc 0.9596, ap 0.9459
EPNet pretrain, Epoch [ 95/160]: loss 0.4858, auc 0.9601, ap 0.9463
EPNet pretrain, Epoch [ 96/160]: loss 0.4850, auc 0.9595, ap 0.9459
EPNet pretrain, Epoch [ 97/160]: loss 0.4842, auc 0.9600, ap 0.9464
EPNet pretrain, Epoch [ 98/160]: loss 0.4835, auc 0.9605, ap 0.9469
EPNet pretrain, Epoch [ 99/160]: loss 0.4827, auc 0.9609, ap 0.9474
EPNet pretrain, Epoch [100/160]: loss 0.4820, auc 0.9614, ap 0.9476
EPNet pretrain, Epoch [101/160]: loss 0.4813, auc 0.9617, ap 0.9479
EPNet pretrain, Epoch [102/160]: loss 0.4806, auc 0.9621, ap 0.9483
EPNet pretrain, Epoch [103/160]: loss 0.4799, auc 0.9624, ap 0.9486
EPNet pretrain, Epoch [104/160]: loss 0.4793, auc 0.9627, ap 0.9489
EPNet pretrain, Epoch [105/160]: loss 0.4786, auc 0.9630, ap 0.9491
EPNet pretrain, Epoch [106/160]: loss 0.4780, auc 0.9633, ap 0.9494
EPNet pretrain, Epoch [107/160]: loss 0.4775, auc 0.9635, ap 0.9497
EPNet pretrain, Epoch [108/160]: loss 0.4769, auc 0.9637, ap 0.9502
EPNet pretrain, Epoch [109/160]: loss 0.4763, auc 0.9639, ap 0.9503
EPNet pretrain, Epoch [110/160]: loss 0.4758, auc 0.9642, ap 0.9507
EPNet pretrain, Epoch [111/160]: loss 0.4752, auc 0.9649, ap 0.9514
EPNet pretrain, Epoch [112/160]: loss 0.4747, auc 0.9651, ap 0.9516
EPNet pretrain, Epoch [113/160]: loss 0.4742, auc 0.9646, ap 0.9513
EPNet pretrain, Epoch [114/160]: loss 0.4738, auc 0.9647, ap 0.9515
EPNet pretrain, Epoch [115/160]: loss 0.4733, auc 0.9642, ap 0.9510
EPNet pretrain, Epoch [116/160]: loss 0.4729, auc 0.9643, ap 0.9511
EPNet pretrain, Epoch [117/160]: loss 0.4724, auc 0.9644, ap 0.9510
EPNet pretrain, Epoch [118/160]: loss 0.4720, auc 0.9646, ap 0.9512
EPNet pretrain, Epoch [119/160]: loss 0.4716, auc 0.9647, ap 0.9511
EPNet pretrain, Epoch [120/160]: loss 0.4711, auc 0.9654, ap 0.9516
EPNet pretrain, Epoch [121/160]: loss 0.4707, auc 0.9656, ap 0.9515
EPNet pretrain, Epoch [122/160]: loss 0.4703, auc 0.9657, ap 0.9514
EPNet pretrain, Epoch [123/160]: loss 0.4699, auc 0.9658, ap 0.9513
EPNet pretrain, Epoch [124/160]: loss 0.4695, auc 0.9659, ap 0.9513
EPNet pretrain, Epoch [125/160]: loss 0.4692, auc 0.9660, ap 0.9512
EPNet pretrain, Epoch [126/160]: loss 0.4688, auc 0.9661, ap 0.9512
EPNet pretrain, Epoch [127/160]: loss 0.4684, auc 0.9661, ap 0.9513
EPNet pretrain, Epoch [128/160]: loss 0.4681, auc 0.9668, ap 0.9518
EPNet pretrain, Epoch [129/160]: loss 0.4678, auc 0.9669, ap 0.9517
EPNet pretrain, Epoch [130/160]: loss 0.4674, auc 0.9677, ap 0.9521
EPNet pretrain, Epoch [131/160]: loss 0.4671, auc 0.9678, ap 0.9520
EPNet pretrain, Epoch [132/160]: loss 0.4668, auc 0.9679, ap 0.9520
EPNet pretrain, Epoch [133/160]: loss 0.4665, auc 0.9680, ap 0.9521
EPNet pretrain, Epoch [134/160]: loss 0.4662, auc 0.9674, ap 0.9516
EPNet pretrain, Epoch [135/160]: loss 0.4659, auc 0.9687, ap 0.9524
EPNet pretrain, Epoch [136/160]: loss 0.4657, auc 0.9687, ap 0.9524
EPNet pretrain, Epoch [137/160]: loss 0.4654, auc 0.9681, ap 0.9518
EPNet pretrain, Epoch [138/160]: loss 0.4651, auc 0.9681, ap 0.9517
EPNet pretrain, Epoch [139/160]: loss 0.4649, auc 0.9682, ap 0.9517
EPNet pretrain, Epoch [140/160]: loss 0.4646, auc 0.9682, ap 0.9516
EPNet pretrain, Epoch [141/160]: loss 0.4643, auc 0.9682, ap 0.9515
EPNet pretrain, Epoch [142/160]: loss 0.4641, auc 0.9688, ap 0.9519
EPNet pretrain, Epoch [143/160]: loss 0.4638, auc 0.9682, ap 0.9515
EPNet pretrain, Epoch [144/160]: loss 0.4636, auc 0.9682, ap 0.9514
EPNet pretrain, Epoch [145/160]: loss 0.4633, auc 0.9682, ap 0.9512
EPNet pretrain, Epoch [146/160]: loss 0.4630, auc 0.9682, ap 0.9512
EPNet pretrain, Epoch [147/160]: loss 0.4628, auc 0.9683, ap 0.9512
EPNet pretrain, Epoch [148/160]: loss 0.4625, auc 0.9677, ap 0.9507
EPNet pretrain, Epoch [149/160]: loss 0.4623, auc 0.9684, ap 0.9512
EPNet pretrain, Epoch [150/160]: loss 0.4621, auc 0.9678, ap 0.9507
EPNet pretrain, Epoch [151/160]: loss 0.4618, auc 0.9679, ap 0.9508
EPNet pretrain, Epoch [152/160]: loss 0.4616, auc 0.9679, ap 0.9508
EPNet pretrain, Epoch [153/160]: loss 0.4613, auc 0.9681, ap 0.9510
EPNet pretrain, Epoch [154/160]: loss 0.4611, auc 0.9682, ap 0.9511
EPNet pretrain, Epoch [155/160]: loss 0.4608, auc 0.9683, ap 0.9510
EPNet pretrain, Epoch [156/160]: loss 0.4606, auc 0.9678, ap 0.9507
EPNet pretrain, Epoch [157/160]: loss 0.4603, auc 0.9685, ap 0.9514
EPNet pretrain, Epoch [158/160]: loss 0.4601, auc 0.9681, ap 0.9509
EPNet pretrain, Epoch [159/160]: loss 0.4598, auc 0.9682, ap 0.9511
EPNet pretrain, Epoch [160/160]: loss 0.4596, auc 0.9683, ap 0.9513
NCNet pretrain, Epoch [ 1/30]: loss 1.9461, val acc 0.4660, test acc 0.5250
NCNet pretrain, Epoch [ 2/30]: loss 1.9297, val acc 0.2640
NCNet pretrain, Epoch [ 3/30]: loss 1.9081, val acc 0.2280
NCNet pretrain, Epoch [ 4/30]: loss 1.8833, val acc 0.2600
NCNet pretrain, Epoch [ 5/30]: loss 1.8554, val acc 0.3400
NCNet pretrain, Epoch [ 6/30]: loss 1.8262, val acc 0.4420
NCNet pretrain, Epoch [ 7/30]: loss 1.7927, val acc 0.5340, test acc 0.5670
NCNet pretrain, Epoch [ 8/30]: loss 1.7539, val acc 0.6240, test acc 0.6190
NCNet pretrain, Epoch [ 9/30]: loss 1.7128, val acc 0.6780, test acc 0.6690
NCNet pretrain, Epoch [10/30]: loss 1.6717, val acc 0.7100, test acc 0.7080
NCNet pretrain, Epoch [11/30]: loss 1.6219, val acc 0.7200, test acc 0.7240
NCNet pretrain, Epoch [12/30]: loss 1.5716, val acc 0.7180
NCNet pretrain, Epoch [13/30]: loss 1.5184, val acc 0.7240, test acc 0.7400
NCNet pretrain, Epoch [14/30]: loss 1.4616, val acc 0.7280, test acc 0.7520
NCNet pretrain, Epoch [15/30]: loss 1.4213, val acc 0.7380, test acc 0.7580
NCNet pretrain, Epoch [16/30]: loss 1.3544, val acc 0.7480, test acc 0.7720
NCNet pretrain, Epoch [17/30]: loss 1.3035, val acc 0.7660, test acc 0.7840
NCNet pretrain, Epoch [18/30]: loss 1.2500, val acc 0.7760, test acc 0.7930
NCNet pretrain, Epoch [19/30]: loss 1.1910, val acc 0.7820, test acc 0.7950
NCNet pretrain, Epoch [20/30]: loss 1.1468, val acc 0.7820
NCNet pretrain, Epoch [21/30]: loss 1.0757, val acc 0.7840, test acc 0.7970
NCNet pretrain, Epoch [22/30]: loss 1.0335, val acc 0.7840
NCNet pretrain, Epoch [23/30]: loss 0.9722, val acc 0.7880, test acc 0.8000
NCNet pretrain, Epoch [24/30]: loss 0.9159, val acc 0.7920, test acc 0.7970
NCNet pretrain, Epoch [25/30]: loss 0.8765, val acc 0.7900
NCNet pretrain, Epoch [26/30]: loss 0.8242, val acc 0.7900
NCNet pretrain, Epoch [27/30]: loss 0.7897, val acc 0.7940, test acc 0.8110
NCNet pretrain, Epoch [28/30]: loss 0.7307, val acc 0.7980, test acc 0.8160
NCNet pretrain, Epoch [29/30]: loss 0.6983, val acc 0.8020, test acc 0.8150
NCNet pretrain, Epoch [30/30]: loss 0.6751, val acc 0.7980
difference tensor(0.3527, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4594, nc loss 1.4937, ep auc: 0.9685, ep ap 0.9515, val acc 0.7240, test acc 0.7520
difference tensor(0.2939, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4716, nc loss 1.4031, ep auc: 0.9646, ep ap 0.9468, val acc 0.7460, test acc 0.7750
difference tensor(0.3102, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.5018, nc loss 1.3276, ep auc: 0.9526, ep ap 0.9345, val acc 0.7820, test acc 0.8150
difference tensor(0.3367, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5365, nc loss 1.1868, ep auc: 0.9323, ep ap 0.9134, val acc 0.8100, test acc 0.8320
difference tensor(1.3653, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5666, nc loss 1.1422, ep auc: 0.8816, ep ap 0.8649, val acc 0.8060, test acc 0.8330
difference tensor(1.0953, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.5925, nc loss 1.1118, ep auc: 0.8531, ep ap 0.8351, val acc 0.8000, test acc 0.8330
difference tensor(0.8821, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.6151, nc loss 1.1087, ep auc: 0.8345, ep ap 0.8153, val acc 0.8020, test acc 0.8330
difference tensor(0.9143, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.6277, nc loss 1.0381, ep auc: 0.8102, ep ap 0.7921, val acc 0.7920, test acc 0.8330
difference tensor(0.5176, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6355, nc loss 0.9807, ep auc: 0.7716, ep ap 0.7583, val acc 0.7900, test acc 0.8330
difference tensor(1.6049, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6380, nc loss 0.9268, ep auc: 0.7449, ep ap 0.7325, val acc 0.7900, test acc 0.8330
difference tensor(0.4917, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6378, nc loss 0.9208, ep auc: 0.7240, ep ap 0.7133, val acc 0.7880, test acc 0.8330
difference tensor(0.8834, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6377, nc loss 0.8593, ep auc: 0.7105, ep ap 0.7014, val acc 0.7980, test acc 0.8330
difference tensor(0.6108, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6379, nc loss 0.8844, ep auc: 0.7059, ep ap 0.6980, val acc 0.8060, test acc 0.8330
difference tensor(0.4717, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6375, nc loss 0.8580, ep auc: 0.7030, ep ap 0.6958, val acc 0.8020, test acc 0.8330
difference tensor(1.2888, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6360, nc loss 0.8436, ep auc: 0.7032, ep ap 0.6963, val acc 0.8040, test acc 0.8330
difference tensor(0.5768, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6340, nc loss 0.7765, ep auc: 0.7033, ep ap 0.6967, val acc 0.8020, test acc 0.8330
difference tensor(0.9131, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6332, nc loss 0.7676, ep auc: 0.7025, ep ap 0.6960, val acc 0.8020, test acc 0.8330
difference tensor(0.8414, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6332, nc loss 0.7370, ep auc: 0.7065, ep ap 0.6990, val acc 0.8060, test acc 0.8330
difference tensor(1.3921, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6339, nc loss 0.7233, ep auc: 0.7075, ep ap 0.7000, val acc 0.8080, test acc 0.8330
difference tensor(1.0636, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6342, nc loss 0.7214, ep auc: 0.7055, ep ap 0.6973, val acc 0.8000, test acc 0.8330
difference tensor(2.6332, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6343, nc loss 0.7002, ep auc: 0.7093, ep ap 0.6999, val acc 0.7960, test acc 0.8330
difference tensor(0.9160, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6342, nc loss 0.7034, ep auc: 0.7082, ep ap 0.6993, val acc 0.7940, test acc 0.8330
difference tensor(1.2069, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6345, nc loss 0.7079, ep auc: 0.7054, ep ap 0.6969, val acc 0.7980, test acc 0.8330
difference tensor(1.2987, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6352, nc loss 0.6759, ep auc: 0.6997, ep ap 0.6925, val acc 0.7940, test acc 0.8330
difference tensor(1.4230, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6367, nc loss 0.6915, ep auc: 0.6924, ep ap 0.6850, val acc 0.7960, test acc 0.8330
difference tensor(1.7567, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6383, nc loss 0.6849, ep auc: 0.6875, ep ap 0.6807, val acc 0.7900, test acc 0.8330
difference tensor(2.4823, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6400, nc loss 0.6558, ep auc: 0.6821, ep ap 0.6754, val acc 0.7980, test acc 0.8330
difference tensor(3.2364, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6414, nc loss 0.6918, ep auc: 0.6768, ep ap 0.6691, val acc 0.7880, test acc 0.8330
difference tensor(1.9476, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6421, nc loss 0.6718, ep auc: 0.6702, ep ap 0.6632, val acc 0.7880, test acc 0.8330
difference tensor(2.5496, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6420, nc loss 0.6659, ep auc: 0.6663, ep ap 0.6596, val acc 0.7840, test acc 0.8330
difference tensor(2.0234, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6418, nc loss 0.6824, ep auc: 0.6672, ep ap 0.6608, val acc 0.7820, test acc 0.8330
difference tensor(1.9322, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6419, nc loss 0.6900, ep auc: 0.6653, ep ap 0.6584, val acc 0.7880, test acc 0.8330
difference tensor(1.4879, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6420, nc loss 0.6521, ep auc: 0.6598, ep ap 0.6545, val acc 0.7840, test acc 0.8330
difference tensor(4.0334, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6424, nc loss 0.6595, ep auc: 0.6598, ep ap 0.6545, val acc 0.7760, test acc 0.8330
difference tensor(1.6836, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6426, nc loss 0.6639, ep auc: 0.6606, ep ap 0.6565, val acc 0.7780, test acc 0.8330
difference tensor(2.7236, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6429, nc loss 0.6561, ep auc: 0.6601, ep ap 0.6565, val acc 0.7760, test acc 0.8330
difference tensor(1.7284, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6430, nc loss 0.6481, ep auc: 0.6610, ep ap 0.6560, val acc 0.7840, test acc 0.8330
difference tensor(1.7812, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6432, nc loss 0.6482, ep auc: 0.6624, ep ap 0.6571, val acc 0.7900, test acc 0.8330
difference tensor(1.6005, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6435, nc loss 0.6696, ep auc: 0.6621, ep ap 0.6565, val acc 0.7980, test acc 0.8330
difference tensor(4.1515, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6436, nc loss 0.6658, ep auc: 0.6624, ep ap 0.6569, val acc 0.7960, test acc 0.8330
difference tensor(2.0433, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6437, nc loss 0.6652, ep auc: 0.6609, ep ap 0.6557, val acc 0.7980, test acc 0.8330
difference tensor(2.0597, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6436, nc loss 0.6472, ep auc: 0.6626, ep ap 0.6576, val acc 0.7960, test acc 0.8330
difference tensor(1.8538, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6438, nc loss 0.6572, ep auc: 0.6626, ep ap 0.6576, val acc 0.7940, test acc 0.8330
difference tensor(2.1082, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6443, nc loss 0.6418, ep auc: 0.6598, ep ap 0.6555, val acc 0.7900, test acc 0.8330
difference tensor(2.1105, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6446, nc loss 0.6565, ep auc: 0.6598, ep ap 0.6553, val acc 0.7860, test acc 0.8330
difference tensor(6.6743, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6452, nc loss 0.6672, ep auc: 0.6597, ep ap 0.6549, val acc 0.7760, test acc 0.8330
difference tensor(1.9226, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 47/200]: ep loss 0.6455, nc loss 0.6596, ep auc: 0.6587, ep ap 0.6536, val acc 0.7700, test acc 0.8330
difference tensor(2.4677, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 48/200]: ep loss 0.6461, nc loss 0.6490, ep auc: 0.6590, ep ap 0.6543, val acc 0.7680, test acc 0.8330
difference tensor(3.1583, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 49/200]: ep loss 0.6467, nc loss 0.6629, ep auc: 0.6635, ep ap 0.6582, val acc 0.7680, test acc 0.8330
difference tensor(2.2332, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 50/200]: ep loss 0.6477, nc loss 0.6410, ep auc: 0.6631, ep ap 0.6583, val acc 0.7700, test acc 0.8330
difference tensor(2.6358, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 51/200]: ep loss 0.6482, nc loss 0.6530, ep auc: 0.6618, ep ap 0.6574, val acc 0.7820, test acc 0.8330
difference tensor(3.2873, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 52/200]: ep loss 0.6483, nc loss 0.6655, ep auc: 0.6598, ep ap 0.6561, val acc 0.7820, test acc 0.8330
difference tensor(1.9856, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 53/200]: ep loss 0.6481, nc loss 0.6407, ep auc: 0.6594, ep ap 0.6556, val acc 0.7940, test acc 0.8330
difference tensor(6.2168, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 54/200]: ep loss 0.6483, nc loss 0.6414, ep auc: 0.6559, ep ap 0.6527, val acc 0.7940, test acc 0.8330
difference tensor(2.6739, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 55/200]: ep loss 0.6485, nc loss 0.6603, ep auc: 0.6571, ep ap 0.6534, val acc 0.7920, test acc 0.8330
difference tensor(2.4649, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 56/200]: ep loss 0.6488, nc loss 0.6397, ep auc: 0.6601, ep ap 0.6563, val acc 0.7860, test acc 0.8330
difference tensor(1.9284, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 57/200]: ep loss 0.6491, nc loss 0.6419, ep auc: 0.6609, ep ap 0.6570, val acc 0.7820, test acc 0.8330
difference tensor(7.1434, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 58/200]: ep loss 0.6495, nc loss 0.6404, ep auc: 0.6602, ep ap 0.6566, val acc 0.7760, test acc 0.8330
difference tensor(3.3636, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 59/200]: ep loss 0.6503, nc loss 0.6444, ep auc: 0.6595, ep ap 0.6564, val acc 0.7640, test acc 0.8330
difference tensor(1.5796, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 60/200]: ep loss 0.6514, nc loss 0.6520, ep auc: 0.6592, ep ap 0.6554, val acc 0.7680, test acc 0.8330
difference tensor(3.1157, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 61/200]: ep loss 0.6526, nc loss 0.6401, ep auc: 0.6585, ep ap 0.6548, val acc 0.7700, test acc 0.8330
difference tensor(3.3190, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 62/200]: ep loss 0.6534, nc loss 0.6380, ep auc: 0.6591, ep ap 0.6540, val acc 0.7820, test acc 0.8330
difference tensor(2.8395, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 63/200]: ep loss 0.6539, nc loss 0.6516, ep auc: 0.6613, ep ap 0.6557, val acc 0.7800, test acc 0.8330
difference tensor(2.5222, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 64/200]: ep loss 0.6536, nc loss 0.6585, ep auc: 0.6594, ep ap 0.6537, val acc 0.7840, test acc 0.8330
difference tensor(2.3348, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 65/200]: ep loss 0.6531, nc loss 0.6281, ep auc: 0.6595, ep ap 0.6540, val acc 0.7840, test acc 0.8330
difference tensor(4.4754, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 66/200]: ep loss 0.6527, nc loss 0.6327, ep auc: 0.6593, ep ap 0.6550, val acc 0.7860, test acc 0.8330
difference tensor(3.9568, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 67/200]: ep loss 0.6521, nc loss 0.6394, ep auc: 0.6593, ep ap 0.6551, val acc 0.7880, test acc 0.8330
difference tensor(2.2815, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 68/200]: ep loss 0.6518, nc loss 0.6278, ep auc: 0.6586, ep ap 0.6545, val acc 0.7900, test acc 0.8330
difference tensor(1.7270, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 69/200]: ep loss 0.6513, nc loss 0.6308, ep auc: 0.6586, ep ap 0.6544, val acc 0.7840, test acc 0.8330
difference tensor(3.0508, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 70/200]: ep loss 0.6509, nc loss 0.6273, ep auc: 0.6578, ep ap 0.6533, val acc 0.7880, test acc 0.8330
difference tensor(1.5145, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 71/200]: ep loss 0.6505, nc loss 0.6318, ep auc: 0.6538, ep ap 0.6493, val acc 0.7840, test acc 0.8330
difference tensor(5.2316, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 72/200]: ep loss 0.6503, nc loss 0.6268, ep auc: 0.6543, ep ap 0.6492, val acc 0.7840, test acc 0.8330
difference tensor(8.2869, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 73/200]: ep loss 0.6500, nc loss 0.6160, ep auc: 0.6523, ep ap 0.6478, val acc 0.7800, test acc 0.8330
difference tensor(2.9075, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 74/200]: ep loss 0.6498, nc loss 0.6151, ep auc: 0.6525, ep ap 0.6481, val acc 0.7780, test acc 0.8330
difference tensor(2.9198, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 75/200]: ep loss 0.6496, nc loss 0.6333, ep auc: 0.6518, ep ap 0.6475, val acc 0.7780, test acc 0.8330
difference tensor(3.3595, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 76/200]: ep loss 0.6495, nc loss 0.6219, ep auc: 0.6530, ep ap 0.6482, val acc 0.7780, test acc 0.8330
difference tensor(4.3443, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 77/200]: ep loss 0.6493, nc loss 0.6219, ep auc: 0.6524, ep ap 0.6483, val acc 0.7880, test acc 0.8330
difference tensor(1.6928, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 78/200]: ep loss 0.6492, nc loss 0.6256, ep auc: 0.6553, ep ap 0.6508, val acc 0.7960, test acc 0.8330
difference tensor(1.6134, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 79/200]: ep loss 0.6491, nc loss 0.6252, ep auc: 0.6564, ep ap 0.6513, val acc 0.7900, test acc 0.8330
difference tensor(3.5863, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 80/200]: ep loss 0.6490, nc loss 0.6108, ep auc: 0.6554, ep ap 0.6514, val acc 0.7920, test acc 0.8330
difference tensor(1.8263, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 81/200]: ep loss 0.6489, nc loss 0.6242, ep auc: 0.6539, ep ap 0.6514, val acc 0.7880, test acc 0.8330
difference tensor(2.3107, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 82/200]: ep loss 0.6490, nc loss 0.6237, ep auc: 0.6544, ep ap 0.6513, val acc 0.7860, test acc 0.8330
difference tensor(1.5999, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 83/200]: ep loss 0.6491, nc loss 0.6267, ep auc: 0.6518, ep ap 0.6496, val acc 0.7780, test acc 0.8330
difference tensor(2.4352, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 84/200]: ep loss 0.6492, nc loss 0.6310, ep auc: 0.6533, ep ap 0.6510, val acc 0.7800, test acc 0.8330
difference tensor(2.2894, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 85/200]: ep loss 0.6493, nc loss 0.6202, ep auc: 0.6533, ep ap 0.6515, val acc 0.7840, test acc 0.8330
difference tensor(6.7470, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 86/200]: ep loss 0.6496, nc loss 0.6068, ep auc: 0.6560, ep ap 0.6538, val acc 0.7840, test acc 0.8330
difference tensor(3.4081, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 87/200]: ep loss 0.6498, nc loss 0.6371, ep auc: 0.6577, ep ap 0.6558, val acc 0.7800, test acc 0.8330
difference tensor(1.5059, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 88/200]: ep loss 0.6501, nc loss 0.6208, ep auc: 0.6585, ep ap 0.6568, val acc 0.7880, test acc 0.8330
difference tensor(2.2681, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 89/200]: ep loss 0.6504, nc loss 0.6170, ep auc: 0.6583, ep ap 0.6577, val acc 0.7900, test acc 0.8330
difference tensor(2.5739, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 90/200]: ep loss 0.6508, nc loss 0.6203, ep auc: 0.6626, ep ap 0.6614, val acc 0.7840, test acc 0.8330
difference tensor(2.0916, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 91/200]: ep loss 0.6512, nc loss 0.6036, ep auc: 0.6624, ep ap 0.6622, val acc 0.7840, test acc 0.8330
difference tensor(2.0676, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 92/200]: ep loss 0.6513, nc loss 0.6175, ep auc: 0.6636, ep ap 0.6631, val acc 0.7840, test acc 0.8330
difference tensor(2.7769, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 93/200]: ep loss 0.6513, nc loss 0.6196, ep auc: 0.6644, ep ap 0.6638, val acc 0.7780, test acc 0.8330
difference tensor(1.6736, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 94/200]: ep loss 0.6512, nc loss 0.6121, ep auc: 0.6654, ep ap 0.6639, val acc 0.7760, test acc 0.8330
difference tensor(1.6797, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 95/200]: ep loss 0.6510, nc loss 0.6313, ep auc: 0.6622, ep ap 0.6609, val acc 0.7780, test acc 0.8330
difference tensor(1.4814, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 96/200]: ep loss 0.6509, nc loss 0.6194, ep auc: 0.6608, ep ap 0.6597, val acc 0.7820, test acc 0.8330
difference tensor(4.1263, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 97/200]: ep loss 0.6510, nc loss 0.6115, ep auc: 0.6608, ep ap 0.6597, val acc 0.7780, test acc 0.8330
difference tensor(2.5270, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 98/200]: ep loss 0.6512, nc loss 0.6107, ep auc: 0.6612, ep ap 0.6595, val acc 0.7760, test acc 0.8330
difference tensor(2.8986, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 99/200]: ep loss 0.6515, nc loss 0.6047, ep auc: 0.6612, ep ap 0.6592, val acc 0.7740, test acc 0.8330
difference tensor(2.1529, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [100/200]: ep loss 0.6517, nc loss 0.6279, ep auc: 0.6606, ep ap 0.6589, val acc 0.7760, test acc 0.8330
difference tensor(1.4697, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [101/200]: ep loss 0.6520, nc loss 0.6174, ep auc: 0.6623, ep ap 0.6605, val acc 0.7740, test acc 0.8330
difference tensor(2.8806, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [102/200]: ep loss 0.6524, nc loss 0.6243, ep auc: 0.6676, ep ap 0.6654, val acc 0.7800, test acc 0.8330
difference tensor(1.2908, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [103/200]: ep loss 0.6529, nc loss 0.6106, ep auc: 0.6698, ep ap 0.6672, val acc 0.7840, test acc 0.8330
difference tensor(2.4851, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [104/200]: ep loss 0.6534, nc loss 0.6216, ep auc: 0.6709, ep ap 0.6689, val acc 0.7740, test acc 0.8330
difference tensor(3.4358, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [105/200]: ep loss 0.6534, nc loss 0.6145, ep auc: 0.6724, ep ap 0.6701, val acc 0.7760, test acc 0.8330
Early stop!
Final test acc with early stop: 0.8330, without early stop: 0.7950
Micro F1: 0.834667, std: 0.005437, Max is 0.842000, min is 0.829000
Big Epoch 2/30 dataset is cora fid_frac is 0.1
Big Epoch 3/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8520, ap 0.8432
EPNet pretrain, Epoch [  2/160]: loss 0.6909, auc 0.8168, ap 0.8083
EPNet pretrain, Epoch [  3/160]: loss 0.6843, auc 0.7916, ap 0.7866
EPNet pretrain, Epoch [  4/160]: loss 0.6796, auc 0.7792, ap 0.7780
EPNet pretrain, Epoch [  5/160]: loss 0.6787, auc 0.7783, ap 0.7840
EPNet pretrain, Epoch [  6/160]: loss 0.6740, auc 0.7797, ap 0.7920
EPNet pretrain, Epoch [  7/160]: loss 0.6721, auc 0.7789, ap 0.7976
EPNet pretrain, Epoch [  8/160]: loss 0.6685, auc 0.7752, ap 0.7985
EPNet pretrain, Epoch [  9/160]: loss 0.6629, auc 0.7706, ap 0.7966
EPNet pretrain, Epoch [ 10/160]: loss 0.6572, auc 0.7676, ap 0.7948
EPNet pretrain, Epoch [ 11/160]: loss 0.6521, auc 0.7715, ap 0.7972
EPNet pretrain, Epoch [ 12/160]: loss 0.6450, auc 0.7867, ap 0.8074
EPNet pretrain, Epoch [ 13/160]: loss 0.6374, auc 0.8079, ap 0.8242
EPNet pretrain, Epoch [ 14/160]: loss 0.6304, auc 0.8257, ap 0.8393
EPNet pretrain, Epoch [ 15/160]: loss 0.6232, auc 0.8370, ap 0.8484
EPNet pretrain, Epoch [ 16/160]: loss 0.6163, auc 0.8437, ap 0.8525
EPNet pretrain, Epoch [ 17/160]: loss 0.6112, auc 0.8488, ap 0.8547
EPNet pretrain, Epoch [ 18/160]: loss 0.6074, auc 0.8533, ap 0.8561
EPNet pretrain, Epoch [ 19/160]: loss 0.6030, auc 0.8575, ap 0.8581
EPNet pretrain, Epoch [ 20/160]: loss 0.5980, auc 0.8618, ap 0.8612
EPNet pretrain, Epoch [ 21/160]: loss 0.5932, auc 0.8659, ap 0.8656
EPNet pretrain, Epoch [ 22/160]: loss 0.5888, auc 0.8694, ap 0.8699
EPNet pretrain, Epoch [ 23/160]: loss 0.5849, auc 0.8727, ap 0.8741
EPNet pretrain, Epoch [ 24/160]: loss 0.5818, auc 0.8754, ap 0.8775
EPNet pretrain, Epoch [ 25/160]: loss 0.5791, auc 0.8782, ap 0.8806
EPNet pretrain, Epoch [ 26/160]: loss 0.5765, auc 0.8808, ap 0.8839
EPNet pretrain, Epoch [ 27/160]: loss 0.5736, auc 0.8845, ap 0.8882
EPNet pretrain, Epoch [ 28/160]: loss 0.5708, auc 0.8880, ap 0.8922
EPNet pretrain, Epoch [ 29/160]: loss 0.5679, auc 0.8921, ap 0.8959
EPNet pretrain, Epoch [ 30/160]: loss 0.5649, auc 0.8959, ap 0.8989
EPNet pretrain, Epoch [ 31/160]: loss 0.5618, auc 0.8995, ap 0.9020
EPNet pretrain, Epoch [ 32/160]: loss 0.5588, auc 0.9015, ap 0.9045
EPNet pretrain, Epoch [ 33/160]: loss 0.5561, auc 0.9047, ap 0.9077
EPNet pretrain, Epoch [ 34/160]: loss 0.5536, auc 0.9066, ap 0.9097
EPNet pretrain, Epoch [ 35/160]: loss 0.5513, auc 0.9098, ap 0.9127
EPNet pretrain, Epoch [ 36/160]: loss 0.5492, auc 0.9137, ap 0.9164
EPNet pretrain, Epoch [ 37/160]: loss 0.5473, auc 0.9168, ap 0.9193
EPNet pretrain, Epoch [ 38/160]: loss 0.5452, auc 0.9192, ap 0.9215
EPNet pretrain, Epoch [ 39/160]: loss 0.5430, auc 0.9212, ap 0.9231
EPNet pretrain, Epoch [ 40/160]: loss 0.5405, auc 0.9244, ap 0.9253
EPNet pretrain, Epoch [ 41/160]: loss 0.5379, auc 0.9271, ap 0.9274
EPNet pretrain, Epoch [ 42/160]: loss 0.5353, auc 0.9297, ap 0.9299
EPNet pretrain, Epoch [ 43/160]: loss 0.5328, auc 0.9320, ap 0.9321
EPNet pretrain, Epoch [ 44/160]: loss 0.5304, auc 0.9339, ap 0.9337
EPNet pretrain, Epoch [ 45/160]: loss 0.5280, auc 0.9354, ap 0.9345
EPNet pretrain, Epoch [ 46/160]: loss 0.5257, auc 0.9369, ap 0.9352
EPNet pretrain, Epoch [ 47/160]: loss 0.5234, auc 0.9380, ap 0.9358
EPNet pretrain, Epoch [ 48/160]: loss 0.5212, auc 0.9396, ap 0.9369
EPNet pretrain, Epoch [ 49/160]: loss 0.5192, auc 0.9411, ap 0.9381
EPNet pretrain, Epoch [ 50/160]: loss 0.5171, auc 0.9428, ap 0.9396
EPNet pretrain, Epoch [ 51/160]: loss 0.5151, auc 0.9438, ap 0.9408
EPNet pretrain, Epoch [ 52/160]: loss 0.5132, auc 0.9456, ap 0.9422
EPNet pretrain, Epoch [ 53/160]: loss 0.5115, auc 0.9473, ap 0.9436
EPNet pretrain, Epoch [ 54/160]: loss 0.5100, auc 0.9485, ap 0.9444
EPNet pretrain, Epoch [ 55/160]: loss 0.5086, auc 0.9493, ap 0.9453
EPNet pretrain, Epoch [ 56/160]: loss 0.5074, auc 0.9502, ap 0.9458
EPNet pretrain, Epoch [ 57/160]: loss 0.5062, auc 0.9506, ap 0.9460
EPNet pretrain, Epoch [ 58/160]: loss 0.5051, auc 0.9508, ap 0.9460
EPNet pretrain, Epoch [ 59/160]: loss 0.5040, auc 0.9514, ap 0.9463
EPNet pretrain, Epoch [ 60/160]: loss 0.5029, auc 0.9519, ap 0.9466
EPNet pretrain, Epoch [ 61/160]: loss 0.5019, auc 0.9519, ap 0.9465
EPNet pretrain, Epoch [ 62/160]: loss 0.5009, auc 0.9523, ap 0.9467
EPNet pretrain, Epoch [ 63/160]: loss 0.5000, auc 0.9523, ap 0.9467
EPNet pretrain, Epoch [ 64/160]: loss 0.4990, auc 0.9544, ap 0.9484
EPNet pretrain, Epoch [ 65/160]: loss 0.4981, auc 0.9552, ap 0.9492
EPNet pretrain, Epoch [ 66/160]: loss 0.4972, auc 0.9565, ap 0.9504
EPNet pretrain, Epoch [ 67/160]: loss 0.4963, auc 0.9566, ap 0.9509
EPNet pretrain, Epoch [ 68/160]: loss 0.4955, auc 0.9567, ap 0.9511
EPNet pretrain, Epoch [ 69/160]: loss 0.4947, auc 0.9572, ap 0.9519
EPNet pretrain, Epoch [ 70/160]: loss 0.4939, auc 0.9578, ap 0.9526
EPNet pretrain, Epoch [ 71/160]: loss 0.4932, auc 0.9583, ap 0.9532
EPNet pretrain, Epoch [ 72/160]: loss 0.4924, auc 0.9588, ap 0.9538
EPNet pretrain, Epoch [ 73/160]: loss 0.4917, auc 0.9585, ap 0.9537
EPNet pretrain, Epoch [ 74/160]: loss 0.4910, auc 0.9610, ap 0.9557
EPNet pretrain, Epoch [ 75/160]: loss 0.4904, auc 0.9617, ap 0.9562
EPNet pretrain, Epoch [ 76/160]: loss 0.4897, auc 0.9619, ap 0.9563
EPNet pretrain, Epoch [ 77/160]: loss 0.4890, auc 0.9622, ap 0.9566
EPNet pretrain, Epoch [ 78/160]: loss 0.4883, auc 0.9625, ap 0.9568
EPNet pretrain, Epoch [ 79/160]: loss 0.4877, auc 0.9616, ap 0.9559
EPNet pretrain, Epoch [ 80/160]: loss 0.4870, auc 0.9612, ap 0.9556
EPNet pretrain, Epoch [ 81/160]: loss 0.4864, auc 0.9614, ap 0.9557
EPNet pretrain, Epoch [ 82/160]: loss 0.4858, auc 0.9621, ap 0.9562
EPNet pretrain, Epoch [ 83/160]: loss 0.4852, auc 0.9627, ap 0.9566
EPNet pretrain, Epoch [ 84/160]: loss 0.4846, auc 0.9630, ap 0.9569
EPNet pretrain, Epoch [ 85/160]: loss 0.4840, auc 0.9632, ap 0.9573
EPNet pretrain, Epoch [ 86/160]: loss 0.4833, auc 0.9634, ap 0.9577
EPNet pretrain, Epoch [ 87/160]: loss 0.4827, auc 0.9630, ap 0.9576
EPNet pretrain, Epoch [ 88/160]: loss 0.4821, auc 0.9628, ap 0.9575
EPNet pretrain, Epoch [ 89/160]: loss 0.4814, auc 0.9631, ap 0.9578
EPNet pretrain, Epoch [ 90/160]: loss 0.4808, auc 0.9634, ap 0.9580
EPNet pretrain, Epoch [ 91/160]: loss 0.4801, auc 0.9637, ap 0.9585
EPNet pretrain, Epoch [ 92/160]: loss 0.4794, auc 0.9639, ap 0.9586
EPNet pretrain, Epoch [ 93/160]: loss 0.4788, auc 0.9648, ap 0.9593
EPNet pretrain, Epoch [ 94/160]: loss 0.4781, auc 0.9651, ap 0.9597
EPNet pretrain, Epoch [ 95/160]: loss 0.4774, auc 0.9654, ap 0.9600
EPNet pretrain, Epoch [ 96/160]: loss 0.4768, auc 0.9657, ap 0.9604
EPNet pretrain, Epoch [ 97/160]: loss 0.4761, auc 0.9660, ap 0.9607
EPNet pretrain, Epoch [ 98/160]: loss 0.4754, auc 0.9664, ap 0.9612
EPNet pretrain, Epoch [ 99/160]: loss 0.4748, auc 0.9672, ap 0.9620
EPNet pretrain, Epoch [100/160]: loss 0.4741, auc 0.9675, ap 0.9623
EPNet pretrain, Epoch [101/160]: loss 0.4734, auc 0.9685, ap 0.9632
EPNet pretrain, Epoch [102/160]: loss 0.4727, auc 0.9688, ap 0.9636
EPNet pretrain, Epoch [103/160]: loss 0.4720, auc 0.9691, ap 0.9639
EPNet pretrain, Epoch [104/160]: loss 0.4713, auc 0.9699, ap 0.9647
EPNet pretrain, Epoch [105/160]: loss 0.4706, auc 0.9702, ap 0.9650
EPNet pretrain, Epoch [106/160]: loss 0.4699, auc 0.9704, ap 0.9651
EPNet pretrain, Epoch [107/160]: loss 0.4691, auc 0.9707, ap 0.9655
EPNet pretrain, Epoch [108/160]: loss 0.4684, auc 0.9711, ap 0.9659
EPNet pretrain, Epoch [109/160]: loss 0.4676, auc 0.9715, ap 0.9663
EPNet pretrain, Epoch [110/160]: loss 0.4669, auc 0.9719, ap 0.9668
EPNet pretrain, Epoch [111/160]: loss 0.4662, auc 0.9722, ap 0.9671
EPNet pretrain, Epoch [112/160]: loss 0.4655, auc 0.9724, ap 0.9674
EPNet pretrain, Epoch [113/160]: loss 0.4649, auc 0.9727, ap 0.9675
EPNet pretrain, Epoch [114/160]: loss 0.4642, auc 0.9723, ap 0.9673
EPNet pretrain, Epoch [115/160]: loss 0.4636, auc 0.9731, ap 0.9679
EPNet pretrain, Epoch [116/160]: loss 0.4630, auc 0.9733, ap 0.9681
EPNet pretrain, Epoch [117/160]: loss 0.4625, auc 0.9735, ap 0.9683
EPNet pretrain, Epoch [118/160]: loss 0.4619, auc 0.9737, ap 0.9684
EPNet pretrain, Epoch [119/160]: loss 0.4613, auc 0.9740, ap 0.9686
EPNet pretrain, Epoch [120/160]: loss 0.4608, auc 0.9742, ap 0.9688
EPNet pretrain, Epoch [121/160]: loss 0.4602, auc 0.9739, ap 0.9686
EPNet pretrain, Epoch [122/160]: loss 0.4598, auc 0.9747, ap 0.9694
EPNet pretrain, Epoch [123/160]: loss 0.4593, auc 0.9749, ap 0.9695
EPNet pretrain, Epoch [124/160]: loss 0.4588, auc 0.9751, ap 0.9696
EPNet pretrain, Epoch [125/160]: loss 0.4584, auc 0.9752, ap 0.9697
EPNet pretrain, Epoch [126/160]: loss 0.4580, auc 0.9753, ap 0.9698
EPNet pretrain, Epoch [127/160]: loss 0.4575, auc 0.9755, ap 0.9700
EPNet pretrain, Epoch [128/160]: loss 0.4571, auc 0.9756, ap 0.9702
EPNet pretrain, Epoch [129/160]: loss 0.4567, auc 0.9756, ap 0.9703
EPNet pretrain, Epoch [130/160]: loss 0.4563, auc 0.9757, ap 0.9703
EPNet pretrain, Epoch [131/160]: loss 0.4559, auc 0.9759, ap 0.9705
EPNet pretrain, Epoch [132/160]: loss 0.4554, auc 0.9761, ap 0.9708
EPNet pretrain, Epoch [133/160]: loss 0.4550, auc 0.9762, ap 0.9710
EPNet pretrain, Epoch [134/160]: loss 0.4546, auc 0.9764, ap 0.9714
EPNet pretrain, Epoch [135/160]: loss 0.4542, auc 0.9765, ap 0.9716
EPNet pretrain, Epoch [136/160]: loss 0.4538, auc 0.9766, ap 0.9717
EPNet pretrain, Epoch [137/160]: loss 0.4534, auc 0.9766, ap 0.9718
EPNet pretrain, Epoch [138/160]: loss 0.4531, auc 0.9767, ap 0.9719
EPNet pretrain, Epoch [139/160]: loss 0.4527, auc 0.9768, ap 0.9721
EPNet pretrain, Epoch [140/160]: loss 0.4523, auc 0.9775, ap 0.9727
EPNet pretrain, Epoch [141/160]: loss 0.4520, auc 0.9770, ap 0.9724
EPNet pretrain, Epoch [142/160]: loss 0.4516, auc 0.9771, ap 0.9725
EPNet pretrain, Epoch [143/160]: loss 0.4513, auc 0.9772, ap 0.9726
EPNet pretrain, Epoch [144/160]: loss 0.4509, auc 0.9773, ap 0.9728
EPNet pretrain, Epoch [145/160]: loss 0.4506, auc 0.9774, ap 0.9729
EPNet pretrain, Epoch [146/160]: loss 0.4503, auc 0.9780, ap 0.9735
EPNet pretrain, Epoch [147/160]: loss 0.4499, auc 0.9780, ap 0.9736
EPNet pretrain, Epoch [148/160]: loss 0.4496, auc 0.9774, ap 0.9730
EPNet pretrain, Epoch [149/160]: loss 0.4493, auc 0.9774, ap 0.9730
EPNet pretrain, Epoch [150/160]: loss 0.4490, auc 0.9774, ap 0.9730
EPNet pretrain, Epoch [151/160]: loss 0.4487, auc 0.9780, ap 0.9736
EPNet pretrain, Epoch [152/160]: loss 0.4484, auc 0.9774, ap 0.9731
EPNet pretrain, Epoch [153/160]: loss 0.4481, auc 0.9774, ap 0.9731
EPNet pretrain, Epoch [154/160]: loss 0.4478, auc 0.9774, ap 0.9731
EPNet pretrain, Epoch [155/160]: loss 0.4475, auc 0.9775, ap 0.9731
EPNet pretrain, Epoch [156/160]: loss 0.4472, auc 0.9782, ap 0.9736
EPNet pretrain, Epoch [157/160]: loss 0.4469, auc 0.9776, ap 0.9732
EPNet pretrain, Epoch [158/160]: loss 0.4467, auc 0.9777, ap 0.9733
EPNet pretrain, Epoch [159/160]: loss 0.4464, auc 0.9778, ap 0.9735
EPNet pretrain, Epoch [160/160]: loss 0.4461, auc 0.9779, ap 0.9735
NCNet pretrain, Epoch [ 1/30]: loss 1.9458, val acc 0.3860, test acc 0.4260
NCNet pretrain, Epoch [ 2/30]: loss 1.9309, val acc 0.3900, test acc 0.4100
NCNet pretrain, Epoch [ 3/30]: loss 1.9115, val acc 0.4300, test acc 0.4380
NCNet pretrain, Epoch [ 4/30]: loss 1.8908, val acc 0.4500, test acc 0.4620
NCNet pretrain, Epoch [ 5/30]: loss 1.8588, val acc 0.4620, test acc 0.4750
NCNet pretrain, Epoch [ 6/30]: loss 1.8264, val acc 0.5200, test acc 0.5180
NCNet pretrain, Epoch [ 7/30]: loss 1.7978, val acc 0.5620, test acc 0.5780
NCNet pretrain, Epoch [ 8/30]: loss 1.7567, val acc 0.6300, test acc 0.6240
NCNet pretrain, Epoch [ 9/30]: loss 1.7169, val acc 0.6680, test acc 0.6760
NCNet pretrain, Epoch [10/30]: loss 1.6745, val acc 0.7080, test acc 0.7130
NCNet pretrain, Epoch [11/30]: loss 1.6239, val acc 0.7180, test acc 0.7240
NCNet pretrain, Epoch [12/30]: loss 1.5750, val acc 0.7360, test acc 0.7350
NCNet pretrain, Epoch [13/30]: loss 1.5301, val acc 0.7500, test acc 0.7480
NCNet pretrain, Epoch [14/30]: loss 1.4680, val acc 0.7640, test acc 0.7680
NCNet pretrain, Epoch [15/30]: loss 1.4176, val acc 0.7740, test acc 0.7780
NCNet pretrain, Epoch [16/30]: loss 1.3552, val acc 0.7760, test acc 0.7830
NCNet pretrain, Epoch [17/30]: loss 1.2904, val acc 0.7820, test acc 0.7920
NCNet pretrain, Epoch [18/30]: loss 1.2317, val acc 0.7860, test acc 0.7970
NCNet pretrain, Epoch [19/30]: loss 1.1811, val acc 0.7900, test acc 0.8000
NCNet pretrain, Epoch [20/30]: loss 1.1242, val acc 0.7900
NCNet pretrain, Epoch [21/30]: loss 1.0643, val acc 0.7880
NCNet pretrain, Epoch [22/30]: loss 0.9920, val acc 0.7940, test acc 0.8040
NCNet pretrain, Epoch [23/30]: loss 0.9271, val acc 0.7880
NCNet pretrain, Epoch [24/30]: loss 0.8850, val acc 0.7860
NCNet pretrain, Epoch [25/30]: loss 0.8621, val acc 0.7860
NCNet pretrain, Epoch [26/30]: loss 0.8014, val acc 0.7940
NCNet pretrain, Epoch [27/30]: loss 0.7447, val acc 0.7940
NCNet pretrain, Epoch [28/30]: loss 0.7133, val acc 0.8000, test acc 0.8170
NCNet pretrain, Epoch [29/30]: loss 0.6589, val acc 0.8000
NCNet pretrain, Epoch [30/30]: loss 0.6284, val acc 0.8000
difference tensor(0.3836, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4458, nc loss 1.4863, ep auc: 0.9779, ep ap 0.9736, val acc 0.7440, test acc 0.7720
difference tensor(1.2456, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4583, nc loss 1.3504, ep auc: 0.9710, ep ap 0.9644, val acc 0.7480, test acc 0.7720
difference tensor(0.5324, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.4880, nc loss 1.2071, ep auc: 0.9629, ep ap 0.9521, val acc 0.7740, test acc 0.8020
difference tensor(0.7715, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5259, nc loss 1.1578, ep auc: 0.9471, ep ap 0.9334, val acc 0.8000, test acc 0.8190
difference tensor(1.0234, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5622, nc loss 1.0907, ep auc: 0.9267, ep ap 0.9108, val acc 0.8140, test acc 0.8280
difference tensor(1.6517, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.5941, nc loss 1.0751, ep auc: 0.8906, ep ap 0.8747, val acc 0.8140, test acc 0.8330
difference tensor(1.0047, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.6165, nc loss 1.0087, ep auc: 0.8456, ep ap 0.8310, val acc 0.8220, test acc 0.8350
difference tensor(1.2988, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.6290, nc loss 1.0014, ep auc: 0.8045, ep ap 0.7916, val acc 0.8180, test acc 0.8350
difference tensor(1.7704, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6363, nc loss 0.9389, ep auc: 0.7844, ep ap 0.7716, val acc 0.8260, test acc 0.8350
difference tensor(1.6216, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6406, nc loss 0.9192, ep auc: 0.7624, ep ap 0.7508, val acc 0.8200, test acc 0.8350
difference tensor(1.5224, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6422, nc loss 0.8826, ep auc: 0.7468, ep ap 0.7362, val acc 0.8040, test acc 0.8350
difference tensor(2.5320, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6444, nc loss 0.8545, ep auc: 0.7302, ep ap 0.7206, val acc 0.7960, test acc 0.8350
difference tensor(2.1859, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6471, nc loss 0.8697, ep auc: 0.7157, ep ap 0.7076, val acc 0.7860, test acc 0.8350
difference tensor(1.4770, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6494, nc loss 0.8215, ep auc: 0.7067, ep ap 0.6991, val acc 0.7840, test acc 0.8350
difference tensor(2.9801, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6530, nc loss 0.7929, ep auc: 0.6983, ep ap 0.6912, val acc 0.7820, test acc 0.8350
difference tensor(2.5959, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6578, nc loss 0.7669, ep auc: 0.6907, ep ap 0.6849, val acc 0.7840, test acc 0.8350
difference tensor(1.6850, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6622, nc loss 0.7803, ep auc: 0.6801, ep ap 0.6750, val acc 0.7800, test acc 0.8350
difference tensor(2.4176, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6663, nc loss 0.7629, ep auc: 0.6751, ep ap 0.6695, val acc 0.7840, test acc 0.8350
difference tensor(2.2058, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6707, nc loss 0.7250, ep auc: 0.6725, ep ap 0.6665, val acc 0.7820, test acc 0.8350
difference tensor(2.5651, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6751, nc loss 0.7287, ep auc: 0.6672, ep ap 0.6604, val acc 0.7840, test acc 0.8350
difference tensor(1.9605, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6792, nc loss 0.7225, ep auc: 0.6571, ep ap 0.6504, val acc 0.7880, test acc 0.8350
difference tensor(2.0748, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6805, nc loss 0.7367, ep auc: 0.6393, ep ap 0.6347, val acc 0.7920, test acc 0.8350
difference tensor(1.8512, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6814, nc loss 0.7270, ep auc: 0.6352, ep ap 0.6303, val acc 0.7940, test acc 0.8350
difference tensor(1.9960, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6822, nc loss 0.7391, ep auc: 0.6299, ep ap 0.6252, val acc 0.7920, test acc 0.8350
difference tensor(1.6021, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6830, nc loss 0.7139, ep auc: 0.6247, ep ap 0.6207, val acc 0.7860, test acc 0.8350
difference tensor(1.6923, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6835, nc loss 0.7151, ep auc: 0.6240, ep ap 0.6202, val acc 0.7840, test acc 0.8350
difference tensor(7.3314, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6837, nc loss 0.7028, ep auc: 0.6223, ep ap 0.6183, val acc 0.7880, test acc 0.8350
difference tensor(2.0444, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6841, nc loss 0.7017, ep auc: 0.6171, ep ap 0.6137, val acc 0.7820, test acc 0.8350
difference tensor(3.0271, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6845, nc loss 0.6917, ep auc: 0.6157, ep ap 0.6125, val acc 0.7860, test acc 0.8350
difference tensor(2.0693, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6851, nc loss 0.6968, ep auc: 0.6134, ep ap 0.6106, val acc 0.7800, test acc 0.8350
difference tensor(2.1181, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6856, nc loss 0.7024, ep auc: 0.6134, ep ap 0.6105, val acc 0.7780, test acc 0.8350
difference tensor(2.2727, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6858, nc loss 0.6953, ep auc: 0.6134, ep ap 0.6105, val acc 0.7740, test acc 0.8350
difference tensor(1.7948, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6863, nc loss 0.6967, ep auc: 0.6112, ep ap 0.6086, val acc 0.7740, test acc 0.8350
difference tensor(2.8558, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6865, nc loss 0.7068, ep auc: 0.6112, ep ap 0.6087, val acc 0.7720, test acc 0.8350
difference tensor(3.1036, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6868, nc loss 0.6840, ep auc: 0.6090, ep ap 0.6068, val acc 0.7720, test acc 0.8350
difference tensor(2.3300, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6872, nc loss 0.7095, ep auc: 0.6083, ep ap 0.6062, val acc 0.7720, test acc 0.8350
difference tensor(1.7670, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6871, nc loss 0.6981, ep auc: 0.6083, ep ap 0.6062, val acc 0.7760, test acc 0.8350
difference tensor(2.1407, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6871, nc loss 0.6922, ep auc: 0.6105, ep ap 0.6084, val acc 0.7780, test acc 0.8350
difference tensor(2.2333, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6877, nc loss 0.6757, ep auc: 0.6120, ep ap 0.6098, val acc 0.7760, test acc 0.8350
difference tensor(2.1587, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6884, nc loss 0.6823, ep auc: 0.6113, ep ap 0.6093, val acc 0.7780, test acc 0.8350
difference tensor(2.0973, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6890, nc loss 0.6924, ep auc: 0.6135, ep ap 0.6112, val acc 0.7840, test acc 0.8350
difference tensor(2.1471, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6893, nc loss 0.6861, ep auc: 0.6142, ep ap 0.6118, val acc 0.7720, test acc 0.8350
difference tensor(3.1479, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6887, nc loss 0.6946, ep auc: 0.6142, ep ap 0.6118, val acc 0.7660, test acc 0.8350
difference tensor(3.6279, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6880, nc loss 0.6713, ep auc: 0.6135, ep ap 0.6112, val acc 0.7660, test acc 0.8350
difference tensor(2.4749, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6872, nc loss 0.6978, ep auc: 0.6120, ep ap 0.6099, val acc 0.7720, test acc 0.8350
difference tensor(1.6186, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6865, nc loss 0.6811, ep auc: 0.6113, ep ap 0.6092, val acc 0.7680, test acc 0.8350
difference tensor(2.9657, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 47/200]: ep loss 0.6857, nc loss 0.6802, ep auc: 0.6113, ep ap 0.6092, val acc 0.7700, test acc 0.8350
difference tensor(2.7043, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 48/200]: ep loss 0.6847, nc loss 0.6751, ep auc: 0.6105, ep ap 0.6086, val acc 0.7740, test acc 0.8350
difference tensor(1.6058, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 49/200]: ep loss 0.6839, nc loss 0.6726, ep auc: 0.6098, ep ap 0.6079, val acc 0.7740, test acc 0.8350
difference tensor(2.3612, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 50/200]: ep loss 0.6832, nc loss 0.6760, ep auc: 0.6090, ep ap 0.6072, val acc 0.7760, test acc 0.8350
difference tensor(2.1161, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 51/200]: ep loss 0.6826, nc loss 0.6713, ep auc: 0.6105, ep ap 0.6084, val acc 0.7740, test acc 0.8350
difference tensor(1.5009, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 52/200]: ep loss 0.6814, nc loss 0.6863, ep auc: 0.6105, ep ap 0.6085, val acc 0.7660, test acc 0.8350
difference tensor(2.3083, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 53/200]: ep loss 0.6798, nc loss 0.6680, ep auc: 0.6120, ep ap 0.6098, val acc 0.7660, test acc 0.8350
difference tensor(1.9615, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 54/200]: ep loss 0.6787, nc loss 0.6775, ep auc: 0.6120, ep ap 0.6100, val acc 0.7680, test acc 0.8350
difference tensor(2.6837, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 55/200]: ep loss 0.6781, nc loss 0.6662, ep auc: 0.6120, ep ap 0.6100, val acc 0.7660, test acc 0.8350
difference tensor(1.6363, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 56/200]: ep loss 0.6778, nc loss 0.6691, ep auc: 0.6113, ep ap 0.6095, val acc 0.7700, test acc 0.8350
difference tensor(1.7815, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 57/200]: ep loss 0.6770, nc loss 0.6646, ep auc: 0.6113, ep ap 0.6095, val acc 0.7680, test acc 0.8350
difference tensor(2.1554, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 58/200]: ep loss 0.6763, nc loss 0.6595, ep auc: 0.6106, ep ap 0.6089, val acc 0.7640, test acc 0.8350
difference tensor(2.4638, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 59/200]: ep loss 0.6758, nc loss 0.6477, ep auc: 0.6106, ep ap 0.6090, val acc 0.7620, test acc 0.8350
difference tensor(1.8382, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 60/200]: ep loss 0.6755, nc loss 0.6692, ep auc: 0.6121, ep ap 0.6102, val acc 0.7660, test acc 0.8350
difference tensor(2.5240, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 61/200]: ep loss 0.6755, nc loss 0.6519, ep auc: 0.6121, ep ap 0.6104, val acc 0.7680, test acc 0.8350
difference tensor(1.4018, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 62/200]: ep loss 0.6752, nc loss 0.6534, ep auc: 0.6121, ep ap 0.6103, val acc 0.7680, test acc 0.8350
difference tensor(3.3561, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 63/200]: ep loss 0.6751, nc loss 0.6635, ep auc: 0.6121, ep ap 0.6102, val acc 0.7720, test acc 0.8350
difference tensor(3.6721, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 64/200]: ep loss 0.6750, nc loss 0.6572, ep auc: 0.6121, ep ap 0.6103, val acc 0.7720, test acc 0.8350
difference tensor(2.5373, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 65/200]: ep loss 0.6752, nc loss 0.6536, ep auc: 0.6121, ep ap 0.6103, val acc 0.7700, test acc 0.8350
difference tensor(1.6035, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 66/200]: ep loss 0.6755, nc loss 0.6522, ep auc: 0.6128, ep ap 0.6108, val acc 0.7640, test acc 0.8350
difference tensor(1.2190, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 67/200]: ep loss 0.6753, nc loss 0.6583, ep auc: 0.6127, ep ap 0.6102, val acc 0.7660, test acc 0.8350
difference tensor(2.2842, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 68/200]: ep loss 0.6751, nc loss 0.6469, ep auc: 0.6127, ep ap 0.6103, val acc 0.7680, test acc 0.8350
difference tensor(1.1862, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 69/200]: ep loss 0.6749, nc loss 0.6430, ep auc: 0.6127, ep ap 0.6103, val acc 0.7600, test acc 0.8350
difference tensor(1.5487, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 70/200]: ep loss 0.6747, nc loss 0.6406, ep auc: 0.6135, ep ap 0.6110, val acc 0.7560, test acc 0.8350
difference tensor(1.8589, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 71/200]: ep loss 0.6744, nc loss 0.6475, ep auc: 0.6135, ep ap 0.6110, val acc 0.7660, test acc 0.8350
difference tensor(1.6746, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 72/200]: ep loss 0.6739, nc loss 0.6524, ep auc: 0.6142, ep ap 0.6117, val acc 0.7700, test acc 0.8350
difference tensor(2.8404, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 73/200]: ep loss 0.6735, nc loss 0.6341, ep auc: 0.6142, ep ap 0.6117, val acc 0.7680, test acc 0.8350
difference tensor(1.6049, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 74/200]: ep loss 0.6733, nc loss 0.6379, ep auc: 0.6150, ep ap 0.6124, val acc 0.7740, test acc 0.8350
difference tensor(2.1211, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 75/200]: ep loss 0.6730, nc loss 0.6351, ep auc: 0.6150, ep ap 0.6125, val acc 0.7720, test acc 0.8350
difference tensor(1.4200, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 76/200]: ep loss 0.6728, nc loss 0.6482, ep auc: 0.6150, ep ap 0.6125, val acc 0.7660, test acc 0.8350
difference tensor(3.9904, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 77/200]: ep loss 0.6727, nc loss 0.6501, ep auc: 0.6142, ep ap 0.6120, val acc 0.7680, test acc 0.8350
difference tensor(1.6719, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 78/200]: ep loss 0.6728, nc loss 0.6247, ep auc: 0.6150, ep ap 0.6126, val acc 0.7660, test acc 0.8350
difference tensor(1.2572, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 79/200]: ep loss 0.6728, nc loss 0.6390, ep auc: 0.6135, ep ap 0.6115, val acc 0.7660, test acc 0.8350
difference tensor(1.4194, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 80/200]: ep loss 0.6729, nc loss 0.6520, ep auc: 0.6143, ep ap 0.6121, val acc 0.7680, test acc 0.8350
difference tensor(5.1489, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 81/200]: ep loss 0.6731, nc loss 0.6308, ep auc: 0.6143, ep ap 0.6121, val acc 0.7680, test acc 0.8350
difference tensor(1.5896, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 82/200]: ep loss 0.6732, nc loss 0.6437, ep auc: 0.6143, ep ap 0.6122, val acc 0.7660, test acc 0.8350
difference tensor(1.8411, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 83/200]: ep loss 0.6733, nc loss 0.6564, ep auc: 0.6143, ep ap 0.6123, val acc 0.7640, test acc 0.8350
difference tensor(2.1091, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 84/200]: ep loss 0.6734, nc loss 0.6452, ep auc: 0.6150, ep ap 0.6129, val acc 0.7700, test acc 0.8350
difference tensor(1.7100, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 85/200]: ep loss 0.6734, nc loss 0.6349, ep auc: 0.6150, ep ap 0.6128, val acc 0.7720, test acc 0.8350
difference tensor(2.3001, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 86/200]: ep loss 0.6734, nc loss 0.6262, ep auc: 0.6150, ep ap 0.6130, val acc 0.7600, test acc 0.8350
difference tensor(1.3654, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 87/200]: ep loss 0.6733, nc loss 0.6296, ep auc: 0.6150, ep ap 0.6129, val acc 0.7640, test acc 0.8350
difference tensor(1.9743, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 88/200]: ep loss 0.6731, nc loss 0.6270, ep auc: 0.6143, ep ap 0.6123, val acc 0.7660, test acc 0.8350
difference tensor(1.9632, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 89/200]: ep loss 0.6727, nc loss 0.6199, ep auc: 0.6143, ep ap 0.6123, val acc 0.7620, test acc 0.8350
difference tensor(1.3780, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 90/200]: ep loss 0.6724, nc loss 0.6392, ep auc: 0.6158, ep ap 0.6136, val acc 0.7660, test acc 0.8350
difference tensor(1.9062, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 91/200]: ep loss 0.6719, nc loss 0.6324, ep auc: 0.6158, ep ap 0.6137, val acc 0.7720, test acc 0.8350
difference tensor(1.8465, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 92/200]: ep loss 0.6716, nc loss 0.6425, ep auc: 0.6164, ep ap 0.6138, val acc 0.7680, test acc 0.8350
difference tensor(1.6114, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 93/200]: ep loss 0.6712, nc loss 0.6280, ep auc: 0.6149, ep ap 0.6125, val acc 0.7660, test acc 0.8350
difference tensor(2.9578, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 94/200]: ep loss 0.6707, nc loss 0.6281, ep auc: 0.6149, ep ap 0.6125, val acc 0.7680, test acc 0.8350
difference tensor(1.3357, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 95/200]: ep loss 0.6703, nc loss 0.6304, ep auc: 0.6149, ep ap 0.6126, val acc 0.7640, test acc 0.8350
difference tensor(2.6909, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 96/200]: ep loss 0.6698, nc loss 0.6234, ep auc: 0.6142, ep ap 0.6120, val acc 0.7620, test acc 0.8350
difference tensor(1.4786, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 97/200]: ep loss 0.6694, nc loss 0.6183, ep auc: 0.6149, ep ap 0.6126, val acc 0.7660, test acc 0.8350
difference tensor(1.3377, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 98/200]: ep loss 0.6690, nc loss 0.6225, ep auc: 0.6149, ep ap 0.6127, val acc 0.7660, test acc 0.8350
difference tensor(2.1450, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 99/200]: ep loss 0.6687, nc loss 0.6256, ep auc: 0.6149, ep ap 0.6127, val acc 0.7680, test acc 0.8350
difference tensor(2.4034, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [100/200]: ep loss 0.6684, nc loss 0.6186, ep auc: 0.6157, ep ap 0.6134, val acc 0.7720, test acc 0.8350
difference tensor(1.5412, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [101/200]: ep loss 0.6680, nc loss 0.6266, ep auc: 0.6149, ep ap 0.6128, val acc 0.7700, test acc 0.8350
difference tensor(2.0472, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [102/200]: ep loss 0.6678, nc loss 0.6230, ep auc: 0.6164, ep ap 0.6141, val acc 0.7660, test acc 0.8350
difference tensor(1.5339, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [103/200]: ep loss 0.6674, nc loss 0.6173, ep auc: 0.6164, ep ap 0.6141, val acc 0.7680, test acc 0.8350
difference tensor(1.2845, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [104/200]: ep loss 0.6670, nc loss 0.6124, ep auc: 0.6179, ep ap 0.6155, val acc 0.7640, test acc 0.8350
difference tensor(2.0545, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [105/200]: ep loss 0.6667, nc loss 0.6144, ep auc: 0.6194, ep ap 0.6167, val acc 0.7700, test acc 0.8350
difference tensor(4.2817, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [106/200]: ep loss 0.6664, nc loss 0.6192, ep auc: 0.6201, ep ap 0.6175, val acc 0.7740, test acc 0.8350
difference tensor(2.2136, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [107/200]: ep loss 0.6663, nc loss 0.6173, ep auc: 0.6209, ep ap 0.6182, val acc 0.7760, test acc 0.8350
Early stop!
Final test acc with early stop: 0.8350, without early stop: 0.8030
Micro F1: 0.834750, std: 0.004710, Max is 0.842000, min is 0.829000
Big Epoch 3/30 dataset is cora fid_frac is 0.1
Big Epoch 4/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8138, ap 0.7994
EPNet pretrain, Epoch [  2/160]: loss 0.6908, auc 0.8126, ap 0.8014
EPNet pretrain, Epoch [  3/160]: loss 0.6839, auc 0.7953, ap 0.7854
EPNet pretrain, Epoch [  4/160]: loss 0.6804, auc 0.7862, ap 0.7798
EPNet pretrain, Epoch [  5/160]: loss 0.6780, auc 0.7821, ap 0.7843
EPNet pretrain, Epoch [  6/160]: loss 0.6745, auc 0.7733, ap 0.7870
EPNet pretrain, Epoch [  7/160]: loss 0.6725, auc 0.7579, ap 0.7832
EPNet pretrain, Epoch [  8/160]: loss 0.6686, auc 0.7427, ap 0.7756
EPNet pretrain, Epoch [  9/160]: loss 0.6636, auc 0.7322, ap 0.7691
EPNet pretrain, Epoch [ 10/160]: loss 0.6594, auc 0.7269, ap 0.7645
EPNet pretrain, Epoch [ 11/160]: loss 0.6543, auc 0.7310, ap 0.7641
EPNet pretrain, Epoch [ 12/160]: loss 0.6483, auc 0.7465, ap 0.7696
EPNet pretrain, Epoch [ 13/160]: loss 0.6431, auc 0.7650, ap 0.7796
EPNet pretrain, Epoch [ 14/160]: loss 0.6374, auc 0.7788, ap 0.7899
EPNet pretrain, Epoch [ 15/160]: loss 0.6310, auc 0.7880, ap 0.7984
EPNet pretrain, Epoch [ 16/160]: loss 0.6250, auc 0.7964, ap 0.8070
EPNet pretrain, Epoch [ 17/160]: loss 0.6194, auc 0.8047, ap 0.8161
EPNet pretrain, Epoch [ 18/160]: loss 0.6140, auc 0.8122, ap 0.8230
EPNet pretrain, Epoch [ 19/160]: loss 0.6095, auc 0.8178, ap 0.8261
EPNet pretrain, Epoch [ 20/160]: loss 0.6049, auc 0.8227, ap 0.8288
EPNet pretrain, Epoch [ 21/160]: loss 0.6004, auc 0.8235, ap 0.8303
EPNet pretrain, Epoch [ 22/160]: loss 0.5964, auc 0.8259, ap 0.8335
EPNet pretrain, Epoch [ 23/160]: loss 0.5925, auc 0.8268, ap 0.8357
EPNet pretrain, Epoch [ 24/160]: loss 0.5884, auc 0.8285, ap 0.8378
EPNet pretrain, Epoch [ 25/160]: loss 0.5845, auc 0.8310, ap 0.8394
EPNet pretrain, Epoch [ 26/160]: loss 0.5810, auc 0.8337, ap 0.8413
EPNet pretrain, Epoch [ 27/160]: loss 0.5779, auc 0.8365, ap 0.8432
EPNet pretrain, Epoch [ 28/160]: loss 0.5753, auc 0.8398, ap 0.8452
EPNet pretrain, Epoch [ 29/160]: loss 0.5730, auc 0.8427, ap 0.8474
EPNet pretrain, Epoch [ 30/160]: loss 0.5704, auc 0.8474, ap 0.8518
EPNet pretrain, Epoch [ 31/160]: loss 0.5677, auc 0.8518, ap 0.8562
EPNet pretrain, Epoch [ 32/160]: loss 0.5652, auc 0.8567, ap 0.8617
EPNet pretrain, Epoch [ 33/160]: loss 0.5631, auc 0.8598, ap 0.8658
EPNet pretrain, Epoch [ 34/160]: loss 0.5610, auc 0.8661, ap 0.8723
EPNet pretrain, Epoch [ 35/160]: loss 0.5590, auc 0.8711, ap 0.8774
EPNet pretrain, Epoch [ 36/160]: loss 0.5572, auc 0.8761, ap 0.8819
EPNet pretrain, Epoch [ 37/160]: loss 0.5555, auc 0.8800, ap 0.8853
EPNet pretrain, Epoch [ 38/160]: loss 0.5535, auc 0.8849, ap 0.8890
EPNet pretrain, Epoch [ 39/160]: loss 0.5511, auc 0.8895, ap 0.8930
EPNet pretrain, Epoch [ 40/160]: loss 0.5486, auc 0.8937, ap 0.8971
EPNet pretrain, Epoch [ 41/160]: loss 0.5461, auc 0.8974, ap 0.9005
EPNet pretrain, Epoch [ 42/160]: loss 0.5437, auc 0.9011, ap 0.9040
EPNet pretrain, Epoch [ 43/160]: loss 0.5412, auc 0.9057, ap 0.9078
EPNet pretrain, Epoch [ 44/160]: loss 0.5388, auc 0.9095, ap 0.9111
EPNet pretrain, Epoch [ 45/160]: loss 0.5364, auc 0.9131, ap 0.9143
EPNet pretrain, Epoch [ 46/160]: loss 0.5340, auc 0.9161, ap 0.9172
EPNet pretrain, Epoch [ 47/160]: loss 0.5315, auc 0.9183, ap 0.9194
EPNet pretrain, Epoch [ 48/160]: loss 0.5290, auc 0.9206, ap 0.9215
EPNet pretrain, Epoch [ 49/160]: loss 0.5266, auc 0.9220, ap 0.9231
EPNet pretrain, Epoch [ 50/160]: loss 0.5242, auc 0.9222, ap 0.9241
EPNet pretrain, Epoch [ 51/160]: loss 0.5221, auc 0.9229, ap 0.9250
EPNet pretrain, Epoch [ 52/160]: loss 0.5202, auc 0.9242, ap 0.9262
EPNet pretrain, Epoch [ 53/160]: loss 0.5185, auc 0.9259, ap 0.9277
EPNet pretrain, Epoch [ 54/160]: loss 0.5169, auc 0.9252, ap 0.9274
EPNet pretrain, Epoch [ 55/160]: loss 0.5153, auc 0.9267, ap 0.9288
EPNet pretrain, Epoch [ 56/160]: loss 0.5138, auc 0.9274, ap 0.9298
EPNet pretrain, Epoch [ 57/160]: loss 0.5124, auc 0.9283, ap 0.9307
EPNet pretrain, Epoch [ 58/160]: loss 0.5111, auc 0.9298, ap 0.9318
EPNet pretrain, Epoch [ 59/160]: loss 0.5097, auc 0.9318, ap 0.9333
EPNet pretrain, Epoch [ 60/160]: loss 0.5084, auc 0.9317, ap 0.9333
EPNet pretrain, Epoch [ 61/160]: loss 0.5072, auc 0.9324, ap 0.9338
EPNet pretrain, Epoch [ 62/160]: loss 0.5060, auc 0.9342, ap 0.9352
EPNet pretrain, Epoch [ 63/160]: loss 0.5048, auc 0.9353, ap 0.9360
EPNet pretrain, Epoch [ 64/160]: loss 0.5037, auc 0.9360, ap 0.9369
EPNet pretrain, Epoch [ 65/160]: loss 0.5026, auc 0.9366, ap 0.9376
EPNet pretrain, Epoch [ 66/160]: loss 0.5015, auc 0.9384, ap 0.9392
EPNet pretrain, Epoch [ 67/160]: loss 0.5004, auc 0.9396, ap 0.9405
EPNet pretrain, Epoch [ 68/160]: loss 0.4993, auc 0.9403, ap 0.9414
EPNet pretrain, Epoch [ 69/160]: loss 0.4983, auc 0.9418, ap 0.9428
EPNet pretrain, Epoch [ 70/160]: loss 0.4973, auc 0.9420, ap 0.9434
EPNet pretrain, Epoch [ 71/160]: loss 0.4962, auc 0.9428, ap 0.9443
EPNet pretrain, Epoch [ 72/160]: loss 0.4953, auc 0.9434, ap 0.9450
EPNet pretrain, Epoch [ 73/160]: loss 0.4943, auc 0.9446, ap 0.9459
EPNet pretrain, Epoch [ 74/160]: loss 0.4934, auc 0.9445, ap 0.9459
EPNet pretrain, Epoch [ 75/160]: loss 0.4925, auc 0.9450, ap 0.9465
EPNet pretrain, Epoch [ 76/160]: loss 0.4915, auc 0.9462, ap 0.9473
EPNet pretrain, Epoch [ 77/160]: loss 0.4907, auc 0.9466, ap 0.9477
EPNet pretrain, Epoch [ 78/160]: loss 0.4898, auc 0.9467, ap 0.9477
EPNet pretrain, Epoch [ 79/160]: loss 0.4890, auc 0.9466, ap 0.9475
EPNet pretrain, Epoch [ 80/160]: loss 0.4882, auc 0.9465, ap 0.9473
EPNet pretrain, Epoch [ 81/160]: loss 0.4875, auc 0.9482, ap 0.9485
EPNet pretrain, Epoch [ 82/160]: loss 0.4867, auc 0.9492, ap 0.9494
EPNet pretrain, Epoch [ 83/160]: loss 0.4860, auc 0.9496, ap 0.9497
EPNet pretrain, Epoch [ 84/160]: loss 0.4854, auc 0.9500, ap 0.9500
EPNet pretrain, Epoch [ 85/160]: loss 0.4847, auc 0.9496, ap 0.9497
EPNet pretrain, Epoch [ 86/160]: loss 0.4841, auc 0.9498, ap 0.9499
EPNet pretrain, Epoch [ 87/160]: loss 0.4834, auc 0.9496, ap 0.9497
EPNet pretrain, Epoch [ 88/160]: loss 0.4827, auc 0.9501, ap 0.9501
EPNet pretrain, Epoch [ 89/160]: loss 0.4821, auc 0.9520, ap 0.9519
EPNet pretrain, Epoch [ 90/160]: loss 0.4815, auc 0.9524, ap 0.9522
EPNet pretrain, Epoch [ 91/160]: loss 0.4808, auc 0.9535, ap 0.9531
EPNet pretrain, Epoch [ 92/160]: loss 0.4802, auc 0.9538, ap 0.9535
EPNet pretrain, Epoch [ 93/160]: loss 0.4796, auc 0.9547, ap 0.9543
EPNet pretrain, Epoch [ 94/160]: loss 0.4790, auc 0.9562, ap 0.9557
EPNet pretrain, Epoch [ 95/160]: loss 0.4784, auc 0.9567, ap 0.9562
EPNet pretrain, Epoch [ 96/160]: loss 0.4778, auc 0.9572, ap 0.9568
EPNet pretrain, Epoch [ 97/160]: loss 0.4772, auc 0.9571, ap 0.9568
EPNet pretrain, Epoch [ 98/160]: loss 0.4766, auc 0.9574, ap 0.9573
EPNet pretrain, Epoch [ 99/160]: loss 0.4760, auc 0.9576, ap 0.9576
EPNet pretrain, Epoch [100/160]: loss 0.4754, auc 0.9585, ap 0.9584
EPNet pretrain, Epoch [101/160]: loss 0.4748, auc 0.9589, ap 0.9589
EPNet pretrain, Epoch [102/160]: loss 0.4742, auc 0.9592, ap 0.9591
EPNet pretrain, Epoch [103/160]: loss 0.4736, auc 0.9596, ap 0.9595
EPNet pretrain, Epoch [104/160]: loss 0.4730, auc 0.9600, ap 0.9598
EPNet pretrain, Epoch [105/160]: loss 0.4724, auc 0.9609, ap 0.9607
EPNet pretrain, Epoch [106/160]: loss 0.4718, auc 0.9614, ap 0.9612
EPNet pretrain, Epoch [107/160]: loss 0.4713, auc 0.9616, ap 0.9615
EPNet pretrain, Epoch [108/160]: loss 0.4707, auc 0.9613, ap 0.9611
EPNet pretrain, Epoch [109/160]: loss 0.4701, auc 0.9614, ap 0.9612
EPNet pretrain, Epoch [110/160]: loss 0.4696, auc 0.9617, ap 0.9614
EPNet pretrain, Epoch [111/160]: loss 0.4690, auc 0.9630, ap 0.9625
EPNet pretrain, Epoch [112/160]: loss 0.4684, auc 0.9626, ap 0.9621
EPNet pretrain, Epoch [113/160]: loss 0.4679, auc 0.9628, ap 0.9623
EPNet pretrain, Epoch [114/160]: loss 0.4673, auc 0.9629, ap 0.9624
EPNet pretrain, Epoch [115/160]: loss 0.4667, auc 0.9630, ap 0.9624
EPNet pretrain, Epoch [116/160]: loss 0.4662, auc 0.9638, ap 0.9630
EPNet pretrain, Epoch [117/160]: loss 0.4657, auc 0.9645, ap 0.9636
EPNet pretrain, Epoch [118/160]: loss 0.4652, auc 0.9641, ap 0.9632
EPNet pretrain, Epoch [119/160]: loss 0.4647, auc 0.9647, ap 0.9638
EPNet pretrain, Epoch [120/160]: loss 0.4643, auc 0.9649, ap 0.9639
EPNet pretrain, Epoch [121/160]: loss 0.4638, auc 0.9645, ap 0.9635
EPNet pretrain, Epoch [122/160]: loss 0.4634, auc 0.9636, ap 0.9627
EPNet pretrain, Epoch [123/160]: loss 0.4630, auc 0.9637, ap 0.9628
EPNet pretrain, Epoch [124/160]: loss 0.4626, auc 0.9638, ap 0.9628
EPNet pretrain, Epoch [125/160]: loss 0.4623, auc 0.9639, ap 0.9629
EPNet pretrain, Epoch [126/160]: loss 0.4619, auc 0.9641, ap 0.9630
EPNet pretrain, Epoch [127/160]: loss 0.4615, auc 0.9643, ap 0.9630
EPNet pretrain, Epoch [128/160]: loss 0.4612, auc 0.9644, ap 0.9632
EPNet pretrain, Epoch [129/160]: loss 0.4608, auc 0.9645, ap 0.9632
EPNet pretrain, Epoch [130/160]: loss 0.4605, auc 0.9646, ap 0.9633
EPNet pretrain, Epoch [131/160]: loss 0.4602, auc 0.9646, ap 0.9634
EPNet pretrain, Epoch [132/160]: loss 0.4598, auc 0.9653, ap 0.9639
EPNet pretrain, Epoch [133/160]: loss 0.4595, auc 0.9653, ap 0.9639
EPNet pretrain, Epoch [134/160]: loss 0.4592, auc 0.9654, ap 0.9640
EPNet pretrain, Epoch [135/160]: loss 0.4589, auc 0.9655, ap 0.9639
EPNet pretrain, Epoch [136/160]: loss 0.4586, auc 0.9655, ap 0.9639
EPNet pretrain, Epoch [137/160]: loss 0.4583, auc 0.9655, ap 0.9640
EPNet pretrain, Epoch [138/160]: loss 0.4580, auc 0.9656, ap 0.9641
EPNet pretrain, Epoch [139/160]: loss 0.4576, auc 0.9657, ap 0.9641
EPNet pretrain, Epoch [140/160]: loss 0.4573, auc 0.9657, ap 0.9641
EPNet pretrain, Epoch [141/160]: loss 0.4570, auc 0.9658, ap 0.9641
EPNet pretrain, Epoch [142/160]: loss 0.4566, auc 0.9658, ap 0.9641
EPNet pretrain, Epoch [143/160]: loss 0.4563, auc 0.9660, ap 0.9642
EPNet pretrain, Epoch [144/160]: loss 0.4560, auc 0.9661, ap 0.9643
EPNet pretrain, Epoch [145/160]: loss 0.4556, auc 0.9661, ap 0.9643
EPNet pretrain, Epoch [146/160]: loss 0.4553, auc 0.9663, ap 0.9644
EPNet pretrain, Epoch [147/160]: loss 0.4550, auc 0.9663, ap 0.9645
EPNet pretrain, Epoch [148/160]: loss 0.4547, auc 0.9664, ap 0.9645
EPNet pretrain, Epoch [149/160]: loss 0.4544, auc 0.9665, ap 0.9646
EPNet pretrain, Epoch [150/160]: loss 0.4541, auc 0.9666, ap 0.9647
EPNet pretrain, Epoch [151/160]: loss 0.4539, auc 0.9667, ap 0.9648
EPNet pretrain, Epoch [152/160]: loss 0.4536, auc 0.9667, ap 0.9649
EPNet pretrain, Epoch [153/160]: loss 0.4533, auc 0.9668, ap 0.9650
EPNet pretrain, Epoch [154/160]: loss 0.4530, auc 0.9669, ap 0.9651
EPNet pretrain, Epoch [155/160]: loss 0.4528, auc 0.9670, ap 0.9652
EPNet pretrain, Epoch [156/160]: loss 0.4525, auc 0.9671, ap 0.9654
EPNet pretrain, Epoch [157/160]: loss 0.4523, auc 0.9673, ap 0.9656
EPNet pretrain, Epoch [158/160]: loss 0.4520, auc 0.9674, ap 0.9657
EPNet pretrain, Epoch [159/160]: loss 0.4518, auc 0.9675, ap 0.9658
EPNet pretrain, Epoch [160/160]: loss 0.4515, auc 0.9682, ap 0.9665
NCNet pretrain, Epoch [ 1/30]: loss 1.9458, val acc 0.3640, test acc 0.3420
NCNet pretrain, Epoch [ 2/30]: loss 1.9279, val acc 0.4420, test acc 0.4350
NCNet pretrain, Epoch [ 3/30]: loss 1.9076, val acc 0.5300, test acc 0.5450
NCNet pretrain, Epoch [ 4/30]: loss 1.8834, val acc 0.5900, test acc 0.6060
NCNet pretrain, Epoch [ 5/30]: loss 1.8571, val acc 0.6480, test acc 0.6620
NCNet pretrain, Epoch [ 6/30]: loss 1.8220, val acc 0.6920, test acc 0.7010
NCNet pretrain, Epoch [ 7/30]: loss 1.7897, val acc 0.7120, test acc 0.7180
NCNet pretrain, Epoch [ 8/30]: loss 1.7503, val acc 0.7100
NCNet pretrain, Epoch [ 9/30]: loss 1.7131, val acc 0.7220, test acc 0.7370
NCNet pretrain, Epoch [10/30]: loss 1.6663, val acc 0.7300, test acc 0.7390
NCNet pretrain, Epoch [11/30]: loss 1.6202, val acc 0.7360, test acc 0.7480
NCNet pretrain, Epoch [12/30]: loss 1.5750, val acc 0.7460, test acc 0.7580
NCNet pretrain, Epoch [13/30]: loss 1.5156, val acc 0.7600, test acc 0.7690
NCNet pretrain, Epoch [14/30]: loss 1.4592, val acc 0.7620, test acc 0.7760
NCNet pretrain, Epoch [15/30]: loss 1.4133, val acc 0.7660, test acc 0.7850
NCNet pretrain, Epoch [16/30]: loss 1.3411, val acc 0.7700, test acc 0.7900
NCNet pretrain, Epoch [17/30]: loss 1.2890, val acc 0.7680
NCNet pretrain, Epoch [18/30]: loss 1.2248, val acc 0.7760, test acc 0.7940
NCNet pretrain, Epoch [19/30]: loss 1.1649, val acc 0.7740
NCNet pretrain, Epoch [20/30]: loss 1.1018, val acc 0.7820, test acc 0.7950
NCNet pretrain, Epoch [21/30]: loss 1.0453, val acc 0.7800
NCNet pretrain, Epoch [22/30]: loss 0.9887, val acc 0.7840, test acc 0.8020
NCNet pretrain, Epoch [23/30]: loss 0.9298, val acc 0.7840
NCNet pretrain, Epoch [24/30]: loss 0.8808, val acc 0.7880, test acc 0.8160
NCNet pretrain, Epoch [25/30]: loss 0.8326, val acc 0.7980, test acc 0.8160
NCNet pretrain, Epoch [26/30]: loss 0.7894, val acc 0.7980
NCNet pretrain, Epoch [27/30]: loss 0.7355, val acc 0.8000, test acc 0.8260
NCNet pretrain, Epoch [28/30]: loss 0.6886, val acc 0.8020, test acc 0.8250
NCNet pretrain, Epoch [29/30]: loss 0.6668, val acc 0.8020
NCNet pretrain, Epoch [30/30]: loss 0.6242, val acc 0.8000
difference tensor(0.3465, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4513, nc loss 1.3723, ep auc: 0.9677, ep ap 0.9661, val acc 0.7760, test acc 0.7870
difference tensor(0.5480, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4642, nc loss 1.2465, ep auc: 0.9598, ep ap 0.9519, val acc 0.7920, test acc 0.8120
difference tensor(0.5126, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.4924, nc loss 1.1428, ep auc: 0.9430, ep ap 0.9274, val acc 0.8140, test acc 0.8320
difference tensor(1.0555, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5255, nc loss 1.0767, ep auc: 0.9189, ep ap 0.8971, val acc 0.8240, test acc 0.8460
difference tensor(0.6733, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5599, nc loss 1.0249, ep auc: 0.8936, ep ap 0.8660, val acc 0.8260, test acc 0.8460
difference tensor(0.8605, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.5888, nc loss 1.0446, ep auc: 0.8590, ep ap 0.8291, val acc 0.8280, test acc 0.8460
difference tensor(1.5227, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.6062, nc loss 0.9998, ep auc: 0.8144, ep ap 0.7866, val acc 0.8160, test acc 0.8460
difference tensor(1.6935, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.6144, nc loss 0.9662, ep auc: 0.7819, ep ap 0.7569, val acc 0.8000, test acc 0.8460
difference tensor(2.2132, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6178, nc loss 0.9375, ep auc: 0.7599, ep ap 0.7380, val acc 0.7960, test acc 0.8460
difference tensor(1.4184, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6183, nc loss 0.9034, ep auc: 0.7527, ep ap 0.7318, val acc 0.7940, test acc 0.8460
difference tensor(1.3880, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6174, nc loss 0.8491, ep auc: 0.7484, ep ap 0.7282, val acc 0.7980, test acc 0.8460
difference tensor(1.9111, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6169, nc loss 0.8429, ep auc: 0.7428, ep ap 0.7240, val acc 0.7980, test acc 0.8460
difference tensor(1.2327, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6158, nc loss 0.8090, ep auc: 0.7328, ep ap 0.7161, val acc 0.8020, test acc 0.8460
difference tensor(3.2548, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6154, nc loss 0.7845, ep auc: 0.7225, ep ap 0.7087, val acc 0.8060, test acc 0.8460
difference tensor(1.7271, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6159, nc loss 0.7622, ep auc: 0.7160, ep ap 0.7036, val acc 0.8140, test acc 0.8460
difference tensor(1.0780, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6175, nc loss 0.7724, ep auc: 0.7169, ep ap 0.7036, val acc 0.8080, test acc 0.8460
difference tensor(1.1040, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6192, nc loss 0.7548, ep auc: 0.7144, ep ap 0.7014, val acc 0.8040, test acc 0.8460
difference tensor(1.2974, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6208, nc loss 0.7512, ep auc: 0.7133, ep ap 0.7012, val acc 0.8000, test acc 0.8460
difference tensor(1.1634, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6230, nc loss 0.7154, ep auc: 0.7116, ep ap 0.6996, val acc 0.7980, test acc 0.8460
difference tensor(1.8946, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6254, nc loss 0.7267, ep auc: 0.7065, ep ap 0.6956, val acc 0.7960, test acc 0.8460
difference tensor(0.8477, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6271, nc loss 0.6967, ep auc: 0.7054, ep ap 0.6943, val acc 0.7960, test acc 0.8460
difference tensor(0.9767, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6284, nc loss 0.6853, ep auc: 0.7012, ep ap 0.6904, val acc 0.7960, test acc 0.8460
difference tensor(1.2872, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6292, nc loss 0.6690, ep auc: 0.6997, ep ap 0.6896, val acc 0.7920, test acc 0.8460
difference tensor(0.8610, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6302, nc loss 0.6955, ep auc: 0.6963, ep ap 0.6860, val acc 0.7880, test acc 0.8460
difference tensor(0.8396, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6308, nc loss 0.6645, ep auc: 0.6885, ep ap 0.6787, val acc 0.7880, test acc 0.8460
difference tensor(0.9884, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6317, nc loss 0.6533, ep auc: 0.6855, ep ap 0.6759, val acc 0.7900, test acc 0.8460
difference tensor(1.1620, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6321, nc loss 0.6703, ep auc: 0.6834, ep ap 0.6741, val acc 0.7880, test acc 0.8460
difference tensor(1.3292, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6327, nc loss 0.6301, ep auc: 0.6805, ep ap 0.6715, val acc 0.7880, test acc 0.8460
difference tensor(0.8600, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6334, nc loss 0.6463, ep auc: 0.6788, ep ap 0.6696, val acc 0.7900, test acc 0.8460
difference tensor(1.2270, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6342, nc loss 0.6560, ep auc: 0.6759, ep ap 0.6670, val acc 0.7920, test acc 0.8460
difference tensor(1.3263, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6351, nc loss 0.6519, ep auc: 0.6683, ep ap 0.6602, val acc 0.7880, test acc 0.8460
difference tensor(1.7993, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6361, nc loss 0.6381, ep auc: 0.6673, ep ap 0.6586, val acc 0.7840, test acc 0.8460
difference tensor(1.7539, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6372, nc loss 0.6504, ep auc: 0.6650, ep ap 0.6563, val acc 0.7820, test acc 0.8460
difference tensor(1.4447, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6382, nc loss 0.6486, ep auc: 0.6635, ep ap 0.6546, val acc 0.7840, test acc 0.8460
difference tensor(2.0538, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6391, nc loss 0.6566, ep auc: 0.6623, ep ap 0.6540, val acc 0.7820, test acc 0.8460
difference tensor(1.3302, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6391, nc loss 0.6571, ep auc: 0.6618, ep ap 0.6540, val acc 0.7840, test acc 0.8460
difference tensor(1.0401, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6391, nc loss 0.6441, ep auc: 0.6599, ep ap 0.6535, val acc 0.7820, test acc 0.8460
difference tensor(1.7368, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6390, nc loss 0.6510, ep auc: 0.6569, ep ap 0.6511, val acc 0.7860, test acc 0.8460
difference tensor(1.4037, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6387, nc loss 0.6547, ep auc: 0.6552, ep ap 0.6512, val acc 0.7880, test acc 0.8460
difference tensor(1.1212, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6394, nc loss 0.6301, ep auc: 0.6552, ep ap 0.6521, val acc 0.7860, test acc 0.8460
difference tensor(1.4045, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6401, nc loss 0.6567, ep auc: 0.6540, ep ap 0.6516, val acc 0.7860, test acc 0.8460
difference tensor(1.8394, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6412, nc loss 0.6489, ep auc: 0.6551, ep ap 0.6523, val acc 0.7820, test acc 0.8460
difference tensor(1.9937, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6421, nc loss 0.6618, ep auc: 0.6544, ep ap 0.6520, val acc 0.7800, test acc 0.8460
difference tensor(0.9977, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6428, nc loss 0.6506, ep auc: 0.6530, ep ap 0.6510, val acc 0.7720, test acc 0.8460
difference tensor(1.2151, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6437, nc loss 0.6319, ep auc: 0.6515, ep ap 0.6495, val acc 0.7680, test acc 0.8460
difference tensor(1.0854, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6444, nc loss 0.6459, ep auc: 0.6493, ep ap 0.6475, val acc 0.7620, test acc 0.8460
difference tensor(3.1761, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 47/200]: ep loss 0.6452, nc loss 0.6498, ep auc: 0.6478, ep ap 0.6461, val acc 0.7640, test acc 0.8460
difference tensor(1.1270, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 48/200]: ep loss 0.6459, nc loss 0.6413, ep auc: 0.6464, ep ap 0.6448, val acc 0.7640, test acc 0.8460
difference tensor(1.4166, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 49/200]: ep loss 0.6464, nc loss 0.6398, ep auc: 0.6483, ep ap 0.6457, val acc 0.7740, test acc 0.8460
difference tensor(1.7536, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 50/200]: ep loss 0.6471, nc loss 0.6422, ep auc: 0.6483, ep ap 0.6456, val acc 0.7780, test acc 0.8460
difference tensor(4.2072, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 51/200]: ep loss 0.6478, nc loss 0.6453, ep auc: 0.6475, ep ap 0.6448, val acc 0.7780, test acc 0.8460
difference tensor(1.8785, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 52/200]: ep loss 0.6485, nc loss 0.6457, ep auc: 0.6475, ep ap 0.6447, val acc 0.7800, test acc 0.8460
difference tensor(1.8737, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 53/200]: ep loss 0.6484, nc loss 0.6295, ep auc: 0.6473, ep ap 0.6442, val acc 0.7860, test acc 0.8460
difference tensor(1.1629, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 54/200]: ep loss 0.6480, nc loss 0.6364, ep auc: 0.6489, ep ap 0.6455, val acc 0.7820, test acc 0.8460
difference tensor(1.0417, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 55/200]: ep loss 0.6478, nc loss 0.6233, ep auc: 0.6480, ep ap 0.6446, val acc 0.7800, test acc 0.8460
difference tensor(1.6286, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 56/200]: ep loss 0.6474, nc loss 0.6377, ep auc: 0.6476, ep ap 0.6438, val acc 0.7800, test acc 0.8460
difference tensor(1.3976, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 57/200]: ep loss 0.6467, nc loss 0.6384, ep auc: 0.6470, ep ap 0.6436, val acc 0.7780, test acc 0.8460
difference tensor(1.4386, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 58/200]: ep loss 0.6460, nc loss 0.6371, ep auc: 0.6456, ep ap 0.6428, val acc 0.7760, test acc 0.8460
difference tensor(0.9594, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 59/200]: ep loss 0.6452, nc loss 0.6349, ep auc: 0.6455, ep ap 0.6427, val acc 0.7760, test acc 0.8460
difference tensor(1.1645, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 60/200]: ep loss 0.6442, nc loss 0.6275, ep auc: 0.6470, ep ap 0.6443, val acc 0.7760, test acc 0.8460
difference tensor(1.4965, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 61/200]: ep loss 0.6434, nc loss 0.6300, ep auc: 0.6458, ep ap 0.6440, val acc 0.7840, test acc 0.8460
difference tensor(1.4063, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 62/200]: ep loss 0.6426, nc loss 0.6181, ep auc: 0.6467, ep ap 0.6455, val acc 0.7820, test acc 0.8460
difference tensor(1.2516, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 63/200]: ep loss 0.6420, nc loss 0.6095, ep auc: 0.6482, ep ap 0.6469, val acc 0.7780, test acc 0.8460
difference tensor(3.2188, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 64/200]: ep loss 0.6415, nc loss 0.6138, ep auc: 0.6483, ep ap 0.6473, val acc 0.7700, test acc 0.8460
difference tensor(1.7629, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 65/200]: ep loss 0.6413, nc loss 0.6262, ep auc: 0.6479, ep ap 0.6464, val acc 0.7680, test acc 0.8460
difference tensor(1.2974, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 66/200]: ep loss 0.6414, nc loss 0.6172, ep auc: 0.6470, ep ap 0.6453, val acc 0.7740, test acc 0.8460
difference tensor(1.2103, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 67/200]: ep loss 0.6416, nc loss 0.6120, ep auc: 0.6458, ep ap 0.6446, val acc 0.7800, test acc 0.8460
difference tensor(1.4187, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 68/200]: ep loss 0.6420, nc loss 0.6239, ep auc: 0.6443, ep ap 0.6433, val acc 0.7780, test acc 0.8460
difference tensor(0.9635, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 69/200]: ep loss 0.6423, nc loss 0.6139, ep auc: 0.6452, ep ap 0.6443, val acc 0.7780, test acc 0.8460
difference tensor(1.1968, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 70/200]: ep loss 0.6427, nc loss 0.6040, ep auc: 0.6452, ep ap 0.6442, val acc 0.7780, test acc 0.8460
difference tensor(1.0402, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 71/200]: ep loss 0.6434, nc loss 0.6255, ep auc: 0.6451, ep ap 0.6440, val acc 0.7800, test acc 0.8460
difference tensor(1.7695, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 72/200]: ep loss 0.6440, nc loss 0.6189, ep auc: 0.6451, ep ap 0.6439, val acc 0.7800, test acc 0.8460
difference tensor(1.5348, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 73/200]: ep loss 0.6445, nc loss 0.6115, ep auc: 0.6451, ep ap 0.6438, val acc 0.7800, test acc 0.8460
difference tensor(1.0784, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 74/200]: ep loss 0.6450, nc loss 0.6099, ep auc: 0.6465, ep ap 0.6449, val acc 0.7780, test acc 0.8460
difference tensor(1.7729, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 75/200]: ep loss 0.6454, nc loss 0.6332, ep auc: 0.6480, ep ap 0.6462, val acc 0.7780, test acc 0.8460
difference tensor(2.8673, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 76/200]: ep loss 0.6454, nc loss 0.6065, ep auc: 0.6488, ep ap 0.6472, val acc 0.7760, test acc 0.8460
difference tensor(1.5536, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 77/200]: ep loss 0.6451, nc loss 0.6064, ep auc: 0.6488, ep ap 0.6474, val acc 0.7760, test acc 0.8460
difference tensor(1.5124, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 78/200]: ep loss 0.6447, nc loss 0.6176, ep auc: 0.6491, ep ap 0.6484, val acc 0.7760, test acc 0.8460
difference tensor(1.7394, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 79/200]: ep loss 0.6446, nc loss 0.6081, ep auc: 0.6484, ep ap 0.6481, val acc 0.7700, test acc 0.8460
difference tensor(1.5678, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 80/200]: ep loss 0.6444, nc loss 0.6195, ep auc: 0.6491, ep ap 0.6489, val acc 0.7720, test acc 0.8460
difference tensor(1.1532, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 81/200]: ep loss 0.6443, nc loss 0.6097, ep auc: 0.6499, ep ap 0.6498, val acc 0.7680, test acc 0.8460
difference tensor(2.4555, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 82/200]: ep loss 0.6446, nc loss 0.6104, ep auc: 0.6499, ep ap 0.6498, val acc 0.7680, test acc 0.8460
difference tensor(1.2744, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 83/200]: ep loss 0.6448, nc loss 0.6117, ep auc: 0.6492, ep ap 0.6492, val acc 0.7680, test acc 0.8460
difference tensor(1.0067, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 84/200]: ep loss 0.6447, nc loss 0.6167, ep auc: 0.6492, ep ap 0.6496, val acc 0.7700, test acc 0.8460
difference tensor(1.3777, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 85/200]: ep loss 0.6446, nc loss 0.6065, ep auc: 0.6477, ep ap 0.6482, val acc 0.7660, test acc 0.8460
difference tensor(1.0184, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 86/200]: ep loss 0.6444, nc loss 0.6183, ep auc: 0.6467, ep ap 0.6473, val acc 0.7660, test acc 0.8460
difference tensor(1.2152, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 87/200]: ep loss 0.6443, nc loss 0.5991, ep auc: 0.6460, ep ap 0.6469, val acc 0.7700, test acc 0.8460
difference tensor(1.8609, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 88/200]: ep loss 0.6444, nc loss 0.6157, ep auc: 0.6455, ep ap 0.6469, val acc 0.7760, test acc 0.8460
difference tensor(1.7122, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 89/200]: ep loss 0.6445, nc loss 0.6101, ep auc: 0.6462, ep ap 0.6475, val acc 0.7680, test acc 0.8460
difference tensor(1.5490, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 90/200]: ep loss 0.6447, nc loss 0.5924, ep auc: 0.6482, ep ap 0.6486, val acc 0.7680, test acc 0.8460
difference tensor(1.6033, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 91/200]: ep loss 0.6450, nc loss 0.6061, ep auc: 0.6467, ep ap 0.6472, val acc 0.7740, test acc 0.8460
difference tensor(1.9404, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 92/200]: ep loss 0.6453, nc loss 0.6171, ep auc: 0.6452, ep ap 0.6459, val acc 0.7720, test acc 0.8460
difference tensor(1.2362, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 93/200]: ep loss 0.6458, nc loss 0.6157, ep auc: 0.6454, ep ap 0.6463, val acc 0.7780, test acc 0.8460
difference tensor(1.9755, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 94/200]: ep loss 0.6464, nc loss 0.6163, ep auc: 0.6476, ep ap 0.6478, val acc 0.7700, test acc 0.8460
difference tensor(2.2376, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 95/200]: ep loss 0.6470, nc loss 0.6049, ep auc: 0.6468, ep ap 0.6471, val acc 0.7780, test acc 0.8460
difference tensor(2.2298, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 96/200]: ep loss 0.6476, nc loss 0.6094, ep auc: 0.6517, ep ap 0.6507, val acc 0.7720, test acc 0.8460
difference tensor(1.6607, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 97/200]: ep loss 0.6484, nc loss 0.6030, ep auc: 0.6516, ep ap 0.6504, val acc 0.7720, test acc 0.8460
difference tensor(4.8679, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 98/200]: ep loss 0.6489, nc loss 0.6219, ep auc: 0.6516, ep ap 0.6503, val acc 0.7760, test acc 0.8460
difference tensor(2.1132, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 99/200]: ep loss 0.6495, nc loss 0.6000, ep auc: 0.6523, ep ap 0.6509, val acc 0.7680, test acc 0.8460
difference tensor(1.7776, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [100/200]: ep loss 0.6497, nc loss 0.5983, ep auc: 0.6531, ep ap 0.6514, val acc 0.7660, test acc 0.8460
difference tensor(1.9639, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [101/200]: ep loss 0.6498, nc loss 0.6080, ep auc: 0.6531, ep ap 0.6515, val acc 0.7720, test acc 0.8460
difference tensor(1.5055, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [102/200]: ep loss 0.6496, nc loss 0.6150, ep auc: 0.6538, ep ap 0.6522, val acc 0.7740, test acc 0.8460
difference tensor(1.8672, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [103/200]: ep loss 0.6493, nc loss 0.5970, ep auc: 0.6538, ep ap 0.6523, val acc 0.7720, test acc 0.8460
difference tensor(2.0345, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [104/200]: ep loss 0.6488, nc loss 0.6104, ep auc: 0.6539, ep ap 0.6527, val acc 0.7640, test acc 0.8460
Early stop!
Final test acc with early stop: 0.8460, without early stop: 0.7910
Micro F1: 0.837000, std: 0.006164, Max is 0.846000, min is 0.829000
Big Epoch 4/30 dataset is cora fid_frac is 0.1
Big Epoch 5/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8685, ap 0.8621
EPNet pretrain, Epoch [  2/160]: loss 0.6910, auc 0.8226, ap 0.8170
EPNet pretrain, Epoch [  3/160]: loss 0.6848, auc 0.8002, ap 0.7973
EPNet pretrain, Epoch [  4/160]: loss 0.6781, auc 0.7888, ap 0.7894
EPNet pretrain, Epoch [  5/160]: loss 0.6829, auc 0.7823, ap 0.7881
EPNet pretrain, Epoch [  6/160]: loss 0.6734, auc 0.7859, ap 0.7938
EPNet pretrain, Epoch [  7/160]: loss 0.6720, auc 0.7959, ap 0.8035
EPNet pretrain, Epoch [  8/160]: loss 0.6709, auc 0.8083, ap 0.8143
EPNet pretrain, Epoch [  9/160]: loss 0.6673, auc 0.8165, ap 0.8213
EPNet pretrain, Epoch [ 10/160]: loss 0.6610, auc 0.8191, ap 0.8233
EPNet pretrain, Epoch [ 11/160]: loss 0.6530, auc 0.8193, ap 0.8231
EPNet pretrain, Epoch [ 12/160]: loss 0.6459, auc 0.8213, ap 0.8242
EPNet pretrain, Epoch [ 13/160]: loss 0.6403, auc 0.8316, ap 0.8329
EPNet pretrain, Epoch [ 14/160]: loss 0.6327, auc 0.8501, ap 0.8500
EPNet pretrain, Epoch [ 15/160]: loss 0.6249, auc 0.8664, ap 0.8632
EPNet pretrain, Epoch [ 16/160]: loss 0.6196, auc 0.8738, ap 0.8652
EPNet pretrain, Epoch [ 17/160]: loss 0.6152, auc 0.8748, ap 0.8629
EPNet pretrain, Epoch [ 18/160]: loss 0.6104, auc 0.8751, ap 0.8639
EPNet pretrain, Epoch [ 19/160]: loss 0.6057, auc 0.8753, ap 0.8671
EPNet pretrain, Epoch [ 20/160]: loss 0.6016, auc 0.8763, ap 0.8711
EPNet pretrain, Epoch [ 21/160]: loss 0.5971, auc 0.8800, ap 0.8773
EPNet pretrain, Epoch [ 22/160]: loss 0.5919, auc 0.8852, ap 0.8841
EPNet pretrain, Epoch [ 23/160]: loss 0.5870, auc 0.8899, ap 0.8897
EPNet pretrain, Epoch [ 24/160]: loss 0.5827, auc 0.8942, ap 0.8945
EPNet pretrain, Epoch [ 25/160]: loss 0.5784, auc 0.8982, ap 0.8988
EPNet pretrain, Epoch [ 26/160]: loss 0.5740, auc 0.9016, ap 0.9021
EPNet pretrain, Epoch [ 27/160]: loss 0.5701, auc 0.9040, ap 0.9044
EPNet pretrain, Epoch [ 28/160]: loss 0.5671, auc 0.9053, ap 0.9054
EPNet pretrain, Epoch [ 29/160]: loss 0.5644, auc 0.9068, ap 0.9063
EPNet pretrain, Epoch [ 30/160]: loss 0.5616, auc 0.9086, ap 0.9077
EPNet pretrain, Epoch [ 31/160]: loss 0.5587, auc 0.9103, ap 0.9090
EPNet pretrain, Epoch [ 32/160]: loss 0.5562, auc 0.9114, ap 0.9097
EPNet pretrain, Epoch [ 33/160]: loss 0.5541, auc 0.9118, ap 0.9100
EPNet pretrain, Epoch [ 34/160]: loss 0.5520, auc 0.9137, ap 0.9108
EPNet pretrain, Epoch [ 35/160]: loss 0.5501, auc 0.9147, ap 0.9107
EPNet pretrain, Epoch [ 36/160]: loss 0.5484, auc 0.9161, ap 0.9111
EPNet pretrain, Epoch [ 37/160]: loss 0.5470, auc 0.9175, ap 0.9114
EPNet pretrain, Epoch [ 38/160]: loss 0.5459, auc 0.9187, ap 0.9118
EPNet pretrain, Epoch [ 39/160]: loss 0.5449, auc 0.9187, ap 0.9120
EPNet pretrain, Epoch [ 40/160]: loss 0.5439, auc 0.9194, ap 0.9128
EPNet pretrain, Epoch [ 41/160]: loss 0.5431, auc 0.9199, ap 0.9131
EPNet pretrain, Epoch [ 42/160]: loss 0.5424, auc 0.9190, ap 0.9123
EPNet pretrain, Epoch [ 43/160]: loss 0.5416, auc 0.9182, ap 0.9116
EPNet pretrain, Epoch [ 44/160]: loss 0.5407, auc 0.9186, ap 0.9115
EPNet pretrain, Epoch [ 45/160]: loss 0.5399, auc 0.9178, ap 0.9105
EPNet pretrain, Epoch [ 46/160]: loss 0.5391, auc 0.9189, ap 0.9112
EPNet pretrain, Epoch [ 47/160]: loss 0.5382, auc 0.9200, ap 0.9121
EPNet pretrain, Epoch [ 48/160]: loss 0.5372, auc 0.9228, ap 0.9145
EPNet pretrain, Epoch [ 49/160]: loss 0.5362, auc 0.9237, ap 0.9157
EPNet pretrain, Epoch [ 50/160]: loss 0.5352, auc 0.9240, ap 0.9161
EPNet pretrain, Epoch [ 51/160]: loss 0.5341, auc 0.9244, ap 0.9165
EPNet pretrain, Epoch [ 52/160]: loss 0.5329, auc 0.9258, ap 0.9179
EPNet pretrain, Epoch [ 53/160]: loss 0.5317, auc 0.9274, ap 0.9195
EPNet pretrain, Epoch [ 54/160]: loss 0.5304, auc 0.9297, ap 0.9214
EPNet pretrain, Epoch [ 55/160]: loss 0.5291, auc 0.9303, ap 0.9224
EPNet pretrain, Epoch [ 56/160]: loss 0.5276, auc 0.9310, ap 0.9239
EPNet pretrain, Epoch [ 57/160]: loss 0.5262, auc 0.9317, ap 0.9256
EPNet pretrain, Epoch [ 58/160]: loss 0.5248, auc 0.9321, ap 0.9267
EPNet pretrain, Epoch [ 59/160]: loss 0.5234, auc 0.9322, ap 0.9277
EPNet pretrain, Epoch [ 60/160]: loss 0.5220, auc 0.9330, ap 0.9287
EPNet pretrain, Epoch [ 61/160]: loss 0.5206, auc 0.9356, ap 0.9311
EPNet pretrain, Epoch [ 62/160]: loss 0.5193, auc 0.9368, ap 0.9323
EPNet pretrain, Epoch [ 63/160]: loss 0.5180, auc 0.9385, ap 0.9339
EPNet pretrain, Epoch [ 64/160]: loss 0.5167, auc 0.9405, ap 0.9357
EPNet pretrain, Epoch [ 65/160]: loss 0.5155, auc 0.9412, ap 0.9365
EPNet pretrain, Epoch [ 66/160]: loss 0.5144, auc 0.9414, ap 0.9370
EPNet pretrain, Epoch [ 67/160]: loss 0.5132, auc 0.9414, ap 0.9373
EPNet pretrain, Epoch [ 68/160]: loss 0.5121, auc 0.9418, ap 0.9378
EPNet pretrain, Epoch [ 69/160]: loss 0.5109, auc 0.9431, ap 0.9392
EPNet pretrain, Epoch [ 70/160]: loss 0.5098, auc 0.9438, ap 0.9400
EPNet pretrain, Epoch [ 71/160]: loss 0.5088, auc 0.9444, ap 0.9409
EPNet pretrain, Epoch [ 72/160]: loss 0.5078, auc 0.9455, ap 0.9418
EPNet pretrain, Epoch [ 73/160]: loss 0.5067, auc 0.9455, ap 0.9419
EPNet pretrain, Epoch [ 74/160]: loss 0.5057, auc 0.9442, ap 0.9409
EPNet pretrain, Epoch [ 75/160]: loss 0.5046, auc 0.9443, ap 0.9409
EPNet pretrain, Epoch [ 76/160]: loss 0.5035, auc 0.9439, ap 0.9405
EPNet pretrain, Epoch [ 77/160]: loss 0.5024, auc 0.9440, ap 0.9406
EPNet pretrain, Epoch [ 78/160]: loss 0.5013, auc 0.9451, ap 0.9415
EPNet pretrain, Epoch [ 79/160]: loss 0.5002, auc 0.9454, ap 0.9419
EPNet pretrain, Epoch [ 80/160]: loss 0.4991, auc 0.9455, ap 0.9421
EPNet pretrain, Epoch [ 81/160]: loss 0.4981, auc 0.9472, ap 0.9436
EPNet pretrain, Epoch [ 82/160]: loss 0.4971, auc 0.9477, ap 0.9441
EPNet pretrain, Epoch [ 83/160]: loss 0.4961, auc 0.9488, ap 0.9449
EPNet pretrain, Epoch [ 84/160]: loss 0.4952, auc 0.9504, ap 0.9462
EPNet pretrain, Epoch [ 85/160]: loss 0.4944, auc 0.9513, ap 0.9471
EPNet pretrain, Epoch [ 86/160]: loss 0.4937, auc 0.9516, ap 0.9474
EPNet pretrain, Epoch [ 87/160]: loss 0.4929, auc 0.9520, ap 0.9475
EPNet pretrain, Epoch [ 88/160]: loss 0.4923, auc 0.9519, ap 0.9473
EPNet pretrain, Epoch [ 89/160]: loss 0.4916, auc 0.9524, ap 0.9475
EPNet pretrain, Epoch [ 90/160]: loss 0.4910, auc 0.9528, ap 0.9478
EPNet pretrain, Epoch [ 91/160]: loss 0.4904, auc 0.9532, ap 0.9482
EPNet pretrain, Epoch [ 92/160]: loss 0.4898, auc 0.9536, ap 0.9486
EPNet pretrain, Epoch [ 93/160]: loss 0.4892, auc 0.9546, ap 0.9494
EPNet pretrain, Epoch [ 94/160]: loss 0.4886, auc 0.9551, ap 0.9498
EPNet pretrain, Epoch [ 95/160]: loss 0.4880, auc 0.9548, ap 0.9496
EPNet pretrain, Epoch [ 96/160]: loss 0.4874, auc 0.9564, ap 0.9509
EPNet pretrain, Epoch [ 97/160]: loss 0.4868, auc 0.9567, ap 0.9511
EPNet pretrain, Epoch [ 98/160]: loss 0.4863, auc 0.9571, ap 0.9512
EPNet pretrain, Epoch [ 99/160]: loss 0.4857, auc 0.9574, ap 0.9513
EPNet pretrain, Epoch [100/160]: loss 0.4852, auc 0.9570, ap 0.9509
EPNet pretrain, Epoch [101/160]: loss 0.4846, auc 0.9573, ap 0.9510
EPNet pretrain, Epoch [102/160]: loss 0.4840, auc 0.9576, ap 0.9515
EPNet pretrain, Epoch [103/160]: loss 0.4835, auc 0.9580, ap 0.9518
EPNet pretrain, Epoch [104/160]: loss 0.4829, auc 0.9583, ap 0.9521
EPNet pretrain, Epoch [105/160]: loss 0.4823, auc 0.9585, ap 0.9525
EPNet pretrain, Epoch [106/160]: loss 0.4817, auc 0.9593, ap 0.9533
EPNet pretrain, Epoch [107/160]: loss 0.4811, auc 0.9607, ap 0.9545
EPNet pretrain, Epoch [108/160]: loss 0.4806, auc 0.9610, ap 0.9548
EPNet pretrain, Epoch [109/160]: loss 0.4800, auc 0.9614, ap 0.9551
EPNet pretrain, Epoch [110/160]: loss 0.4794, auc 0.9616, ap 0.9554
EPNet pretrain, Epoch [111/160]: loss 0.4788, auc 0.9619, ap 0.9557
EPNet pretrain, Epoch [112/160]: loss 0.4783, auc 0.9618, ap 0.9557
EPNet pretrain, Epoch [113/160]: loss 0.4777, auc 0.9620, ap 0.9560
EPNet pretrain, Epoch [114/160]: loss 0.4771, auc 0.9628, ap 0.9567
EPNet pretrain, Epoch [115/160]: loss 0.4765, auc 0.9632, ap 0.9569
EPNet pretrain, Epoch [116/160]: loss 0.4760, auc 0.9634, ap 0.9570
EPNet pretrain, Epoch [117/160]: loss 0.4754, auc 0.9636, ap 0.9571
EPNet pretrain, Epoch [118/160]: loss 0.4748, auc 0.9632, ap 0.9568
EPNet pretrain, Epoch [119/160]: loss 0.4743, auc 0.9635, ap 0.9569
EPNet pretrain, Epoch [120/160]: loss 0.4737, auc 0.9637, ap 0.9571
EPNet pretrain, Epoch [121/160]: loss 0.4732, auc 0.9639, ap 0.9573
EPNet pretrain, Epoch [122/160]: loss 0.4726, auc 0.9648, ap 0.9579
EPNet pretrain, Epoch [123/160]: loss 0.4720, auc 0.9650, ap 0.9582
EPNet pretrain, Epoch [124/160]: loss 0.4715, auc 0.9651, ap 0.9582
EPNet pretrain, Epoch [125/160]: loss 0.4709, auc 0.9653, ap 0.9583
EPNet pretrain, Epoch [126/160]: loss 0.4704, auc 0.9649, ap 0.9581
EPNet pretrain, Epoch [127/160]: loss 0.4698, auc 0.9650, ap 0.9582
EPNet pretrain, Epoch [128/160]: loss 0.4693, auc 0.9640, ap 0.9572
EPNet pretrain, Epoch [129/160]: loss 0.4687, auc 0.9641, ap 0.9571
EPNet pretrain, Epoch [130/160]: loss 0.4682, auc 0.9648, ap 0.9575
EPNet pretrain, Epoch [131/160]: loss 0.4677, auc 0.9650, ap 0.9576
EPNet pretrain, Epoch [132/160]: loss 0.4671, auc 0.9645, ap 0.9571
EPNet pretrain, Epoch [133/160]: loss 0.4666, auc 0.9639, ap 0.9565
EPNet pretrain, Epoch [134/160]: loss 0.4660, auc 0.9642, ap 0.9566
EPNet pretrain, Epoch [135/160]: loss 0.4655, auc 0.9642, ap 0.9567
EPNet pretrain, Epoch [136/160]: loss 0.4649, auc 0.9643, ap 0.9568
EPNet pretrain, Epoch [137/160]: loss 0.4644, auc 0.9651, ap 0.9573
EPNet pretrain, Epoch [138/160]: loss 0.4639, auc 0.9646, ap 0.9569
EPNet pretrain, Epoch [139/160]: loss 0.4634, auc 0.9646, ap 0.9568
EPNet pretrain, Epoch [140/160]: loss 0.4628, auc 0.9649, ap 0.9568
EPNet pretrain, Epoch [141/160]: loss 0.4623, auc 0.9650, ap 0.9570
EPNet pretrain, Epoch [142/160]: loss 0.4618, auc 0.9653, ap 0.9573
EPNet pretrain, Epoch [143/160]: loss 0.4613, auc 0.9661, ap 0.9579
EPNet pretrain, Epoch [144/160]: loss 0.4608, auc 0.9663, ap 0.9581
EPNet pretrain, Epoch [145/160]: loss 0.4603, auc 0.9664, ap 0.9584
EPNet pretrain, Epoch [146/160]: loss 0.4598, auc 0.9679, ap 0.9596
EPNet pretrain, Epoch [147/160]: loss 0.4593, auc 0.9674, ap 0.9594
EPNet pretrain, Epoch [148/160]: loss 0.4587, auc 0.9675, ap 0.9596
EPNet pretrain, Epoch [149/160]: loss 0.4582, auc 0.9677, ap 0.9599
EPNet pretrain, Epoch [150/160]: loss 0.4577, auc 0.9679, ap 0.9604
EPNet pretrain, Epoch [151/160]: loss 0.4571, auc 0.9681, ap 0.9607
EPNet pretrain, Epoch [152/160]: loss 0.4566, auc 0.9681, ap 0.9611
EPNet pretrain, Epoch [153/160]: loss 0.4561, auc 0.9683, ap 0.9614
EPNet pretrain, Epoch [154/160]: loss 0.4555, auc 0.9698, ap 0.9626
EPNet pretrain, Epoch [155/160]: loss 0.4550, auc 0.9701, ap 0.9628
EPNet pretrain, Epoch [156/160]: loss 0.4545, auc 0.9709, ap 0.9637
EPNet pretrain, Epoch [157/160]: loss 0.4540, auc 0.9711, ap 0.9640
EPNet pretrain, Epoch [158/160]: loss 0.4535, auc 0.9706, ap 0.9636
EPNet pretrain, Epoch [159/160]: loss 0.4530, auc 0.9714, ap 0.9645
EPNet pretrain, Epoch [160/160]: loss 0.4525, auc 0.9709, ap 0.9642
NCNet pretrain, Epoch [ 1/30]: loss 1.9453, val acc 0.2720, test acc 0.2900
NCNet pretrain, Epoch [ 2/30]: loss 1.9278, val acc 0.3840, test acc 0.4310
NCNet pretrain, Epoch [ 3/30]: loss 1.9072, val acc 0.3700
NCNet pretrain, Epoch [ 4/30]: loss 1.8805, val acc 0.3920, test acc 0.4250
NCNet pretrain, Epoch [ 5/30]: loss 1.8535, val acc 0.4600, test acc 0.4950
NCNet pretrain, Epoch [ 6/30]: loss 1.8161, val acc 0.5260, test acc 0.5530
NCNet pretrain, Epoch [ 7/30]: loss 1.7826, val acc 0.5940, test acc 0.5980
NCNet pretrain, Epoch [ 8/30]: loss 1.7415, val acc 0.6460, test acc 0.6450
NCNet pretrain, Epoch [ 9/30]: loss 1.7031, val acc 0.6800, test acc 0.6780
NCNet pretrain, Epoch [10/30]: loss 1.6547, val acc 0.7120, test acc 0.7140
NCNet pretrain, Epoch [11/30]: loss 1.6047, val acc 0.7220, test acc 0.7360
NCNet pretrain, Epoch [12/30]: loss 1.5554, val acc 0.7440, test acc 0.7520
NCNet pretrain, Epoch [13/30]: loss 1.5069, val acc 0.7500, test acc 0.7560
NCNet pretrain, Epoch [14/30]: loss 1.4594, val acc 0.7580, test acc 0.7660
NCNet pretrain, Epoch [15/30]: loss 1.3916, val acc 0.7640, test acc 0.7740
NCNet pretrain, Epoch [16/30]: loss 1.3412, val acc 0.7740, test acc 0.7780
NCNet pretrain, Epoch [17/30]: loss 1.2895, val acc 0.7760, test acc 0.7870
NCNet pretrain, Epoch [18/30]: loss 1.2162, val acc 0.7760
NCNet pretrain, Epoch [19/30]: loss 1.1786, val acc 0.7820, test acc 0.7920
NCNet pretrain, Epoch [20/30]: loss 1.1023, val acc 0.7800
NCNet pretrain, Epoch [21/30]: loss 1.0488, val acc 0.7800
NCNet pretrain, Epoch [22/30]: loss 0.9948, val acc 0.7800
NCNet pretrain, Epoch [23/30]: loss 0.9298, val acc 0.7820
NCNet pretrain, Epoch [24/30]: loss 0.8872, val acc 0.7860, test acc 0.8070
NCNet pretrain, Epoch [25/30]: loss 0.8519, val acc 0.7920, test acc 0.8110
NCNet pretrain, Epoch [26/30]: loss 0.8020, val acc 0.7960, test acc 0.8100
NCNet pretrain, Epoch [27/30]: loss 0.7467, val acc 0.7940
NCNet pretrain, Epoch [28/30]: loss 0.7057, val acc 0.7940
NCNet pretrain, Epoch [29/30]: loss 0.6832, val acc 0.7940
NCNet pretrain, Epoch [30/30]: loss 0.6305, val acc 0.7920
difference tensor(0.3194, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4521, nc loss 1.4704, ep auc: 0.9711, ep ap 0.9645, val acc 0.7460, test acc 0.7560
difference tensor(0.5296, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4639, nc loss 1.3540, ep auc: 0.9669, ep ap 0.9577, val acc 0.7480, test acc 0.7630
difference tensor(0.4683, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.4913, nc loss 1.2376, ep auc: 0.9541, ep ap 0.9425, val acc 0.7700, test acc 0.7910
difference tensor(0.4866, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5236, nc loss 1.1898, ep auc: 0.9434, ep ap 0.9293, val acc 0.7960, test acc 0.8050
difference tensor(0.8429, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5561, nc loss 1.1069, ep auc: 0.9153, ep ap 0.9000, val acc 0.8040, test acc 0.8310
difference tensor(0.7554, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.5830, nc loss 1.0206, ep auc: 0.8891, ep ap 0.8728, val acc 0.8080, test acc 0.8350
difference tensor(0.9306, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.6069, nc loss 1.0225, ep auc: 0.8466, ep ap 0.8309, val acc 0.8240, test acc 0.8360
difference tensor(0.9199, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.6238, nc loss 1.0008, ep auc: 0.8187, ep ap 0.8030, val acc 0.8240, test acc 0.8360
difference tensor(1.3526, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6333, nc loss 0.9683, ep auc: 0.7941, ep ap 0.7802, val acc 0.8140, test acc 0.8360
difference tensor(1.3135, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6381, nc loss 0.9449, ep auc: 0.7744, ep ap 0.7609, val acc 0.8140, test acc 0.8360
difference tensor(0.9895, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6405, nc loss 0.9124, ep auc: 0.7526, ep ap 0.7409, val acc 0.8080, test acc 0.8360
difference tensor(1.6002, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6419, nc loss 0.9133, ep auc: 0.7422, ep ap 0.7308, val acc 0.8000, test acc 0.8360
difference tensor(1.0657, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6426, nc loss 0.8405, ep auc: 0.7346, ep ap 0.7238, val acc 0.8020, test acc 0.8360
difference tensor(1.4712, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6426, nc loss 0.8389, ep auc: 0.7309, ep ap 0.7195, val acc 0.8000, test acc 0.8360
difference tensor(1.5161, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6423, nc loss 0.8165, ep auc: 0.7230, ep ap 0.7127, val acc 0.8000, test acc 0.8360
difference tensor(2.6390, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6427, nc loss 0.8130, ep auc: 0.7186, ep ap 0.7089, val acc 0.7960, test acc 0.8360
difference tensor(1.3458, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6431, nc loss 0.8381, ep auc: 0.7122, ep ap 0.7033, val acc 0.8000, test acc 0.8360
difference tensor(2.1032, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6412, nc loss 0.7661, ep auc: 0.7117, ep ap 0.7034, val acc 0.8020, test acc 0.8360
difference tensor(1.2728, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6404, nc loss 0.7545, ep auc: 0.7089, ep ap 0.7013, val acc 0.8100, test acc 0.8360
difference tensor(1.5554, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6403, nc loss 0.7426, ep auc: 0.7092, ep ap 0.7020, val acc 0.8140, test acc 0.8360
difference tensor(3.0870, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6394, nc loss 0.7586, ep auc: 0.7140, ep ap 0.7060, val acc 0.8180, test acc 0.8360
difference tensor(2.0404, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6395, nc loss 0.7440, ep auc: 0.7075, ep ap 0.7004, val acc 0.8120, test acc 0.8360
difference tensor(2.6695, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6395, nc loss 0.7093, ep auc: 0.7024, ep ap 0.6949, val acc 0.8100, test acc 0.8360
difference tensor(1.0919, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6396, nc loss 0.7081, ep auc: 0.6988, ep ap 0.6921, val acc 0.8100, test acc 0.8360
difference tensor(1.0407, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6406, nc loss 0.6799, ep auc: 0.6922, ep ap 0.6863, val acc 0.8020, test acc 0.8360
difference tensor(1.3989, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6411, nc loss 0.6835, ep auc: 0.6888, ep ap 0.6828, val acc 0.8020, test acc 0.8360
difference tensor(1.3585, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6419, nc loss 0.6999, ep auc: 0.6889, ep ap 0.6833, val acc 0.7940, test acc 0.8360
difference tensor(1.2250, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6434, nc loss 0.6756, ep auc: 0.6849, ep ap 0.6796, val acc 0.7960, test acc 0.8360
difference tensor(1.6466, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6451, nc loss 0.6685, ep auc: 0.6844, ep ap 0.6785, val acc 0.7940, test acc 0.8360
difference tensor(1.3372, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6468, nc loss 0.6896, ep auc: 0.6800, ep ap 0.6745, val acc 0.7920, test acc 0.8360
difference tensor(1.6066, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6480, nc loss 0.6824, ep auc: 0.6746, ep ap 0.6692, val acc 0.7920, test acc 0.8360
difference tensor(1.3390, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6494, nc loss 0.6653, ep auc: 0.6704, ep ap 0.6659, val acc 0.7880, test acc 0.8360
difference tensor(4.7964, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6510, nc loss 0.6758, ep auc: 0.6688, ep ap 0.6643, val acc 0.7820, test acc 0.8360
difference tensor(1.5464, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6523, nc loss 0.6641, ep auc: 0.6676, ep ap 0.6635, val acc 0.7820, test acc 0.8360
difference tensor(2.0711, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6538, nc loss 0.6829, ep auc: 0.6688, ep ap 0.6639, val acc 0.7860, test acc 0.8360
difference tensor(2.0422, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6549, nc loss 0.6608, ep auc: 0.6704, ep ap 0.6656, val acc 0.7860, test acc 0.8360
difference tensor(1.3485, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6564, nc loss 0.6545, ep auc: 0.6717, ep ap 0.6667, val acc 0.7840, test acc 0.8360
difference tensor(2.0399, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6576, nc loss 0.6612, ep auc: 0.6697, ep ap 0.6649, val acc 0.7840, test acc 0.8360
difference tensor(1.6712, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6593, nc loss 0.6817, ep auc: 0.6683, ep ap 0.6638, val acc 0.7800, test acc 0.8360
difference tensor(1.8331, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6610, nc loss 0.6722, ep auc: 0.6674, ep ap 0.6614, val acc 0.7800, test acc 0.8360
difference tensor(1.4851, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6623, nc loss 0.6629, ep auc: 0.6654, ep ap 0.6599, val acc 0.7780, test acc 0.8360
difference tensor(3.6019, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6635, nc loss 0.6719, ep auc: 0.6675, ep ap 0.6616, val acc 0.7760, test acc 0.8360
difference tensor(1.5422, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6648, nc loss 0.6407, ep auc: 0.6675, ep ap 0.6615, val acc 0.7760, test acc 0.8360
difference tensor(2.2352, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6663, nc loss 0.6628, ep auc: 0.6645, ep ap 0.6589, val acc 0.7720, test acc 0.8360
difference tensor(2.8111, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6665, nc loss 0.6502, ep auc: 0.6667, ep ap 0.6608, val acc 0.7680, test acc 0.8360
difference tensor(2.2587, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6669, nc loss 0.6590, ep auc: 0.6674, ep ap 0.6613, val acc 0.7680, test acc 0.8360
difference tensor(2.4576, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 47/200]: ep loss 0.6670, nc loss 0.6631, ep auc: 0.6659, ep ap 0.6600, val acc 0.7700, test acc 0.8360
difference tensor(1.9703, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 48/200]: ep loss 0.6668, nc loss 0.6539, ep auc: 0.6660, ep ap 0.6601, val acc 0.7740, test acc 0.8360
difference tensor(2.1941, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 49/200]: ep loss 0.6665, nc loss 0.6815, ep auc: 0.6660, ep ap 0.6600, val acc 0.7760, test acc 0.8360
difference tensor(1.9778, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 50/200]: ep loss 0.6657, nc loss 0.6718, ep auc: 0.6660, ep ap 0.6602, val acc 0.7800, test acc 0.8360
difference tensor(1.8160, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 51/200]: ep loss 0.6647, nc loss 0.6561, ep auc: 0.6646, ep ap 0.6594, val acc 0.7720, test acc 0.8360
difference tensor(1.4783, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 52/200]: ep loss 0.6639, nc loss 0.6620, ep auc: 0.6654, ep ap 0.6616, val acc 0.7760, test acc 0.8360
difference tensor(1.5367, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 53/200]: ep loss 0.6631, nc loss 0.6672, ep auc: 0.6662, ep ap 0.6624, val acc 0.7660, test acc 0.8360
difference tensor(2.2206, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 54/200]: ep loss 0.6624, nc loss 0.6704, ep auc: 0.6663, ep ap 0.6626, val acc 0.7720, test acc 0.8360
difference tensor(2.4734, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 55/200]: ep loss 0.6623, nc loss 0.6775, ep auc: 0.6663, ep ap 0.6626, val acc 0.7740, test acc 0.8360
difference tensor(1.4968, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 56/200]: ep loss 0.6616, nc loss 0.6582, ep auc: 0.6671, ep ap 0.6637, val acc 0.7720, test acc 0.8360
difference tensor(2.2180, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 57/200]: ep loss 0.6611, nc loss 0.6512, ep auc: 0.6671, ep ap 0.6637, val acc 0.7660, test acc 0.8360
difference tensor(1.6689, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 58/200]: ep loss 0.6605, nc loss 0.6467, ep auc: 0.6672, ep ap 0.6639, val acc 0.7620, test acc 0.8360
difference tensor(1.8689, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 59/200]: ep loss 0.6599, nc loss 0.6533, ep auc: 0.6672, ep ap 0.6640, val acc 0.7740, test acc 0.8360
difference tensor(2.6517, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 60/200]: ep loss 0.6595, nc loss 0.6427, ep auc: 0.6679, ep ap 0.6646, val acc 0.7780, test acc 0.8360
difference tensor(1.6275, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 61/200]: ep loss 0.6591, nc loss 0.6367, ep auc: 0.6687, ep ap 0.6654, val acc 0.7720, test acc 0.8360
difference tensor(1.6937, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 62/200]: ep loss 0.6590, nc loss 0.6610, ep auc: 0.6684, ep ap 0.6648, val acc 0.7660, test acc 0.8360
difference tensor(1.6575, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 63/200]: ep loss 0.6588, nc loss 0.6454, ep auc: 0.6684, ep ap 0.6647, val acc 0.7640, test acc 0.8360
difference tensor(1.4283, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 64/200]: ep loss 0.6587, nc loss 0.6382, ep auc: 0.6684, ep ap 0.6647, val acc 0.7660, test acc 0.8360
difference tensor(1.5129, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 65/200]: ep loss 0.6587, nc loss 0.6482, ep auc: 0.6692, ep ap 0.6652, val acc 0.7700, test acc 0.8360
difference tensor(1.6155, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 66/200]: ep loss 0.6589, nc loss 0.6225, ep auc: 0.6692, ep ap 0.6652, val acc 0.7800, test acc 0.8360
difference tensor(1.5840, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 67/200]: ep loss 0.6593, nc loss 0.6311, ep auc: 0.6689, ep ap 0.6657, val acc 0.7760, test acc 0.8360
difference tensor(2.0599, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 68/200]: ep loss 0.6597, nc loss 0.6305, ep auc: 0.6689, ep ap 0.6656, val acc 0.7740, test acc 0.8360
difference tensor(1.4724, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 69/200]: ep loss 0.6603, nc loss 0.6422, ep auc: 0.6696, ep ap 0.6660, val acc 0.7700, test acc 0.8360
difference tensor(2.3816, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 70/200]: ep loss 0.6610, nc loss 0.6286, ep auc: 0.6681, ep ap 0.6648, val acc 0.7740, test acc 0.8360
difference tensor(1.4471, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 71/200]: ep loss 0.6616, nc loss 0.6401, ep auc: 0.6656, ep ap 0.6635, val acc 0.7740, test acc 0.8360
difference tensor(5.5653, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 72/200]: ep loss 0.6618, nc loss 0.6362, ep auc: 0.6673, ep ap 0.6640, val acc 0.7780, test acc 0.8360
difference tensor(2.3095, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 73/200]: ep loss 0.6620, nc loss 0.6352, ep auc: 0.6666, ep ap 0.6632, val acc 0.7740, test acc 0.8360
difference tensor(1.7466, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 74/200]: ep loss 0.6621, nc loss 0.6374, ep auc: 0.6663, ep ap 0.6626, val acc 0.7720, test acc 0.8360
difference tensor(1.6406, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 75/200]: ep loss 0.6621, nc loss 0.6217, ep auc: 0.6649, ep ap 0.6614, val acc 0.7760, test acc 0.8360
difference tensor(2.7957, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 76/200]: ep loss 0.6616, nc loss 0.6313, ep auc: 0.6656, ep ap 0.6620, val acc 0.7700, test acc 0.8360
difference tensor(1.8321, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 77/200]: ep loss 0.6614, nc loss 0.6304, ep auc: 0.6649, ep ap 0.6613, val acc 0.7740, test acc 0.8360
difference tensor(1.6199, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 78/200]: ep loss 0.6614, nc loss 0.6299, ep auc: 0.6663, ep ap 0.6612, val acc 0.7720, test acc 0.8360
difference tensor(3.2524, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 79/200]: ep loss 0.6610, nc loss 0.6380, ep auc: 0.6660, ep ap 0.6606, val acc 0.7720, test acc 0.8360
difference tensor(1.7520, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 80/200]: ep loss 0.6608, nc loss 0.6233, ep auc: 0.6660, ep ap 0.6606, val acc 0.7820, test acc 0.8360
difference tensor(2.4455, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 81/200]: ep loss 0.6607, nc loss 0.6196, ep auc: 0.6675, ep ap 0.6618, val acc 0.7820, test acc 0.8360
difference tensor(2.2205, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 82/200]: ep loss 0.6610, nc loss 0.6310, ep auc: 0.6660, ep ap 0.6602, val acc 0.7800, test acc 0.8360
difference tensor(5.3768, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 83/200]: ep loss 0.6611, nc loss 0.6211, ep auc: 0.6652, ep ap 0.6609, val acc 0.7800, test acc 0.8360
difference tensor(2.1334, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 84/200]: ep loss 0.6612, nc loss 0.6201, ep auc: 0.6674, ep ap 0.6626, val acc 0.7820, test acc 0.8360
difference tensor(1.6373, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 85/200]: ep loss 0.6611, nc loss 0.6283, ep auc: 0.6689, ep ap 0.6638, val acc 0.7780, test acc 0.8360
difference tensor(1.8102, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 86/200]: ep loss 0.6609, nc loss 0.6140, ep auc: 0.6696, ep ap 0.6644, val acc 0.7760, test acc 0.8360
difference tensor(1.8760, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 87/200]: ep loss 0.6608, nc loss 0.6297, ep auc: 0.6710, ep ap 0.6655, val acc 0.7640, test acc 0.8360
difference tensor(1.8357, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 88/200]: ep loss 0.6607, nc loss 0.6312, ep auc: 0.6718, ep ap 0.6662, val acc 0.7720, test acc 0.8360
difference tensor(1.6966, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 89/200]: ep loss 0.6606, nc loss 0.6303, ep auc: 0.6720, ep ap 0.6669, val acc 0.7780, test acc 0.8360
difference tensor(2.2321, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 90/200]: ep loss 0.6602, nc loss 0.6298, ep auc: 0.6723, ep ap 0.6675, val acc 0.7820, test acc 0.8360
difference tensor(2.2943, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 91/200]: ep loss 0.6597, nc loss 0.6190, ep auc: 0.6731, ep ap 0.6682, val acc 0.7760, test acc 0.8360
difference tensor(2.4310, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 92/200]: ep loss 0.6594, nc loss 0.6247, ep auc: 0.6782, ep ap 0.6728, val acc 0.7740, test acc 0.8360
difference tensor(1.5634, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 93/200]: ep loss 0.6587, nc loss 0.6412, ep auc: 0.6803, ep ap 0.6743, val acc 0.7760, test acc 0.8360
difference tensor(2.0209, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 94/200]: ep loss 0.6577, nc loss 0.6262, ep auc: 0.6820, ep ap 0.6752, val acc 0.7740, test acc 0.8360
difference tensor(1.8083, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 95/200]: ep loss 0.6568, nc loss 0.6326, ep auc: 0.6828, ep ap 0.6763, val acc 0.7700, test acc 0.8360
difference tensor(1.7315, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 96/200]: ep loss 0.6554, nc loss 0.6182, ep auc: 0.6836, ep ap 0.6773, val acc 0.7700, test acc 0.8360
difference tensor(2.0306, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 97/200]: ep loss 0.6539, nc loss 0.6164, ep auc: 0.6804, ep ap 0.6752, val acc 0.7660, test acc 0.8360
difference tensor(1.4223, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 98/200]: ep loss 0.6529, nc loss 0.6052, ep auc: 0.6805, ep ap 0.6753, val acc 0.7620, test acc 0.8360
difference tensor(1.7238, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 99/200]: ep loss 0.6521, nc loss 0.6366, ep auc: 0.6798, ep ap 0.6748, val acc 0.7780, test acc 0.8360
difference tensor(2.7167, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [100/200]: ep loss 0.6520, nc loss 0.6318, ep auc: 0.6798, ep ap 0.6749, val acc 0.7760, test acc 0.8360
difference tensor(1.8558, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [101/200]: ep loss 0.6520, nc loss 0.6122, ep auc: 0.6813, ep ap 0.6749, val acc 0.7820, test acc 0.8360
difference tensor(1.9826, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [102/200]: ep loss 0.6527, nc loss 0.6183, ep auc: 0.6827, ep ap 0.6760, val acc 0.7840, test acc 0.8360
difference tensor(2.2556, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [103/200]: ep loss 0.6534, nc loss 0.6326, ep auc: 0.6827, ep ap 0.6760, val acc 0.7860, test acc 0.8360
difference tensor(2.5120, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [104/200]: ep loss 0.6542, nc loss 0.6223, ep auc: 0.6826, ep ap 0.6757, val acc 0.7840, test acc 0.8360
difference tensor(1.5274, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [105/200]: ep loss 0.6549, nc loss 0.6071, ep auc: 0.6796, ep ap 0.6752, val acc 0.7820, test acc 0.8360
difference tensor(1.6785, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [106/200]: ep loss 0.6555, nc loss 0.6119, ep auc: 0.6817, ep ap 0.6767, val acc 0.7820, test acc 0.8360
difference tensor(1.1062, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [107/200]: ep loss 0.6559, nc loss 0.6289, ep auc: 0.6810, ep ap 0.6761, val acc 0.7780, test acc 0.8360
Early stop!
Final test acc with early stop: 0.8360, without early stop: 0.7890
Micro F1: 0.836833, std: 0.005640, Max is 0.846000, min is 0.829000
Big Epoch 5/30 dataset is cora fid_frac is 0.1
Big Epoch 6/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8351, ap 0.8238
EPNet pretrain, Epoch [  2/160]: loss 0.6906, auc 0.8075, ap 0.8033
EPNet pretrain, Epoch [  3/160]: loss 0.6837, auc 0.7948, ap 0.7917
EPNet pretrain, Epoch [  4/160]: loss 0.6802, auc 0.7892, ap 0.7882
EPNet pretrain, Epoch [  5/160]: loss 0.6780, auc 0.7848, ap 0.7899
EPNet pretrain, Epoch [  6/160]: loss 0.6743, auc 0.7757, ap 0.7896
EPNet pretrain, Epoch [  7/160]: loss 0.6724, auc 0.7622, ap 0.7852
EPNet pretrain, Epoch [  8/160]: loss 0.6688, auc 0.7496, ap 0.7800
EPNet pretrain, Epoch [  9/160]: loss 0.6639, auc 0.7411, ap 0.7754
EPNet pretrain, Epoch [ 10/160]: loss 0.6593, auc 0.7364, ap 0.7721
EPNet pretrain, Epoch [ 11/160]: loss 0.6543, auc 0.7384, ap 0.7727
EPNet pretrain, Epoch [ 12/160]: loss 0.6479, auc 0.7502, ap 0.7790
EPNet pretrain, Epoch [ 13/160]: loss 0.6417, auc 0.7695, ap 0.7909
EPNet pretrain, Epoch [ 14/160]: loss 0.6355, auc 0.7904, ap 0.8054
EPNet pretrain, Epoch [ 15/160]: loss 0.6282, auc 0.8065, ap 0.8183
EPNet pretrain, Epoch [ 16/160]: loss 0.6205, auc 0.8196, ap 0.8306
EPNet pretrain, Epoch [ 17/160]: loss 0.6131, auc 0.8331, ap 0.8433
EPNet pretrain, Epoch [ 18/160]: loss 0.6065, auc 0.8447, ap 0.8540
EPNet pretrain, Epoch [ 19/160]: loss 0.6012, auc 0.8532, ap 0.8601
EPNet pretrain, Epoch [ 20/160]: loss 0.5968, auc 0.8584, ap 0.8629
EPNet pretrain, Epoch [ 21/160]: loss 0.5929, auc 0.8641, ap 0.8665
EPNet pretrain, Epoch [ 22/160]: loss 0.5902, auc 0.8685, ap 0.8696
EPNet pretrain, Epoch [ 23/160]: loss 0.5885, auc 0.8716, ap 0.8718
EPNet pretrain, Epoch [ 24/160]: loss 0.5869, auc 0.8740, ap 0.8735
EPNet pretrain, Epoch [ 25/160]: loss 0.5853, auc 0.8772, ap 0.8766
EPNet pretrain, Epoch [ 26/160]: loss 0.5834, auc 0.8812, ap 0.8811
EPNet pretrain, Epoch [ 27/160]: loss 0.5813, auc 0.8863, ap 0.8865
EPNet pretrain, Epoch [ 28/160]: loss 0.5792, auc 0.8899, ap 0.8912
EPNet pretrain, Epoch [ 29/160]: loss 0.5773, auc 0.8940, ap 0.8959
EPNet pretrain, Epoch [ 30/160]: loss 0.5752, auc 0.8977, ap 0.9003
EPNet pretrain, Epoch [ 31/160]: loss 0.5727, auc 0.9018, ap 0.9041
EPNet pretrain, Epoch [ 32/160]: loss 0.5704, auc 0.9053, ap 0.9073
EPNet pretrain, Epoch [ 33/160]: loss 0.5679, auc 0.9094, ap 0.9112
EPNet pretrain, Epoch [ 34/160]: loss 0.5652, auc 0.9147, ap 0.9165
EPNet pretrain, Epoch [ 35/160]: loss 0.5625, auc 0.9194, ap 0.9217
EPNet pretrain, Epoch [ 36/160]: loss 0.5598, auc 0.9229, ap 0.9258
EPNet pretrain, Epoch [ 37/160]: loss 0.5571, auc 0.9258, ap 0.9286
EPNet pretrain, Epoch [ 38/160]: loss 0.5543, auc 0.9283, ap 0.9306
EPNet pretrain, Epoch [ 39/160]: loss 0.5514, auc 0.9315, ap 0.9328
EPNet pretrain, Epoch [ 40/160]: loss 0.5485, auc 0.9337, ap 0.9346
EPNet pretrain, Epoch [ 41/160]: loss 0.5455, auc 0.9358, ap 0.9366
EPNet pretrain, Epoch [ 42/160]: loss 0.5426, auc 0.9379, ap 0.9385
EPNet pretrain, Epoch [ 43/160]: loss 0.5397, auc 0.9389, ap 0.9396
EPNet pretrain, Epoch [ 44/160]: loss 0.5371, auc 0.9411, ap 0.9413
EPNet pretrain, Epoch [ 45/160]: loss 0.5345, auc 0.9437, ap 0.9434
EPNet pretrain, Epoch [ 46/160]: loss 0.5319, auc 0.9453, ap 0.9450
EPNet pretrain, Epoch [ 47/160]: loss 0.5295, auc 0.9462, ap 0.9460
EPNet pretrain, Epoch [ 48/160]: loss 0.5272, auc 0.9466, ap 0.9462
EPNet pretrain, Epoch [ 49/160]: loss 0.5250, auc 0.9477, ap 0.9471
EPNet pretrain, Epoch [ 50/160]: loss 0.5229, auc 0.9473, ap 0.9467
EPNet pretrain, Epoch [ 51/160]: loss 0.5209, auc 0.9484, ap 0.9471
EPNet pretrain, Epoch [ 52/160]: loss 0.5191, auc 0.9486, ap 0.9471
EPNet pretrain, Epoch [ 53/160]: loss 0.5175, auc 0.9493, ap 0.9475
EPNet pretrain, Epoch [ 54/160]: loss 0.5160, auc 0.9487, ap 0.9469
EPNet pretrain, Epoch [ 55/160]: loss 0.5147, auc 0.9495, ap 0.9474
EPNet pretrain, Epoch [ 56/160]: loss 0.5134, auc 0.9500, ap 0.9477
EPNet pretrain, Epoch [ 57/160]: loss 0.5121, auc 0.9506, ap 0.9481
EPNet pretrain, Epoch [ 58/160]: loss 0.5108, auc 0.9505, ap 0.9480
EPNet pretrain, Epoch [ 59/160]: loss 0.5094, auc 0.9511, ap 0.9485
EPNet pretrain, Epoch [ 60/160]: loss 0.5079, auc 0.9511, ap 0.9484
EPNet pretrain, Epoch [ 61/160]: loss 0.5065, auc 0.9514, ap 0.9487
EPNet pretrain, Epoch [ 62/160]: loss 0.5050, auc 0.9515, ap 0.9488
EPNet pretrain, Epoch [ 63/160]: loss 0.5035, auc 0.9521, ap 0.9492
EPNet pretrain, Epoch [ 64/160]: loss 0.5021, auc 0.9526, ap 0.9498
EPNet pretrain, Epoch [ 65/160]: loss 0.5008, auc 0.9531, ap 0.9499
EPNet pretrain, Epoch [ 66/160]: loss 0.4996, auc 0.9536, ap 0.9503
EPNet pretrain, Epoch [ 67/160]: loss 0.4985, auc 0.9537, ap 0.9503
EPNet pretrain, Epoch [ 68/160]: loss 0.4976, auc 0.9542, ap 0.9506
EPNet pretrain, Epoch [ 69/160]: loss 0.4967, auc 0.9545, ap 0.9502
EPNet pretrain, Epoch [ 70/160]: loss 0.4958, auc 0.9554, ap 0.9509
EPNet pretrain, Epoch [ 71/160]: loss 0.4949, auc 0.9556, ap 0.9513
EPNet pretrain, Epoch [ 72/160]: loss 0.4939, auc 0.9554, ap 0.9519
EPNet pretrain, Epoch [ 73/160]: loss 0.4930, auc 0.9554, ap 0.9524
EPNet pretrain, Epoch [ 74/160]: loss 0.4919, auc 0.9560, ap 0.9532
EPNet pretrain, Epoch [ 75/160]: loss 0.4909, auc 0.9566, ap 0.9543
EPNet pretrain, Epoch [ 76/160]: loss 0.4899, auc 0.9577, ap 0.9553
EPNet pretrain, Epoch [ 77/160]: loss 0.4890, auc 0.9582, ap 0.9560
EPNet pretrain, Epoch [ 78/160]: loss 0.4881, auc 0.9583, ap 0.9566
EPNet pretrain, Epoch [ 79/160]: loss 0.4872, auc 0.9588, ap 0.9575
EPNet pretrain, Epoch [ 80/160]: loss 0.4863, auc 0.9593, ap 0.9582
EPNet pretrain, Epoch [ 81/160]: loss 0.4854, auc 0.9598, ap 0.9589
EPNet pretrain, Epoch [ 82/160]: loss 0.4846, auc 0.9604, ap 0.9595
EPNet pretrain, Epoch [ 83/160]: loss 0.4838, auc 0.9603, ap 0.9597
EPNet pretrain, Epoch [ 84/160]: loss 0.4830, auc 0.9606, ap 0.9602
EPNet pretrain, Epoch [ 85/160]: loss 0.4822, auc 0.9610, ap 0.9605
EPNet pretrain, Epoch [ 86/160]: loss 0.4815, auc 0.9615, ap 0.9610
EPNet pretrain, Epoch [ 87/160]: loss 0.4807, auc 0.9620, ap 0.9615
EPNet pretrain, Epoch [ 88/160]: loss 0.4800, auc 0.9624, ap 0.9619
EPNet pretrain, Epoch [ 89/160]: loss 0.4793, auc 0.9628, ap 0.9622
EPNet pretrain, Epoch [ 90/160]: loss 0.4786, auc 0.9631, ap 0.9626
EPNet pretrain, Epoch [ 91/160]: loss 0.4779, auc 0.9634, ap 0.9629
EPNet pretrain, Epoch [ 92/160]: loss 0.4773, auc 0.9630, ap 0.9626
EPNet pretrain, Epoch [ 93/160]: loss 0.4767, auc 0.9637, ap 0.9632
EPNet pretrain, Epoch [ 94/160]: loss 0.4760, auc 0.9646, ap 0.9640
EPNet pretrain, Epoch [ 95/160]: loss 0.4754, auc 0.9643, ap 0.9637
EPNet pretrain, Epoch [ 96/160]: loss 0.4748, auc 0.9641, ap 0.9636
EPNet pretrain, Epoch [ 97/160]: loss 0.4743, auc 0.9644, ap 0.9638
EPNet pretrain, Epoch [ 98/160]: loss 0.4737, auc 0.9652, ap 0.9646
EPNet pretrain, Epoch [ 99/160]: loss 0.4731, auc 0.9661, ap 0.9654
EPNet pretrain, Epoch [100/160]: loss 0.4726, auc 0.9664, ap 0.9656
EPNet pretrain, Epoch [101/160]: loss 0.4720, auc 0.9667, ap 0.9659
EPNet pretrain, Epoch [102/160]: loss 0.4715, auc 0.9670, ap 0.9662
EPNet pretrain, Epoch [103/160]: loss 0.4710, auc 0.9677, ap 0.9669
EPNet pretrain, Epoch [104/160]: loss 0.4705, auc 0.9687, ap 0.9677
EPNet pretrain, Epoch [105/160]: loss 0.4700, auc 0.9695, ap 0.9684
EPNet pretrain, Epoch [106/160]: loss 0.4695, auc 0.9692, ap 0.9682
EPNet pretrain, Epoch [107/160]: loss 0.4691, auc 0.9693, ap 0.9683
EPNet pretrain, Epoch [108/160]: loss 0.4686, auc 0.9695, ap 0.9685
EPNet pretrain, Epoch [109/160]: loss 0.4681, auc 0.9698, ap 0.9688
EPNet pretrain, Epoch [110/160]: loss 0.4676, auc 0.9700, ap 0.9690
EPNet pretrain, Epoch [111/160]: loss 0.4671, auc 0.9696, ap 0.9687
EPNet pretrain, Epoch [112/160]: loss 0.4666, auc 0.9698, ap 0.9689
EPNet pretrain, Epoch [113/160]: loss 0.4661, auc 0.9700, ap 0.9691
EPNet pretrain, Epoch [114/160]: loss 0.4656, auc 0.9702, ap 0.9692
EPNet pretrain, Epoch [115/160]: loss 0.4651, auc 0.9703, ap 0.9692
EPNet pretrain, Epoch [116/160]: loss 0.4647, auc 0.9705, ap 0.9693
EPNet pretrain, Epoch [117/160]: loss 0.4642, auc 0.9711, ap 0.9699
EPNet pretrain, Epoch [118/160]: loss 0.4637, auc 0.9713, ap 0.9699
EPNet pretrain, Epoch [119/160]: loss 0.4633, auc 0.9715, ap 0.9700
EPNet pretrain, Epoch [120/160]: loss 0.4629, auc 0.9721, ap 0.9705
EPNet pretrain, Epoch [121/160]: loss 0.4624, auc 0.9721, ap 0.9704
EPNet pretrain, Epoch [122/160]: loss 0.4620, auc 0.9722, ap 0.9705
EPNet pretrain, Epoch [123/160]: loss 0.4615, auc 0.9717, ap 0.9701
EPNet pretrain, Epoch [124/160]: loss 0.4611, auc 0.9719, ap 0.9702
EPNet pretrain, Epoch [125/160]: loss 0.4606, auc 0.9720, ap 0.9702
EPNet pretrain, Epoch [126/160]: loss 0.4602, auc 0.9727, ap 0.9708
EPNet pretrain, Epoch [127/160]: loss 0.4597, auc 0.9729, ap 0.9709
EPNet pretrain, Epoch [128/160]: loss 0.4593, auc 0.9730, ap 0.9709
EPNet pretrain, Epoch [129/160]: loss 0.4588, auc 0.9731, ap 0.9709
EPNet pretrain, Epoch [130/160]: loss 0.4584, auc 0.9732, ap 0.9710
EPNet pretrain, Epoch [131/160]: loss 0.4579, auc 0.9733, ap 0.9710
EPNet pretrain, Epoch [132/160]: loss 0.4574, auc 0.9734, ap 0.9711
EPNet pretrain, Epoch [133/160]: loss 0.4570, auc 0.9735, ap 0.9711
EPNet pretrain, Epoch [134/160]: loss 0.4565, auc 0.9736, ap 0.9712
EPNet pretrain, Epoch [135/160]: loss 0.4561, auc 0.9737, ap 0.9712
EPNet pretrain, Epoch [136/160]: loss 0.4556, auc 0.9738, ap 0.9711
EPNet pretrain, Epoch [137/160]: loss 0.4552, auc 0.9743, ap 0.9716
EPNet pretrain, Epoch [138/160]: loss 0.4548, auc 0.9737, ap 0.9711
EPNet pretrain, Epoch [139/160]: loss 0.4544, auc 0.9731, ap 0.9705
EPNet pretrain, Epoch [140/160]: loss 0.4540, auc 0.9731, ap 0.9705
EPNet pretrain, Epoch [141/160]: loss 0.4536, auc 0.9731, ap 0.9704
EPNet pretrain, Epoch [142/160]: loss 0.4532, auc 0.9737, ap 0.9708
EPNet pretrain, Epoch [143/160]: loss 0.4528, auc 0.9744, ap 0.9712
EPNet pretrain, Epoch [144/160]: loss 0.4524, auc 0.9738, ap 0.9706
EPNet pretrain, Epoch [145/160]: loss 0.4520, auc 0.9739, ap 0.9706
EPNet pretrain, Epoch [146/160]: loss 0.4516, auc 0.9739, ap 0.9705
EPNet pretrain, Epoch [147/160]: loss 0.4512, auc 0.9740, ap 0.9705
EPNet pretrain, Epoch [148/160]: loss 0.4508, auc 0.9740, ap 0.9704
EPNet pretrain, Epoch [149/160]: loss 0.4505, auc 0.9746, ap 0.9708
EPNet pretrain, Epoch [150/160]: loss 0.4501, auc 0.9753, ap 0.9713
EPNet pretrain, Epoch [151/160]: loss 0.4497, auc 0.9754, ap 0.9713
EPNet pretrain, Epoch [152/160]: loss 0.4494, auc 0.9760, ap 0.9718
EPNet pretrain, Epoch [153/160]: loss 0.4491, auc 0.9753, ap 0.9711
EPNet pretrain, Epoch [154/160]: loss 0.4488, auc 0.9760, ap 0.9715
EPNet pretrain, Epoch [155/160]: loss 0.4485, auc 0.9760, ap 0.9714
EPNet pretrain, Epoch [156/160]: loss 0.4482, auc 0.9761, ap 0.9714
EPNet pretrain, Epoch [157/160]: loss 0.4479, auc 0.9762, ap 0.9713
EPNet pretrain, Epoch [158/160]: loss 0.4476, auc 0.9756, ap 0.9708
EPNet pretrain, Epoch [159/160]: loss 0.4473, auc 0.9757, ap 0.9709
EPNet pretrain, Epoch [160/160]: loss 0.4469, auc 0.9764, ap 0.9714
NCNet pretrain, Epoch [ 1/30]: loss 1.9453, val acc 0.2500, test acc 0.2560
NCNet pretrain, Epoch [ 2/30]: loss 1.9299, val acc 0.2840, test acc 0.3000
NCNet pretrain, Epoch [ 3/30]: loss 1.9106, val acc 0.3940, test acc 0.4210
NCNet pretrain, Epoch [ 4/30]: loss 1.8864, val acc 0.6120, test acc 0.6260
NCNet pretrain, Epoch [ 5/30]: loss 1.8577, val acc 0.6780, test acc 0.6880
NCNet pretrain, Epoch [ 6/30]: loss 1.8288, val acc 0.6840, test acc 0.7020
NCNet pretrain, Epoch [ 7/30]: loss 1.7921, val acc 0.6760
NCNet pretrain, Epoch [ 8/30]: loss 1.7549, val acc 0.6620
NCNet pretrain, Epoch [ 9/30]: loss 1.7210, val acc 0.6700
NCNet pretrain, Epoch [10/30]: loss 1.6659, val acc 0.6780
NCNet pretrain, Epoch [11/30]: loss 1.6275, val acc 0.6920, test acc 0.6940
NCNet pretrain, Epoch [12/30]: loss 1.5744, val acc 0.7160, test acc 0.7220
NCNet pretrain, Epoch [13/30]: loss 1.5217, val acc 0.7360, test acc 0.7420
NCNet pretrain, Epoch [14/30]: loss 1.4746, val acc 0.7500, test acc 0.7550
NCNet pretrain, Epoch [15/30]: loss 1.4100, val acc 0.7640, test acc 0.7700
NCNet pretrain, Epoch [16/30]: loss 1.3583, val acc 0.7620
NCNet pretrain, Epoch [17/30]: loss 1.3050, val acc 0.7680, test acc 0.7860
NCNet pretrain, Epoch [18/30]: loss 1.2427, val acc 0.7720, test acc 0.7900
NCNet pretrain, Epoch [19/30]: loss 1.1824, val acc 0.7780, test acc 0.7890
NCNet pretrain, Epoch [20/30]: loss 1.1205, val acc 0.7800, test acc 0.7860
NCNet pretrain, Epoch [21/30]: loss 1.0667, val acc 0.7800
NCNet pretrain, Epoch [22/30]: loss 1.0211, val acc 0.7840, test acc 0.7910
NCNet pretrain, Epoch [23/30]: loss 0.9708, val acc 0.7840
NCNet pretrain, Epoch [24/30]: loss 0.9189, val acc 0.7920, test acc 0.7980
NCNet pretrain, Epoch [25/30]: loss 0.8605, val acc 0.7960, test acc 0.8090
NCNet pretrain, Epoch [26/30]: loss 0.7957, val acc 0.7960
NCNet pretrain, Epoch [27/30]: loss 0.7487, val acc 0.7980, test acc 0.8140
NCNet pretrain, Epoch [28/30]: loss 0.7301, val acc 0.7960
NCNet pretrain, Epoch [29/30]: loss 0.7110, val acc 0.7940
NCNet pretrain, Epoch [30/30]: loss 0.6824, val acc 0.7960
difference tensor(0.2735, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4466, nc loss 1.4518, ep auc: 0.9758, ep ap 0.9708, val acc 0.7360, test acc 0.7570
difference tensor(0.4526, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4571, nc loss 1.3495, ep auc: 0.9724, ep ap 0.9655, val acc 0.7400, test acc 0.7590
difference tensor(0.3855, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.4813, nc loss 1.2724, ep auc: 0.9624, ep ap 0.9543, val acc 0.7400, test acc 0.7710
difference tensor(0.6583, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5100, nc loss 1.1744, ep auc: 0.9484, ep ap 0.9388, val acc 0.7680, test acc 0.7960
difference tensor(0.6414, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5375, nc loss 1.1045, ep auc: 0.9262, ep ap 0.9155, val acc 0.8040, test acc 0.8230
difference tensor(1.3797, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.5623, nc loss 1.0537, ep auc: 0.8794, ep ap 0.8696, val acc 0.8080, test acc 0.8260
difference tensor(1.0145, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.5813, nc loss 0.9902, ep auc: 0.8366, ep ap 0.8277, val acc 0.8180, test acc 0.8270
difference tensor(1.0684, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.5947, nc loss 0.9312, ep auc: 0.8045, ep ap 0.7964, val acc 0.8180, test acc 0.8270
difference tensor(0.7638, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6061, nc loss 0.9474, ep auc: 0.7804, ep ap 0.7715, val acc 0.8180, test acc 0.8290
difference tensor(1.1814, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6137, nc loss 0.9409, ep auc: 0.7687, ep ap 0.7583, val acc 0.8160, test acc 0.8290
difference tensor(0.9189, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6191, nc loss 0.9150, ep auc: 0.7524, ep ap 0.7422, val acc 0.8080, test acc 0.8290
difference tensor(1.1339, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6222, nc loss 0.8736, ep auc: 0.7467, ep ap 0.7370, val acc 0.8060, test acc 0.8310
difference tensor(1.2298, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6247, nc loss 0.8599, ep auc: 0.7401, ep ap 0.7304, val acc 0.8060, test acc 0.8330
difference tensor(1.8241, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6268, nc loss 0.8046, ep auc: 0.7359, ep ap 0.7264, val acc 0.8020, test acc 0.8330
difference tensor(1.4275, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6286, nc loss 0.8315, ep auc: 0.7276, ep ap 0.7196, val acc 0.8000, test acc 0.8330
difference tensor(1.3170, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6299, nc loss 0.7941, ep auc: 0.7205, ep ap 0.7132, val acc 0.7940, test acc 0.8330
difference tensor(1.5472, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6315, nc loss 0.7468, ep auc: 0.7198, ep ap 0.7129, val acc 0.7980, test acc 0.8330
difference tensor(2.7913, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6327, nc loss 0.7597, ep auc: 0.7192, ep ap 0.7125, val acc 0.7980, test acc 0.8330
difference tensor(1.8709, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6349, nc loss 0.7456, ep auc: 0.7138, ep ap 0.7072, val acc 0.7980, test acc 0.8330
difference tensor(2.1717, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6374, nc loss 0.7313, ep auc: 0.7124, ep ap 0.7057, val acc 0.8020, test acc 0.8330
difference tensor(2.1256, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6387, nc loss 0.7133, ep auc: 0.7082, ep ap 0.7017, val acc 0.8000, test acc 0.8330
difference tensor(1.9094, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6402, nc loss 0.6963, ep auc: 0.7067, ep ap 0.7002, val acc 0.7980, test acc 0.8330
difference tensor(2.3821, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6425, nc loss 0.7310, ep auc: 0.7043, ep ap 0.6978, val acc 0.7940, test acc 0.8330
difference tensor(1.6652, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6440, nc loss 0.7157, ep auc: 0.7024, ep ap 0.6956, val acc 0.8020, test acc 0.8330
difference tensor(2.7905, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6454, nc loss 0.6976, ep auc: 0.7003, ep ap 0.6941, val acc 0.8020, test acc 0.8330
difference tensor(2.5132, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6464, nc loss 0.7043, ep auc: 0.6990, ep ap 0.6931, val acc 0.8020, test acc 0.8330
difference tensor(2.7528, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6464, nc loss 0.6959, ep auc: 0.6947, ep ap 0.6896, val acc 0.8040, test acc 0.8330
difference tensor(2.8796, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6467, nc loss 0.6692, ep auc: 0.6967, ep ap 0.6912, val acc 0.8000, test acc 0.8330
difference tensor(2.3162, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6469, nc loss 0.6645, ep auc: 0.6941, ep ap 0.6895, val acc 0.8020, test acc 0.8330
difference tensor(2.1329, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6476, nc loss 0.6775, ep auc: 0.6948, ep ap 0.6910, val acc 0.7980, test acc 0.8330
difference tensor(2.1654, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6475, nc loss 0.6734, ep auc: 0.6893, ep ap 0.6861, val acc 0.7900, test acc 0.8330
difference tensor(3.7557, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6473, nc loss 0.6702, ep auc: 0.6862, ep ap 0.6835, val acc 0.7840, test acc 0.8330
difference tensor(3.8562, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6476, nc loss 0.6591, ep auc: 0.6851, ep ap 0.6832, val acc 0.7860, test acc 0.8330
difference tensor(1.8942, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6484, nc loss 0.6782, ep auc: 0.6832, ep ap 0.6816, val acc 0.7860, test acc 0.8330
difference tensor(2.1172, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6492, nc loss 0.6606, ep auc: 0.6827, ep ap 0.6816, val acc 0.7960, test acc 0.8330
difference tensor(1.7675, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6496, nc loss 0.6646, ep auc: 0.6819, ep ap 0.6808, val acc 0.7960, test acc 0.8330
difference tensor(1.8520, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6507, nc loss 0.6633, ep auc: 0.6825, ep ap 0.6809, val acc 0.7860, test acc 0.8330
difference tensor(1.8903, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6515, nc loss 0.6723, ep auc: 0.6845, ep ap 0.6821, val acc 0.7820, test acc 0.8330
difference tensor(2.0452, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6521, nc loss 0.6697, ep auc: 0.6845, ep ap 0.6822, val acc 0.7900, test acc 0.8330
difference tensor(1.7720, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6522, nc loss 0.6743, ep auc: 0.6848, ep ap 0.6820, val acc 0.7880, test acc 0.8330
difference tensor(1.9643, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6515, nc loss 0.6638, ep auc: 0.6841, ep ap 0.6810, val acc 0.7860, test acc 0.8330
difference tensor(2.0860, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6515, nc loss 0.6693, ep auc: 0.6834, ep ap 0.6803, val acc 0.7940, test acc 0.8330
difference tensor(1.5027, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6513, nc loss 0.6667, ep auc: 0.6828, ep ap 0.6799, val acc 0.7940, test acc 0.8330
difference tensor(2.3949, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6501, nc loss 0.6803, ep auc: 0.6823, ep ap 0.6789, val acc 0.7980, test acc 0.8330
difference tensor(1.7853, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6485, nc loss 0.6644, ep auc: 0.6789, ep ap 0.6765, val acc 0.7960, test acc 0.8330
difference tensor(2.1638, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6471, nc loss 0.6718, ep auc: 0.6797, ep ap 0.6758, val acc 0.7940, test acc 0.8330
difference tensor(2.8401, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 47/200]: ep loss 0.6460, nc loss 0.6396, ep auc: 0.6793, ep ap 0.6749, val acc 0.7940, test acc 0.8330
difference tensor(1.4957, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 48/200]: ep loss 0.6449, nc loss 0.6535, ep auc: 0.6801, ep ap 0.6758, val acc 0.7940, test acc 0.8330
difference tensor(3.9727, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 49/200]: ep loss 0.6441, nc loss 0.6688, ep auc: 0.6806, ep ap 0.6758, val acc 0.7920, test acc 0.8330
difference tensor(1.5010, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 50/200]: ep loss 0.6433, nc loss 0.6358, ep auc: 0.6791, ep ap 0.6746, val acc 0.7860, test acc 0.8330
difference tensor(1.5428, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 51/200]: ep loss 0.6429, nc loss 0.6520, ep auc: 0.6774, ep ap 0.6728, val acc 0.7860, test acc 0.8330
difference tensor(1.2573, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 52/200]: ep loss 0.6434, nc loss 0.6347, ep auc: 0.6765, ep ap 0.6718, val acc 0.7840, test acc 0.8330
difference tensor(1.2415, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 53/200]: ep loss 0.6433, nc loss 0.6412, ep auc: 0.6736, ep ap 0.6691, val acc 0.7880, test acc 0.8330
difference tensor(2.2940, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 54/200]: ep loss 0.6430, nc loss 0.6382, ep auc: 0.6735, ep ap 0.6688, val acc 0.7880, test acc 0.8330
difference tensor(1.6672, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 55/200]: ep loss 0.6428, nc loss 0.6356, ep auc: 0.6685, ep ap 0.6647, val acc 0.7860, test acc 0.8330
difference tensor(3.8963, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 56/200]: ep loss 0.6421, nc loss 0.6414, ep auc: 0.6678, ep ap 0.6640, val acc 0.7840, test acc 0.8330
difference tensor(1.2929, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 57/200]: ep loss 0.6411, nc loss 0.6294, ep auc: 0.6705, ep ap 0.6661, val acc 0.7860, test acc 0.8330
difference tensor(1.0326, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 58/200]: ep loss 0.6393, nc loss 0.6393, ep auc: 0.6675, ep ap 0.6637, val acc 0.7900, test acc 0.8330
difference tensor(1.4673, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 59/200]: ep loss 0.6382, nc loss 0.6400, ep auc: 0.6655, ep ap 0.6620, val acc 0.7900, test acc 0.8330
difference tensor(1.6661, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 60/200]: ep loss 0.6374, nc loss 0.6326, ep auc: 0.6630, ep ap 0.6594, val acc 0.7880, test acc 0.8330
difference tensor(2.0539, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 61/200]: ep loss 0.6366, nc loss 0.6229, ep auc: 0.6633, ep ap 0.6591, val acc 0.7900, test acc 0.8330
difference tensor(1.2068, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 62/200]: ep loss 0.6357, nc loss 0.6248, ep auc: 0.6634, ep ap 0.6593, val acc 0.7860, test acc 0.8330
difference tensor(1.2138, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 63/200]: ep loss 0.6351, nc loss 0.6436, ep auc: 0.6634, ep ap 0.6593, val acc 0.7860, test acc 0.8330
difference tensor(1.3568, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 64/200]: ep loss 0.6347, nc loss 0.6203, ep auc: 0.6640, ep ap 0.6594, val acc 0.7880, test acc 0.8330
difference tensor(1.4728, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 65/200]: ep loss 0.6344, nc loss 0.6165, ep auc: 0.6661, ep ap 0.6612, val acc 0.7900, test acc 0.8330
difference tensor(1.0547, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 66/200]: ep loss 0.6342, nc loss 0.6216, ep auc: 0.6683, ep ap 0.6629, val acc 0.7920, test acc 0.8330
difference tensor(2.4059, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 67/200]: ep loss 0.6341, nc loss 0.6359, ep auc: 0.6690, ep ap 0.6635, val acc 0.7960, test acc 0.8330
difference tensor(1.1044, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 68/200]: ep loss 0.6348, nc loss 0.6160, ep auc: 0.6681, ep ap 0.6624, val acc 0.7960, test acc 0.8330
difference tensor(1.2422, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 69/200]: ep loss 0.6358, nc loss 0.6058, ep auc: 0.6657, ep ap 0.6611, val acc 0.7940, test acc 0.8330
difference tensor(1.1935, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 70/200]: ep loss 0.6369, nc loss 0.6100, ep auc: 0.6662, ep ap 0.6613, val acc 0.7980, test acc 0.8330
difference tensor(1.1997, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 71/200]: ep loss 0.6384, nc loss 0.6299, ep auc: 0.6661, ep ap 0.6610, val acc 0.8000, test acc 0.8330
difference tensor(1.4035, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 72/200]: ep loss 0.6400, nc loss 0.6177, ep auc: 0.6673, ep ap 0.6617, val acc 0.7920, test acc 0.8330
difference tensor(1.3158, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 73/200]: ep loss 0.6417, nc loss 0.6144, ep auc: 0.6670, ep ap 0.6620, val acc 0.7780, test acc 0.8330
difference tensor(1.1626, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 74/200]: ep loss 0.6427, nc loss 0.6247, ep auc: 0.6661, ep ap 0.6613, val acc 0.7840, test acc 0.8330
difference tensor(1.5260, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 75/200]: ep loss 0.6414, nc loss 0.6317, ep auc: 0.6638, ep ap 0.6591, val acc 0.7860, test acc 0.8330
difference tensor(1.7511, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 76/200]: ep loss 0.6397, nc loss 0.6068, ep auc: 0.6640, ep ap 0.6595, val acc 0.7860, test acc 0.8330
difference tensor(1.4823, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 77/200]: ep loss 0.6385, nc loss 0.6165, ep auc: 0.6665, ep ap 0.6611, val acc 0.7900, test acc 0.8330
difference tensor(1.5347, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 78/200]: ep loss 0.6378, nc loss 0.6169, ep auc: 0.6635, ep ap 0.6583, val acc 0.7880, test acc 0.8330
difference tensor(1.3293, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 79/200]: ep loss 0.6374, nc loss 0.6101, ep auc: 0.6621, ep ap 0.6572, val acc 0.7860, test acc 0.8330
difference tensor(2.2312, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 80/200]: ep loss 0.6368, nc loss 0.6088, ep auc: 0.6624, ep ap 0.6566, val acc 0.7980, test acc 0.8330
difference tensor(1.6913, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 81/200]: ep loss 0.6362, nc loss 0.6195, ep auc: 0.6626, ep ap 0.6561, val acc 0.7980, test acc 0.8330
difference tensor(1.2499, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 82/200]: ep loss 0.6358, nc loss 0.6019, ep auc: 0.6626, ep ap 0.6561, val acc 0.7960, test acc 0.8330
difference tensor(1.4679, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 83/200]: ep loss 0.6356, nc loss 0.6314, ep auc: 0.6631, ep ap 0.6561, val acc 0.7920, test acc 0.8330
difference tensor(1.2366, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 84/200]: ep loss 0.6351, nc loss 0.6190, ep auc: 0.6653, ep ap 0.6578, val acc 0.7940, test acc 0.8330
difference tensor(2.5883, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 85/200]: ep loss 0.6349, nc loss 0.6058, ep auc: 0.6675, ep ap 0.6596, val acc 0.7920, test acc 0.8330
difference tensor(1.0585, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 86/200]: ep loss 0.6347, nc loss 0.5980, ep auc: 0.6685, ep ap 0.6608, val acc 0.7900, test acc 0.8330
difference tensor(1.3916, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 87/200]: ep loss 0.6346, nc loss 0.5965, ep auc: 0.6681, ep ap 0.6608, val acc 0.7860, test acc 0.8330
difference tensor(2.5393, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 88/200]: ep loss 0.6346, nc loss 0.6038, ep auc: 0.6681, ep ap 0.6609, val acc 0.7840, test acc 0.8330
difference tensor(2.8546, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 89/200]: ep loss 0.6345, nc loss 0.6081, ep auc: 0.6702, ep ap 0.6627, val acc 0.7880, test acc 0.8330
difference tensor(1.4389, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 90/200]: ep loss 0.6347, nc loss 0.5940, ep auc: 0.6710, ep ap 0.6633, val acc 0.7920, test acc 0.8330
difference tensor(0.9329, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 91/200]: ep loss 0.6349, nc loss 0.6141, ep auc: 0.6714, ep ap 0.6635, val acc 0.7960, test acc 0.8330
difference tensor(1.1745, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 92/200]: ep loss 0.6352, nc loss 0.6047, ep auc: 0.6700, ep ap 0.6635, val acc 0.8020, test acc 0.8330
difference tensor(1.0792, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 93/200]: ep loss 0.6353, nc loss 0.6081, ep auc: 0.6693, ep ap 0.6629, val acc 0.7960, test acc 0.8330
difference tensor(1.6933, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 94/200]: ep loss 0.6348, nc loss 0.6156, ep auc: 0.6698, ep ap 0.6631, val acc 0.7940, test acc 0.8330
difference tensor(1.6100, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 95/200]: ep loss 0.6341, nc loss 0.5940, ep auc: 0.6706, ep ap 0.6639, val acc 0.7900, test acc 0.8330
difference tensor(1.2147, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 96/200]: ep loss 0.6336, nc loss 0.5945, ep auc: 0.6723, ep ap 0.6654, val acc 0.7840, test acc 0.8330
difference tensor(1.3659, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 97/200]: ep loss 0.6331, nc loss 0.5969, ep auc: 0.6749, ep ap 0.6673, val acc 0.7820, test acc 0.8330
difference tensor(1.1733, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 98/200]: ep loss 0.6319, nc loss 0.6041, ep auc: 0.6755, ep ap 0.6675, val acc 0.7780, test acc 0.8330
difference tensor(1.3429, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 99/200]: ep loss 0.6311, nc loss 0.6074, ep auc: 0.6761, ep ap 0.6679, val acc 0.7780, test acc 0.8330
difference tensor(1.4272, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [100/200]: ep loss 0.6305, nc loss 0.6051, ep auc: 0.6790, ep ap 0.6713, val acc 0.7920, test acc 0.8330
difference tensor(1.6134, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [101/200]: ep loss 0.6300, nc loss 0.5940, ep auc: 0.6782, ep ap 0.6693, val acc 0.7860, test acc 0.8330
difference tensor(2.6315, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [102/200]: ep loss 0.6298, nc loss 0.5998, ep auc: 0.6775, ep ap 0.6700, val acc 0.7920, test acc 0.8330
difference tensor(1.1984, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [103/200]: ep loss 0.6295, nc loss 0.6048, ep auc: 0.6780, ep ap 0.6704, val acc 0.7980, test acc 0.8330
difference tensor(1.3544, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [104/200]: ep loss 0.6294, nc loss 0.5924, ep auc: 0.6787, ep ap 0.6714, val acc 0.7920, test acc 0.8330
difference tensor(1.1704, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [105/200]: ep loss 0.6296, nc loss 0.6089, ep auc: 0.6802, ep ap 0.6727, val acc 0.7900, test acc 0.8330
difference tensor(1.5629, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [106/200]: ep loss 0.6296, nc loss 0.5919, ep auc: 0.6802, ep ap 0.6729, val acc 0.7880, test acc 0.8330
difference tensor(0.9726, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [107/200]: ep loss 0.6298, nc loss 0.5896, ep auc: 0.6788, ep ap 0.6720, val acc 0.7880, test acc 0.8330
difference tensor(1.1376, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [108/200]: ep loss 0.6301, nc loss 0.6008, ep auc: 0.6788, ep ap 0.6719, val acc 0.7740, test acc 0.8330
difference tensor(1.2081, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [109/200]: ep loss 0.6304, nc loss 0.6016, ep auc: 0.6781, ep ap 0.6713, val acc 0.7760, test acc 0.8330
difference tensor(1.1259, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [110/200]: ep loss 0.6308, nc loss 0.5917, ep auc: 0.6773, ep ap 0.6706, val acc 0.7720, test acc 0.8330
difference tensor(1.3366, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [111/200]: ep loss 0.6311, nc loss 0.5905, ep auc: 0.6768, ep ap 0.6693, val acc 0.7780, test acc 0.8330
difference tensor(1.1220, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [112/200]: ep loss 0.6313, nc loss 0.6038, ep auc: 0.6776, ep ap 0.6698, val acc 0.7820, test acc 0.8330
difference tensor(1.7320, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [113/200]: ep loss 0.6317, nc loss 0.5883, ep auc: 0.6804, ep ap 0.6720, val acc 0.7940, test acc 0.8330
Early stop!
Final test acc with early stop: 0.8330, without early stop: 0.7960
Micro F1: 0.836286, std: 0.005391, Max is 0.846000, min is 0.829000
Big Epoch 6/30 dataset is cora fid_frac is 0.1
Big Epoch 7/30
EPNet pretrain, Epoch [  1/160]: loss 0.6931, auc 0.8180, ap 0.8074
EPNet pretrain, Epoch [  2/160]: loss 0.6910, auc 0.7966, ap 0.7969
EPNet pretrain, Epoch [  3/160]: loss 0.6847, auc 0.7813, ap 0.7813
EPNet pretrain, Epoch [  4/160]: loss 0.6791, auc 0.7731, ap 0.7754
EPNet pretrain, Epoch [  5/160]: loss 0.6807, auc 0.7731, ap 0.7800
EPNet pretrain, Epoch [  6/160]: loss 0.6741, auc 0.7738, ap 0.7865
EPNet pretrain, Epoch [  7/160]: loss 0.6727, auc 0.7726, ap 0.7930
EPNet pretrain, Epoch [  8/160]: loss 0.6703, auc 0.7702, ap 0.7949
EPNet pretrain, Epoch [  9/160]: loss 0.6655, auc 0.7680, ap 0.7933
EPNet pretrain, Epoch [ 10/160]: loss 0.6591, auc 0.7665, ap 0.7909
EPNet pretrain, Epoch [ 11/160]: loss 0.6530, auc 0.7686, ap 0.7916
EPNet pretrain, Epoch [ 12/160]: loss 0.6475, auc 0.7780, ap 0.7990
EPNet pretrain, Epoch [ 13/160]: loss 0.6398, auc 0.7941, ap 0.8133
EPNet pretrain, Epoch [ 14/160]: loss 0.6318, auc 0.8078, ap 0.8250
EPNet pretrain, Epoch [ 15/160]: loss 0.6258, auc 0.8132, ap 0.8244
EPNet pretrain, Epoch [ 16/160]: loss 0.6213, auc 0.8167, ap 0.8210
EPNet pretrain, Epoch [ 17/160]: loss 0.6166, auc 0.8232, ap 0.8227
EPNet pretrain, Epoch [ 18/160]: loss 0.6122, auc 0.8310, ap 0.8283
EPNet pretrain, Epoch [ 19/160]: loss 0.6089, auc 0.8379, ap 0.8341
EPNet pretrain, Epoch [ 20/160]: loss 0.6052, auc 0.8451, ap 0.8413
EPNet pretrain, Epoch [ 21/160]: loss 0.5998, auc 0.8534, ap 0.8508
EPNet pretrain, Epoch [ 22/160]: loss 0.5940, auc 0.8624, ap 0.8611
EPNet pretrain, Epoch [ 23/160]: loss 0.5886, auc 0.8707, ap 0.8708
EPNet pretrain, Epoch [ 24/160]: loss 0.5834, auc 0.8784, ap 0.8801
EPNet pretrain, Epoch [ 25/160]: loss 0.5783, auc 0.8854, ap 0.8879
EPNet pretrain, Epoch [ 26/160]: loss 0.5734, auc 0.8923, ap 0.8954
EPNet pretrain, Epoch [ 27/160]: loss 0.5691, auc 0.8985, ap 0.9015
EPNet pretrain, Epoch [ 28/160]: loss 0.5651, auc 0.9044, ap 0.9063
EPNet pretrain, Epoch [ 29/160]: loss 0.5612, auc 0.9100, ap 0.9105
EPNet pretrain, Epoch [ 30/160]: loss 0.5574, auc 0.9147, ap 0.9143
EPNet pretrain, Epoch [ 31/160]: loss 0.5540, auc 0.9177, ap 0.9165
EPNet pretrain, Epoch [ 32/160]: loss 0.5511, auc 0.9193, ap 0.9177
EPNet pretrain, Epoch [ 33/160]: loss 0.5483, auc 0.9221, ap 0.9195
EPNet pretrain, Epoch [ 34/160]: loss 0.5453, auc 0.9253, ap 0.9220
EPNet pretrain, Epoch [ 35/160]: loss 0.5423, auc 0.9291, ap 0.9253
EPNet pretrain, Epoch [ 36/160]: loss 0.5396, auc 0.9322, ap 0.9281
EPNet pretrain, Epoch [ 37/160]: loss 0.5370, auc 0.9349, ap 0.9304
EPNet pretrain, Epoch [ 38/160]: loss 0.5345, auc 0.9376, ap 0.9330
EPNet pretrain, Epoch [ 39/160]: loss 0.5320, auc 0.9383, ap 0.9340
EPNet pretrain, Epoch [ 40/160]: loss 0.5295, auc 0.9392, ap 0.9350
EPNet pretrain, Epoch [ 41/160]: loss 0.5274, auc 0.9411, ap 0.9366
EPNet pretrain, Epoch [ 42/160]: loss 0.5254, auc 0.9428, ap 0.9384
EPNet pretrain, Epoch [ 43/160]: loss 0.5235, auc 0.9446, ap 0.9403
EPNet pretrain, Epoch [ 44/160]: loss 0.5216, auc 0.9461, ap 0.9422
EPNet pretrain, Epoch [ 45/160]: loss 0.5199, auc 0.9472, ap 0.9435
EPNet pretrain, Epoch [ 46/160]: loss 0.5184, auc 0.9487, ap 0.9449
EPNet pretrain, Epoch [ 47/160]: loss 0.5170, auc 0.9510, ap 0.9467
EPNet pretrain, Epoch [ 48/160]: loss 0.5155, auc 0.9523, ap 0.9480
EPNet pretrain, Epoch [ 49/160]: loss 0.5141, auc 0.9527, ap 0.9488
EPNet pretrain, Epoch [ 50/160]: loss 0.5130, auc 0.9537, ap 0.9498
EPNet pretrain, Epoch [ 51/160]: loss 0.5119, auc 0.9538, ap 0.9502
EPNet pretrain, Epoch [ 52/160]: loss 0.5107, auc 0.9546, ap 0.9512
EPNet pretrain, Epoch [ 53/160]: loss 0.5096, auc 0.9551, ap 0.9518
EPNet pretrain, Epoch [ 54/160]: loss 0.5085, auc 0.9566, ap 0.9530
EPNet pretrain, Epoch [ 55/160]: loss 0.5074, auc 0.9575, ap 0.9538
EPNet pretrain, Epoch [ 56/160]: loss 0.5063, auc 0.9582, ap 0.9544
EPNet pretrain, Epoch [ 57/160]: loss 0.5053, auc 0.9580, ap 0.9542
EPNet pretrain, Epoch [ 58/160]: loss 0.5044, auc 0.9584, ap 0.9545
EPNet pretrain, Epoch [ 59/160]: loss 0.5035, auc 0.9587, ap 0.9548
EPNet pretrain, Epoch [ 60/160]: loss 0.5027, auc 0.9579, ap 0.9543
EPNet pretrain, Epoch [ 61/160]: loss 0.5019, auc 0.9583, ap 0.9548
EPNet pretrain, Epoch [ 62/160]: loss 0.5011, auc 0.9587, ap 0.9551
EPNet pretrain, Epoch [ 63/160]: loss 0.5003, auc 0.9585, ap 0.9548
EPNet pretrain, Epoch [ 64/160]: loss 0.4996, auc 0.9599, ap 0.9557
EPNet pretrain, Epoch [ 65/160]: loss 0.4989, auc 0.9603, ap 0.9558
EPNet pretrain, Epoch [ 66/160]: loss 0.4981, auc 0.9606, ap 0.9562
EPNet pretrain, Epoch [ 67/160]: loss 0.4974, auc 0.9610, ap 0.9564
EPNet pretrain, Epoch [ 68/160]: loss 0.4967, auc 0.9607, ap 0.9563
EPNet pretrain, Epoch [ 69/160]: loss 0.4960, auc 0.9605, ap 0.9562
EPNet pretrain, Epoch [ 70/160]: loss 0.4953, auc 0.9607, ap 0.9563
EPNet pretrain, Epoch [ 71/160]: loss 0.4947, auc 0.9611, ap 0.9565
EPNet pretrain, Epoch [ 72/160]: loss 0.4940, auc 0.9613, ap 0.9565
EPNet pretrain, Epoch [ 73/160]: loss 0.4934, auc 0.9622, ap 0.9571
EPNet pretrain, Epoch [ 74/160]: loss 0.4928, auc 0.9623, ap 0.9571
EPNet pretrain, Epoch [ 75/160]: loss 0.4922, auc 0.9632, ap 0.9578
EPNet pretrain, Epoch [ 76/160]: loss 0.4916, auc 0.9635, ap 0.9584
EPNet pretrain, Epoch [ 77/160]: loss 0.4910, auc 0.9638, ap 0.9587
EPNet pretrain, Epoch [ 78/160]: loss 0.4903, auc 0.9646, ap 0.9593
EPNet pretrain, Epoch [ 79/160]: loss 0.4897, auc 0.9649, ap 0.9595
EPNet pretrain, Epoch [ 80/160]: loss 0.4890, auc 0.9647, ap 0.9593
EPNet pretrain, Epoch [ 81/160]: loss 0.4884, auc 0.9654, ap 0.9600
EPNet pretrain, Epoch [ 82/160]: loss 0.4877, auc 0.9657, ap 0.9603
EPNet pretrain, Epoch [ 83/160]: loss 0.4871, auc 0.9658, ap 0.9604
EPNet pretrain, Epoch [ 84/160]: loss 0.4865, auc 0.9659, ap 0.9603
EPNet pretrain, Epoch [ 85/160]: loss 0.4858, auc 0.9661, ap 0.9603
EPNet pretrain, Epoch [ 86/160]: loss 0.4852, auc 0.9657, ap 0.9599
EPNet pretrain, Epoch [ 87/160]: loss 0.4846, auc 0.9664, ap 0.9604
EPNet pretrain, Epoch [ 88/160]: loss 0.4840, auc 0.9667, ap 0.9607
EPNet pretrain, Epoch [ 89/160]: loss 0.4835, auc 0.9670, ap 0.9609
EPNet pretrain, Epoch [ 90/160]: loss 0.4829, auc 0.9673, ap 0.9611
EPNet pretrain, Epoch [ 91/160]: loss 0.4823, auc 0.9675, ap 0.9613
EPNet pretrain, Epoch [ 92/160]: loss 0.4818, auc 0.9677, ap 0.9613
EPNet pretrain, Epoch [ 93/160]: loss 0.4812, auc 0.9685, ap 0.9619
EPNet pretrain, Epoch [ 94/160]: loss 0.4807, auc 0.9687, ap 0.9622
EPNet pretrain, Epoch [ 95/160]: loss 0.4802, auc 0.9684, ap 0.9621
EPNet pretrain, Epoch [ 96/160]: loss 0.4797, auc 0.9682, ap 0.9621
EPNet pretrain, Epoch [ 97/160]: loss 0.4792, auc 0.9685, ap 0.9625
EPNet pretrain, Epoch [ 98/160]: loss 0.4787, auc 0.9687, ap 0.9629
EPNet pretrain, Epoch [ 99/160]: loss 0.4782, auc 0.9695, ap 0.9635
EPNet pretrain, Epoch [100/160]: loss 0.4777, auc 0.9698, ap 0.9639
EPNet pretrain, Epoch [101/160]: loss 0.4772, auc 0.9700, ap 0.9642
EPNet pretrain, Epoch [102/160]: loss 0.4767, auc 0.9702, ap 0.9645
EPNet pretrain, Epoch [103/160]: loss 0.4762, auc 0.9704, ap 0.9649
EPNet pretrain, Epoch [104/160]: loss 0.4757, auc 0.9706, ap 0.9651
EPNet pretrain, Epoch [105/160]: loss 0.4752, auc 0.9702, ap 0.9648
EPNet pretrain, Epoch [106/160]: loss 0.4747, auc 0.9697, ap 0.9645
EPNet pretrain, Epoch [107/160]: loss 0.4742, auc 0.9699, ap 0.9647
EPNet pretrain, Epoch [108/160]: loss 0.4736, auc 0.9699, ap 0.9649
EPNet pretrain, Epoch [109/160]: loss 0.4731, auc 0.9707, ap 0.9654
EPNet pretrain, Epoch [110/160]: loss 0.4726, auc 0.9708, ap 0.9655
EPNet pretrain, Epoch [111/160]: loss 0.4721, auc 0.9709, ap 0.9656
EPNet pretrain, Epoch [112/160]: loss 0.4716, auc 0.9711, ap 0.9659
EPNet pretrain, Epoch [113/160]: loss 0.4710, auc 0.9712, ap 0.9661
EPNet pretrain, Epoch [114/160]: loss 0.4705, auc 0.9707, ap 0.9657
EPNet pretrain, Epoch [115/160]: loss 0.4700, auc 0.9715, ap 0.9665
EPNet pretrain, Epoch [116/160]: loss 0.4695, auc 0.9716, ap 0.9667
EPNet pretrain, Epoch [117/160]: loss 0.4690, auc 0.9718, ap 0.9669
EPNet pretrain, Epoch [118/160]: loss 0.4685, auc 0.9718, ap 0.9670
EPNet pretrain, Epoch [119/160]: loss 0.4681, auc 0.9719, ap 0.9671
EPNet pretrain, Epoch [120/160]: loss 0.4677, auc 0.9721, ap 0.9673
EPNet pretrain, Epoch [121/160]: loss 0.4673, auc 0.9728, ap 0.9680
EPNet pretrain, Epoch [122/160]: loss 0.4669, auc 0.9730, ap 0.9683
EPNet pretrain, Epoch [123/160]: loss 0.4665, auc 0.9726, ap 0.9680
EPNet pretrain, Epoch [124/160]: loss 0.4662, auc 0.9727, ap 0.9681
EPNet pretrain, Epoch [125/160]: loss 0.4658, auc 0.9728, ap 0.9682
EPNet pretrain, Epoch [126/160]: loss 0.4655, auc 0.9729, ap 0.9683
EPNet pretrain, Epoch [127/160]: loss 0.4651, auc 0.9730, ap 0.9684
EPNet pretrain, Epoch [128/160]: loss 0.4647, auc 0.9731, ap 0.9685
EPNet pretrain, Epoch [129/160]: loss 0.4643, auc 0.9732, ap 0.9686
EPNet pretrain, Epoch [130/160]: loss 0.4640, auc 0.9733, ap 0.9685
EPNet pretrain, Epoch [131/160]: loss 0.4636, auc 0.9734, ap 0.9686
EPNet pretrain, Epoch [132/160]: loss 0.4633, auc 0.9733, ap 0.9686
EPNet pretrain, Epoch [133/160]: loss 0.4629, auc 0.9729, ap 0.9683
EPNet pretrain, Epoch [134/160]: loss 0.4625, auc 0.9735, ap 0.9689
EPNet pretrain, Epoch [135/160]: loss 0.4622, auc 0.9736, ap 0.9689
EPNet pretrain, Epoch [136/160]: loss 0.4618, auc 0.9730, ap 0.9684
EPNet pretrain, Epoch [137/160]: loss 0.4615, auc 0.9730, ap 0.9684
EPNet pretrain, Epoch [138/160]: loss 0.4611, auc 0.9732, ap 0.9685
EPNet pretrain, Epoch [139/160]: loss 0.4607, auc 0.9733, ap 0.9687
EPNet pretrain, Epoch [140/160]: loss 0.4603, auc 0.9734, ap 0.9689
EPNet pretrain, Epoch [141/160]: loss 0.4600, auc 0.9741, ap 0.9695
EPNet pretrain, Epoch [142/160]: loss 0.4596, auc 0.9747, ap 0.9701
EPNet pretrain, Epoch [143/160]: loss 0.4592, auc 0.9748, ap 0.9704
EPNet pretrain, Epoch [144/160]: loss 0.4588, auc 0.9743, ap 0.9700
EPNet pretrain, Epoch [145/160]: loss 0.4584, auc 0.9744, ap 0.9703
EPNet pretrain, Epoch [146/160]: loss 0.4580, auc 0.9751, ap 0.9711
EPNet pretrain, Epoch [147/160]: loss 0.4576, auc 0.9747, ap 0.9709
EPNet pretrain, Epoch [148/160]: loss 0.4571, auc 0.9747, ap 0.9712
EPNet pretrain, Epoch [149/160]: loss 0.4567, auc 0.9749, ap 0.9715
EPNet pretrain, Epoch [150/160]: loss 0.4563, auc 0.9751, ap 0.9718
EPNet pretrain, Epoch [151/160]: loss 0.4558, auc 0.9758, ap 0.9726
EPNet pretrain, Epoch [152/160]: loss 0.4554, auc 0.9754, ap 0.9723
EPNet pretrain, Epoch [153/160]: loss 0.4550, auc 0.9756, ap 0.9726
EPNet pretrain, Epoch [154/160]: loss 0.4546, auc 0.9758, ap 0.9729
EPNet pretrain, Epoch [155/160]: loss 0.4541, auc 0.9759, ap 0.9732
EPNet pretrain, Epoch [156/160]: loss 0.4537, auc 0.9761, ap 0.9734
EPNet pretrain, Epoch [157/160]: loss 0.4533, auc 0.9762, ap 0.9735
EPNet pretrain, Epoch [158/160]: loss 0.4530, auc 0.9762, ap 0.9735
EPNet pretrain, Epoch [159/160]: loss 0.4526, auc 0.9769, ap 0.9740
EPNet pretrain, Epoch [160/160]: loss 0.4523, auc 0.9769, ap 0.9740
NCNet pretrain, Epoch [ 1/30]: loss 1.9461, val acc 0.2500, test acc 0.2400
NCNet pretrain, Epoch [ 2/30]: loss 1.9292, val acc 0.2780, test acc 0.2910
NCNet pretrain, Epoch [ 3/30]: loss 1.9086, val acc 0.4380, test acc 0.4640
NCNet pretrain, Epoch [ 4/30]: loss 1.8812, val acc 0.5920, test acc 0.6110
NCNet pretrain, Epoch [ 5/30]: loss 1.8548, val acc 0.6680, test acc 0.6850
NCNet pretrain, Epoch [ 6/30]: loss 1.8254, val acc 0.7180, test acc 0.7330
NCNet pretrain, Epoch [ 7/30]: loss 1.7865, val acc 0.7300, test acc 0.7520
NCNet pretrain, Epoch [ 8/30]: loss 1.7472, val acc 0.7380, test acc 0.7660
NCNet pretrain, Epoch [ 9/30]: loss 1.7059, val acc 0.7320
NCNet pretrain, Epoch [10/30]: loss 1.6571, val acc 0.7340
NCNet pretrain, Epoch [11/30]: loss 1.6143, val acc 0.7340
NCNet pretrain, Epoch [12/30]: loss 1.5680, val acc 0.7360
NCNet pretrain, Epoch [13/30]: loss 1.5088, val acc 0.7440, test acc 0.7680
NCNet pretrain, Epoch [14/30]: loss 1.4477, val acc 0.7500, test acc 0.7750
NCNet pretrain, Epoch [15/30]: loss 1.4003, val acc 0.7580, test acc 0.7840
NCNet pretrain, Epoch [16/30]: loss 1.3442, val acc 0.7640, test acc 0.7900
NCNet pretrain, Epoch [17/30]: loss 1.2832, val acc 0.7720, test acc 0.7940
NCNet pretrain, Epoch [18/30]: loss 1.2280, val acc 0.7800, test acc 0.7950
NCNet pretrain, Epoch [19/30]: loss 1.1675, val acc 0.7820, test acc 0.7960
NCNet pretrain, Epoch [20/30]: loss 1.1124, val acc 0.7860, test acc 0.7950
NCNet pretrain, Epoch [21/30]: loss 1.0441, val acc 0.7840
NCNet pretrain, Epoch [22/30]: loss 1.0067, val acc 0.7880, test acc 0.7960
NCNet pretrain, Epoch [23/30]: loss 0.9399, val acc 0.7920, test acc 0.8060
NCNet pretrain, Epoch [24/30]: loss 0.8916, val acc 0.7920
NCNet pretrain, Epoch [25/30]: loss 0.8325, val acc 0.7960, test acc 0.8140
NCNet pretrain, Epoch [26/30]: loss 0.7795, val acc 0.8000, test acc 0.8140
NCNet pretrain, Epoch [27/30]: loss 0.7485, val acc 0.8000
NCNet pretrain, Epoch [28/30]: loss 0.7097, val acc 0.8000
NCNet pretrain, Epoch [29/30]: loss 0.6583, val acc 0.7980
NCNet pretrain, Epoch [30/30]: loss 0.6066, val acc 0.7980
difference tensor(0.3040, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  1/200]: ep loss 0.4519, nc loss 1.3734, ep auc: 0.9770, ep ap 0.9740, val acc 0.7620, test acc 0.7990
difference tensor(0.5919, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  2/200]: ep loss 0.4651, nc loss 1.2802, ep auc: 0.9687, ep ap 0.9611, val acc 0.7880, test acc 0.8050
difference tensor(0.4354, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  3/200]: ep loss 0.4959, nc loss 1.1660, ep auc: 0.9584, ep ap 0.9445, val acc 0.8020, test acc 0.8190
difference tensor(0.6172, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  4/200]: ep loss 0.5337, nc loss 1.1061, ep auc: 0.9405, ep ap 0.9204, val acc 0.8060, test acc 0.8190
difference tensor(0.8565, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  5/200]: ep loss 0.5720, nc loss 1.0654, ep auc: 0.9052, ep ap 0.8813, val acc 0.8060, test acc 0.8190
difference tensor(1.0381, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  6/200]: ep loss 0.6015, nc loss 1.0584, ep auc: 0.8651, ep ap 0.8406, val acc 0.8060, test acc 0.8220
difference tensor(1.1535, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  7/200]: ep loss 0.6184, nc loss 1.0060, ep auc: 0.8338, ep ap 0.8089, val acc 0.8040, test acc 0.8270
difference tensor(1.9524, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  8/200]: ep loss 0.6253, nc loss 0.9627, ep auc: 0.7948, ep ap 0.7734, val acc 0.7900, test acc 0.8270
difference tensor(0.9595, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [  9/200]: ep loss 0.6266, nc loss 0.9393, ep auc: 0.7659, ep ap 0.7471, val acc 0.7840, test acc 0.8270
difference tensor(1.0995, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 10/200]: ep loss 0.6238, nc loss 0.8825, ep auc: 0.7459, ep ap 0.7301, val acc 0.7880, test acc 0.8270
difference tensor(1.1075, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 11/200]: ep loss 0.6199, nc loss 0.8633, ep auc: 0.7366, ep ap 0.7218, val acc 0.7880, test acc 0.8270
difference tensor(1.1944, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 12/200]: ep loss 0.6158, nc loss 0.8120, ep auc: 0.7280, ep ap 0.7150, val acc 0.7840, test acc 0.8270
difference tensor(1.2484, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 13/200]: ep loss 0.6130, nc loss 0.7913, ep auc: 0.7271, ep ap 0.7157, val acc 0.7880, test acc 0.8270
difference tensor(0.8579, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 14/200]: ep loss 0.6117, nc loss 0.7869, ep auc: 0.7195, ep ap 0.7096, val acc 0.7900, test acc 0.8270
difference tensor(0.9796, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 15/200]: ep loss 0.6113, nc loss 0.7559, ep auc: 0.7163, ep ap 0.7069, val acc 0.7940, test acc 0.8270
difference tensor(1.1688, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 16/200]: ep loss 0.6113, nc loss 0.7428, ep auc: 0.7167, ep ap 0.7073, val acc 0.8040, test acc 0.8270
difference tensor(2.1871, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 17/200]: ep loss 0.6131, nc loss 0.7297, ep auc: 0.7141, ep ap 0.7046, val acc 0.8020, test acc 0.8270
difference tensor(0.9402, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 18/200]: ep loss 0.6159, nc loss 0.7384, ep auc: 0.7105, ep ap 0.7013, val acc 0.7980, test acc 0.8270
difference tensor(1.2177, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 19/200]: ep loss 0.6190, nc loss 0.7181, ep auc: 0.7083, ep ap 0.6991, val acc 0.7900, test acc 0.8270
difference tensor(2.6684, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 20/200]: ep loss 0.6227, nc loss 0.6796, ep auc: 0.7023, ep ap 0.6934, val acc 0.7940, test acc 0.8270
difference tensor(1.7840, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 21/200]: ep loss 0.6263, nc loss 0.6935, ep auc: 0.7000, ep ap 0.6903, val acc 0.7940, test acc 0.8270
difference tensor(1.3781, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 22/200]: ep loss 0.6291, nc loss 0.6813, ep auc: 0.6969, ep ap 0.6871, val acc 0.7960, test acc 0.8270
difference tensor(1.5766, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 23/200]: ep loss 0.6324, nc loss 0.6868, ep auc: 0.6978, ep ap 0.6869, val acc 0.7880, test acc 0.8270
difference tensor(2.0105, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 24/200]: ep loss 0.6363, nc loss 0.6694, ep auc: 0.6954, ep ap 0.6843, val acc 0.7800, test acc 0.8270
difference tensor(4.9055, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 25/200]: ep loss 0.6402, nc loss 0.6817, ep auc: 0.6934, ep ap 0.6825, val acc 0.7720, test acc 0.8270
difference tensor(1.4257, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 26/200]: ep loss 0.6439, nc loss 0.6614, ep auc: 0.6913, ep ap 0.6808, val acc 0.7720, test acc 0.8270
difference tensor(1.4653, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 27/200]: ep loss 0.6471, nc loss 0.6775, ep auc: 0.6916, ep ap 0.6804, val acc 0.7780, test acc 0.8270
difference tensor(1.8429, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 28/200]: ep loss 0.6501, nc loss 0.6888, ep auc: 0.6907, ep ap 0.6793, val acc 0.7740, test acc 0.8270
difference tensor(1.7575, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 29/200]: ep loss 0.6524, nc loss 0.6884, ep auc: 0.6906, ep ap 0.6791, val acc 0.7740, test acc 0.8270
difference tensor(1.9057, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 30/200]: ep loss 0.6529, nc loss 0.6751, ep auc: 0.6897, ep ap 0.6780, val acc 0.7780, test acc 0.8270
difference tensor(1.8477, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 31/200]: ep loss 0.6530, nc loss 0.6704, ep auc: 0.6868, ep ap 0.6757, val acc 0.7840, test acc 0.8270
difference tensor(2.4519, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 32/200]: ep loss 0.6529, nc loss 0.6870, ep auc: 0.6854, ep ap 0.6747, val acc 0.7880, test acc 0.8270
difference tensor(4.3147, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 33/200]: ep loss 0.6515, nc loss 0.6864, ep auc: 0.6836, ep ap 0.6729, val acc 0.7900, test acc 0.8270
difference tensor(2.5566, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 34/200]: ep loss 0.6492, nc loss 0.6557, ep auc: 0.6797, ep ap 0.6696, val acc 0.7820, test acc 0.8270
difference tensor(1.7678, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 35/200]: ep loss 0.6467, nc loss 0.6832, ep auc: 0.6741, ep ap 0.6657, val acc 0.7820, test acc 0.8270
difference tensor(1.2900, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 36/200]: ep loss 0.6444, nc loss 0.6548, ep auc: 0.6699, ep ap 0.6629, val acc 0.7780, test acc 0.8270
difference tensor(1.6532, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 37/200]: ep loss 0.6426, nc loss 0.6517, ep auc: 0.6694, ep ap 0.6631, val acc 0.7740, test acc 0.8270
difference tensor(2.2125, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 38/200]: ep loss 0.6412, nc loss 0.6420, ep auc: 0.6666, ep ap 0.6611, val acc 0.7720, test acc 0.8270
difference tensor(2.1501, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 39/200]: ep loss 0.6404, nc loss 0.6398, ep auc: 0.6667, ep ap 0.6614, val acc 0.7760, test acc 0.8270
difference tensor(1.1546, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 40/200]: ep loss 0.6401, nc loss 0.6538, ep auc: 0.6660, ep ap 0.6610, val acc 0.7720, test acc 0.8270
difference tensor(1.4234, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 41/200]: ep loss 0.6404, nc loss 0.6365, ep auc: 0.6646, ep ap 0.6598, val acc 0.7700, test acc 0.8270
difference tensor(1.2489, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 42/200]: ep loss 0.6409, nc loss 0.6459, ep auc: 0.6645, ep ap 0.6598, val acc 0.7620, test acc 0.8270
difference tensor(4.2171, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 43/200]: ep loss 0.6414, nc loss 0.6386, ep auc: 0.6652, ep ap 0.6601, val acc 0.7580, test acc 0.8270
difference tensor(2.9591, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 44/200]: ep loss 0.6421, nc loss 0.6583, ep auc: 0.6651, ep ap 0.6599, val acc 0.7640, test acc 0.8270
difference tensor(2.1232, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 45/200]: ep loss 0.6429, nc loss 0.6472, ep auc: 0.6629, ep ap 0.6580, val acc 0.7660, test acc 0.8270
difference tensor(1.8385, device='cuda:1', grad_fn=<MaxBackward1>)
Epoch [ 46/200]: ep loss 0.6440, nc loss 0.6575, ep auc: 0.6643, ep ap 0.6590, val acc 0.7680, test acc 0.8270